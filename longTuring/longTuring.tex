\documentclass[11pt]{memoir}

\pagestyle{plain}
%\pagestyle{simple}
\setlrmarginsandblock{1in}{*}{*}
\checkandfixthelayout

\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{3}
\counterwithout{section}{chapter}
\counterwithin{equation}{section}
%\numberwithin{equation}{section} % in amsmath
%\counterwithout{figure}{chapter}
\counterwithin{figure}{section}

\makeatletter
% To correct a memoir bug:
\renewcommand{\@memmain@floats}{%
  \counterwithin{figure}{section}
  \counterwithin{table}{section}}
\makeatother

\firmlists

% If you do not want the bibliography on a separate page:
\renewcommand{\bibsection}{% 
\section*{\bibname} 
\prebibhook}

\usepackage[backref,hyperindex,colorlinks,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage[numbered]{bookmark} % Allows to place a bookmark, see the title. Shows section numbers.
% \usepackage[all]{hypcap} % After hyperref, to anchor floats correctly.
% \usepackage{float}
 % After hyperref:
\usepackage[algo2e,algosection,tworuled,noend,noline]{algorithm2e}
\usepackage[charter]{gacs}
%\usepackage[noBBpl]{mathpazo}
%\usepackage{amssymb}
%\usepackage[charter]{gacs}
%\usepackage[libertine]{gacs}
\usepackage{gacs-algo} % After hyperref.
% After gacs.sty

%\usepackage[pagecolor={LightCyan1}]{pagecolor}
%\usepackage[pagecolor={DarkSeaGreen1}]{pagecolor}
%\usepackage[pagecolor={Honeydew1}]{pagecolor}
%\usepackage[pagecolor={Azure1}]{pagecolor}
%\usepackage[pagecolor={Cornsilk1}]{pagecolor}
%\usepackage[pagecolor={Ivory1}]{pagecolor}

\hyphenation{com-plex-ity des-tin-at-ion co-lon-ies}

% \newcommand{\shownotes}{1}
% \ifnum\shownotes=1
% \newcommand{\authnote}[3]
% {\text{{ \textcolor{#3}{\( \langle\hspace{-0.2em}\langle \)\textsf{\footnotesize #1: #2}\( \rangle\hspace{-0.2em}\rangle \)}}}}
% \else
% \newcommand{\authnote}[2]{}
% \fi
% \newcommand{\Pnote}[1]{{\authnote{P}{#1}{cyan}}}
% \newcommand{\Inote}[1]{{\authnote{I}{#1}{blue}}}

\theoremstyle{definition} % not italicized
\newtheorem{Premark}{\color{cyan}Peter remark}
\newenvironment{premark}{\begin{Premark}\color{cyan}}{\varqed\end{Premark}}

% \newtheorem{Iremark}{\color{blue}Ilir remark}[Premark]
% \newenvironment{iremark}{\begin{Iremark}\color{blue}}{\varqed\end{Iremark}}

% \renewcommand{\Pnote}[1]{\begin{premark}#1\end{premark}}
% \renewcommand{\Inote}[1]{\begin{iremark}#1\end{iremark}}

\renewcommand{\le}{\leq}
\renewcommand{\ge}{\geq}

\renewcommand{\vek}[1]{\mathbf{#1}}
\newcommand{\fld}[1]{\ensuremath{\textit{#1\/}}}
\newcommand{\rul}[1]{\ensuremath{\texttt{#1}}}

% Using def for the possibility of switching between LaTeX and XeTeX:
\def\B{B}  
\def\U{U}

\newcommand{\va}{\vek{a}} % current cell-pair
\newcommand{\blank}{\text{\textvisiblespace}}
\newcommand{\Configs}{\mathrm{Configs}}
\renewcommand{\d}{d}
\newcommand{\E}{E} % size of healing interval
% Feathering:

\makeatletter
\if@charter\renewcommand{\f}{f}\else\newcommand{\f}{f}\fi
\makeatother
\newcommand{\F}{F}
\newcommand{\g}{g}
\def\G{G} % TM to be simulated (why a def?)
\newcommand{\h}{h} % head position
% Current pair
\newcommand{\hc}{\hat h}
\newcommand{\vhc}{\vek{\hat h}}
\newcommand{\Int}{\mathrm{Int}} % interior of intervals
\newcommand{\Noise}{\mathit{Noise}}
\newcommand{\passno}{\pi}
\newcommand{\pos}{\mathrm{pos}}
\newcommand{\curcell}{\textrm{cur-cell}}
\newcommand{\Q}{Q} % Colony size
\newcommand{\R}{R} % healing interval
\newcommand{\s}{s} % used as burst number upper bound 
\renewcommand{\S}{S} % What was it? Used to denote the time bound on short stays.
% switching time upper bound:
\newcommand{\Tu}{T} 
\newcommand{\Tus}{T^{*}}
\newcommand{\Z}{Z} % Zigging length
\newcommand{\z}{z} % center of healing or rebuilding

\newcommand{\tape}{\mathrm{tape}}
\newcommand{\Interpr}{\mathrm{Interpr}} % interprets the set of rules
\newcommand{\Decode}{\mathrm{Decode}}
\newcommand{\Encode}{\mathrm{Encode}}
\newcommand{\Un}{\mathrm{Univ}}
\newcommand{\increment}[1]{#1\mathord{+}\mathord{+}}
\newcommand{\decrement}[1]{#1\mathord{-}\mathord{-}}

% Indexes of program names
\newcommand{\decode}{\mathrm{decode}}
\newcommand{\encode}{\mathrm{encode}}

\newcommand{\dir}{\mathrm{dir}} % sweep direction
\newcommand{\Histories}{\mathrm{Histories}}
\newcommand{\Trajectories}{\mathrm{Trajectories}}

% Certain milestone sweep numbers.
\newcommand{\TransferSw}{\mathrm{TransferSw}}
\newcommand{\Last}{\mathrm{Last}}

\newcommand{\PadLen}{\mathit{PadLen}} % width of margin used for feathering
%\newcommand{\Interpr}{\mathit{Interpr}} % interprets the set of rules

% Left and right newly created colonies C_{\Left}, etc.
\newcommand{\Left}{\text{left}}
\newcommand{\Right}{\text{right}}

\renewcommand{\r}{\vek{r}} % radius. What was it? 
\newcommand{\x}{\vek{x}} % center of a segment 
\newcommand{\y}{\vek{y}} % center of a segment 

% Fields
\newcommand{\Addr}{\fld{Addr}}
\newcommand{\bigDigression}{\fld{BigDigression}}
\newcommand{\BridgeDir}{\fld{BridgeDir}}
\newcommand{\BridgeKind}{\fld{BridgeKind}}
\newcommand{\Core}{\fld{Core}}
\newcommand{\Drift}{\fld{Drift}}
\newcommand{\Doomed}{\fld{Doomed}}
\newcommand{\frontDist}{\fld{FrontDist}}
\newcommand{\Heal}{\fld{Heal}} % collects fields used in healing mode
\newcommand{\Hold}{\fld{Hold}}
\newcommand{\Index}{\fld{Index}}
\newcommand{\Info}{\fld{Info}}
\newcommand{\Kind}{\fld{Kind}}
\newcommand{\leftTurnDist}{\fld{LeftTurnDist}}
\newcommand{\Mode}{\fld{Mode}}
\newcommand{\Output}{\fld{Output}}
\newcommand{\Rebuild}{\fld{Rebuild}} % collects fields used in rebuilding mode 
\newcommand{\Replace}{\fld{Replace}} 
\newcommand{\Rider}{\fld{Rider}} % to execute the actual simulation.
\newcommand{\rightTurnDist}{\fld{RightTurnDist}}
\newcommand{\Sweep}{\fld{Sweep}} % the number of sweep during simulation
\newcommand{\totalBigDigression}{\fld{TotalBigDigression}}
\newcommand{\Turned}{\fld{Turned}} % to control feathering
\newcommand{\Work}{\fld{Work}} % track for all kinds of work
\newcommand{\ZigAddr}{\fld{ZigAddr}}

% modes
\newcommand{\Normal}{\mathrm{Normal}}
\newcommand{\Healing}{\mathrm{Healing}}
\newcommand{\Rebuilding}{\mathrm{Rebuilding}}

% states
\newcommand{\Bad}{\mathrm{Bad}}
\newcommand{\Vacant}{\mathrm{Vac}}
\newcommand{\New}{\mathrm{New}}
\newcommand{\new}{\mathrm{new}}

% kinds
\newcommand{\Stem}{\mathrm{Stem}}
\newcommand{\Booting}{\mathrm{Booting}}
\newcommand{\Bridge}{\mathrm{Bridge}}
\newcommand{\Inner}{\mathrm{Inner}}
\newcommand{\Member}{\mathrm{Member}}
\newcommand{\Outer}{\mathrm{Outer}}

% Rules
\newcommand{\rHeal}{\rul{Heal}}
\newcommand{\Compute}{\rul{Compute}}
\newcommand{\Transfer}{\rul{Transfer}}
\newcommand{\WriteProgramBit}{\rul{WriteProgramBit}}

% Constants
\newcommand{\True}{\mathrm{True}}
\newcommand{\False}{\mathrm{False}}
\newcommand{\cns}[1]{c_{\textrm{\upshape #1}}}
\newcommand{\CEsc}{\cns{esc}}
\newcommand{\CMarg}{\cns{marg}}
\newcommand{\CPass}{\cns{pass}}
\newcommand{\CRedund}{\cns{redund}}
\newcommand{\CSim}{\cns{sim}}
\newcommand{\CShort}{\cns{short}}
\newcommand{\CSpill}{\cns{spill}}


\begin{document}

\title{A reliable Turing machine}
% Why do I need this?  Some people get the title bookmarked even without this.
\bookmark[page=1,level=0]{A reliable Turing machine}

\author{Ilir \c{C}apuni 
\\ University of Montenegro
\\ ilir@bu.edu
\and
Peter G\'acs
\\ Boston University
\\ gacs@bu.edu
}
\maketitle

\begin{abstract}
  We consider computations of a Turing machine subjected to noise.
  In every step, the action (the new state and the new content of the observed
  cell, the direction of the head movement) can differ from that prescribed by
  the transition function with a small probability (independently of previous
  such events).  We construct a universal 1-tape Turing machine that for a low enough
  (constant) noise probability performs arbitrarily large computations.  For
  this unavoidably, the input needs to be encoded---by a simple code depending
  on its size.  The work uses a technique familiar from reliable cellular
  automata, complemented by some new ideas.
\end{abstract}

\newpage

% \tableofcontents*

\section{Introduction}

This work addresses a question from the area of ``reliable computation with unreliable components''.
A certain class of machines is chosen, (like a Boolean circuit, cellular automaton, Turing machine).
It is specified what kind of faults (local in space and time)
are allowed, and a machine of the given
kind is built that---paying some price in performance---carries out essentially the same
task as any given machine of the same kind without any faults would.

We confine attention to \emph{transient}, \emph{probabilistic} faults:
the fault occurs at a given time but no component is damaged permanently,
and faults occur independently of each other, with a bound on their probability.
This in contrast to bounding the \emph{number} of faults, allowing them to be set by an adversary.

Historically the first result of this kind is~\cite{VonNeum56}, which for each Boolean
circuit \( C \) of size \( n \) constructs a new circuit \( C' \)
of size \( O(n\log n) \) that performs the same task as \( C \) with a (constant)
high probability, even though each gate of
\( C' \) is allowed to fail with some (constant) small probability.

Cellular automata as a model have several theoretical advantages over Boolean circuits, and results concerning
reliable computation with them have interest also from a purely mathematical or 
physical point of view (non-ergodicity).
The simple construction in~\cite{GacsReif3dim88} gives, for any 1-dimensional
cellular automaton \( A \) a 3-dimensional cellular automaton \( A' \) 
that performs the same task as \( A \) with high probability, even though each cell of
\( A' \) is allowed to fail in each time step with some constant small probability.
(A drawback of this construction is the requirement of synchronization: all cells of \( A' \) must
update simultaneously.)
Reliable cellular automata in less than 3 dimensions can also be constructed (even
without the synchrony requirement), but so far only at a
steep increase in complexity (both of the construction and the proof).
The first such result was~\cite{Gacs1dim86}, relying on some ideas proposed in~\cite{Kurd78}.

Here, the reliability question will be considered for a \emph{serial}
computation model---Turing machine---as opposed to parallel ones like
Boolean circuits or cellular automata.
There is a single elementary processing unit (the \df{active} unit)
interacting with a memory of unlimited size.
The error model needs to be relaxed.
Allowing each memory component to fail in each time step with constant probability
makes, in the absence of parallelism, reliable computation seems impossible.
Indeed, while in every step some constant fraction of the memory gets corrupted,
the active unit can only correct a constant \emph{number} of them per step.

In the relaxed model considered here, faults can affect only the operation of the active unit.
More precisely at any given time the allowed operations of the machine are the usual ones:
changing its state, writing to the observed tape cell, moving the head by a step left or right (or not at all).
The transition table of the machine prescribes which action to take.
So our fault model is the following.

\begin{definition}
  Let \( \Noise \) be a random subset of some set \( U \).
  We will say that the distribution of \( \Noise \) is \( \eps \)-\df{bounded} if for every finite subset \( A \)
  we have
  \begin{align*}
   \Pbof{A\subseteq\Noise} \le \eps^{|A|}.
  \end{align*}
\end{definition}
See~\cite{Toom80} for an earlier use of this kind of restriction.

\begin{definition}\label{def:faults-eps-bounded}
  Let \( \cC = (C_{1},C_{2}\dots) \) be  a random sequence of configurations of a Turing machine \( T \)
  with a given fixed
  transition table, with the property that for each time \( t \), the \( C_{t+1} \) is obtained from \( C_{t} \) by
  one of the allowed operations.
  We say that a \df{fault} occurred at time \( t \) if the operation giving \( C_{t+1} \) from \( C_{t} \) is
  not obtained by the transition function.
  Let \( \Noise\subseteq\bbZ_{+} \) be the (random) set of faults in the sequence.
  We say that faults of the sequence \( \cC \) are \( \eps \)-\df{bounded}, if the set \( \Noise \) is.  
\end{definition}

The challenge for Turing machines
is still significant, since even if only with small probability, occasionally a group
of faults can put the head into the middle of a large segment of the tape rewritten
in an arbitrarily ``malicious'' way.
A method must be found to recover from all these situations.

Here we define a Turing machine that is reliable---under this fault model--- in
the same sense as the other models above.
The construction and proof are similar in complexity to the ones for 1-di\-men\-sion\-al cellular automata;
however, we did not find a reduction to these earlier results.
A natural idea is to let the Turing machine simulate a 1-dimensional cellular automaton, by
having the head make large sweeps, and updating the tape as the simulated cellular automaton would.
But apart from the issue of excessive delay, we did not find any simple
way to guarantee the large sweeps in the presence of faults (where ``simple'' means not building some new
hierarchy), even for some price paid in efficiency.
So here we proceed ``from scratch''.

Many ideas used here are taken from~\cite{Gacs1dim86} and~\cite{GacsSorg01},
but hopefully in a somewhat simpler and more intuitive conceptual framework.
Like~\cite{Gacs1dim86} it confines all probability reasoning to a single lemma,
deals on each level only with a numerical restriction on faults (of that level).
On the other hand, like~\cite{GacsSorg01} it defines a series of generalized objects
(generalized Turing machines here rather than generalized cellular automata),
each one simulating the next in the series.
In~\cite{GacsSorg01} a ``trajectory'' (central for defining the notion of simulation) was
a random history whose distribution satisfies certain constraints (most of which are combinatorial).
Here it is a single history satisfying only some combinatorial constraints.

The work~\cite{AsarinCollins2005} seems related by its title 
but is actually on another topic.
The work~\cite{DurandRomashShenTiling12} applies the self-simulation and
hierarchical robustness technique developed for cellular automata in an interesting, but
simpler setting.
Several attempts at the chemical or
biological implementation of universal computation have to deal with
the issue of error-correction right away.
In these cases generally the first issue is the faults occurring at the active site (the head).
See~\cite{BennettThermodynComp1982,QianSoloveichikWinfree2011}.

Our result can use any standard definition of 1-tape Turing machines whose tape alphabet
contains some fixed ``input-output alphabet'' \( \Sigma \); we will
introduce one formally in Section~\ref{sec:TM}.
We will generally view a tape symbol as a tuple consisting of several \df{fields}.
The notation
\begin{align*}
   a.\Output, a.\Info
 \end{align*}
 shows \( \Output \) and \( \Info \) as fields of tape cell state \( a \).
Combining the same field of all tape cells, we can talk about a \df{track}
(say the \( \Output \) track and \( \Info \) track).
For ease of spelling out a result, we consider only computations whose outcome
is a single symbol, written into the \( \Output \) field of tape position 1.
It normally holds a special value---say \( * \) ---meaning \df{undefined}.

 Block codes (as defined in Section~\ref{sec:codes} below) are specified by a pair \( \pair{\psi_{*}}{\psi^{*}} \)
of encoding and decoding functions.
In the theorem below, the input of the computation, of some length \( n \), is broken up into blocks
that are encoded by a block code that depends in some simple way on \( n \).
Its redundancy depends on the size of the input as a log power.
The main result in the theorem below shows a Turing machine simulating a fault-free
Turing machine computation in a fault-tolerant way.
It is best to think of the simulated machine \( G \) as some universal Turing machine.

\begin{theorem}\label{thm:main}
  For any Turing machine \( \G \) there are constants \( \alpha_{1},\alpha_{2}>0 \),
for each \( n \) a block code \( (\varphi_{*}, \varphi^{*}) \) of block size \( O((\log n)^{\alpha_{1}}) \),
a fault bound  \( 0\le\eps <1 \) and a Turing machine \( M_{1} \) with a 
function \( a\mapsto a.\Output \) defined on its alphabet,
such that the following holds.

Let \( M_{1} \) start its work from the initial tape configuration \( \varphi_{*}(x) \) with the head
in position 0,
running through a random sequence of configurations whose faults are \( \eps \)-bounded in the sense
of Definition~\ref{def:faults-eps-bounded}.
Suppose that at time \( t \) the machine \( \G \) writes a value \( y\ne * \) 
into the \( \Output \) field of the cell at position 0.
Then at any time greater than \(    t(\log t)^{\alpha_{2}} \),
 the tape symbol \( a \) of machine \( M_{1} \) at position 0
 will have \( a.\Output= y \) with probability at least \( 1 - O(\eps) \).
\end{theorem}


\section{Overview}

The overview, but even the main text, is not separated completely
into two parts: the definition of the Turing machine, followed by the proof of its reliability.
The definition of the machine is certainly translatable (with a lot of tedious work) into just a Turing
machine transition table (or \df{program}), but its complexity requires first to develop a \df{conceptual
apparatus} behind it which is also used in the proof of reliability.
We will try to indicate below at the beginning of each
section whether it is devoted more to the program or more to the conceptual apparatus.

\subsection{Isolated bursts of faults}\label{sec:bursts}

(Introducing some basic elements of the \emph{program}.)
In~\cite{burstyTuring13} we defined a Turing machine \( M_{1} \) that simulates ``reliably'' any other
Turing machine even when it is subjected to isolated \df{bursts} of faults (that is a group
of faults occurring in consecutive time steps) of constant size.
We will use some of the ideas of~\cite{burstyTuring13}, without relying directly
on any of its details, and will add several new ideas.
Let us give a brief overview of this machine \( M_{1} \).
% We break up the task of error correction into several 
% problems to be solved.
% The solution of one problem gives rise to another one, but the process converges.
% \begin{description}
% \item[Redundant information] The tape information of \( G \) is put into
% an error-correcting block code.
% \item[Redundant processing] The block code will be decoded, the retrieved information 
% will be processed, and the result encoded.
% The major processing steps will be 
% carried out on a working track three times within one work period,
% recording the result onto separate tracks.
% The information track is changed only in a final majority vote.
% \item[Local repairability] In order to resist a local burst of faults.
% the process is organized into a rigid, locally checkable structure
% with the help of local addresses, and some other tools like sweeps and 
% short switchbacks (zigzags).
% \item[Disturbed local repair] A conservatively organized healing procedure
% restores consistency in a way that cannot be abused by new bursts.
% \end{description}

% Here is some more detail.
Each tape cell of the simulated machine \( M_{2} \) will be represented by a block of
some size \( \Q \) called a \df{colony}, of the simulating machine \( M_{1} \).
Each step of \( M_{2} \) will be simulated by a computation of \( M_{1} \) called
a \df{work period}.
During this time, the head of \( M_{1} \) makes a number of sweeps over the
current colony-pair, decodes the represented cell symbols,
then computes and encodes the new symbols, and finally moves the head 
to the new position of the head of \( M_{2} \).
The major processing steps will be 
carried out on a working track three times within one work period,
recording the result onto separate tracks.
The information track is changed only in a final majority vote.

The organization is controlled by a few key fields, for example a field
called \( \Addr \) showing the position of each cell in the colony, and a field
\( \Sweep \), the number of the last sweep of the computation (along with its direction)
that has been performed already.
The most technical part is to protect this control information from faults.
For example, a burst of faults of constant size can reverse the head in the middle of a sweep.
To discover such structural disruptions locally before
the head would go far in the wrong direction, it will make frequent short zigzags.
A premature turn-back will be detected this way, triggering the healing procedure.

% This description uses in an informal way some words that
% will get precise definition later.
% For example, the word \df{colony} will have at least two formal definitions.
% From the point of view of the program (transition function), it is just a 
% sequence of addresses from \( 0 \) to \( \Q-1 \).
% From the point of view of the analysis, it is a sequence of
% actual adjacent tape cells with the address field having theses values.

\subsection{Hierarchy}\label{sec:hier}

(Starting to develop the \emph{conceptual apparatus}.)
In order to build a machine resisting faults 
occurring independently in each step with some small probability,
we take the approach used for one-dimensional cellular automata.
We aim at building a \df{hierarchy of simulations}:
machine \( M_{1} \) simulates machine \( M_{2} \) which simulates machine \( M_{3} \), and so on.
Machine \( M_{k} \) has alphabet
\begin{align}\label{eq:Sigma_k}
   \Sigma_{k}=\{0,1\}^{s_{k}},
\end{align}
that is its tape cells have ``capacity'' \( s_{k} \).
All these machines should be implementable on a universal Turing machine with
the same program (with an extra input, the number \( k \) denoting the level).
For ease of analysis, we introduce the notion of \df{cell size}:
level \( k \) has its own cell size \( \B_{k} \) and block (colony) size \( \Q_{k} \)
with \( B_{1}=1 \), \( \B_{k+1}=\B_{k}\Q_{k} \).
This allows
locating a tape cell of \( M_{k} \) on the same interval where the cells of \( M_{1} \) simulate it.
One cell of machine \( M_{k+1} \) is simulated by a colony of machine \( M_{k} \);
so one cell of \( M_{3} \) is simulated by \( \Q_{1}\Q_{2} \) cells of \( M_{1} \).
Further, one step of, say, machine \( M_{3} \) is simulated by one
work period of \( M_{2} \) of, say, \( O(\Q_{2}^{2}) \) steps.

Per construction, machine \( M_{1} \) can withstand
bursts of faults with size  \( \le \beta \) for some constant parameter \( \beta \),
separated by at least some constant \( \gamma \) work periods.
It would be natural now to expect that machine
\( M_{1} \) can withstand also some \emph{additional}, larger bursts
of size \( \le \beta \Q_{1} \) if those are separated
by at least \( \gamma \) work periods of \( M_{2} \).
However, a \emph{new obstacle} arises.
Damage caused by a big burst of faults spans several colonies.
The repair mechanism of machine \( M_{1} \) outlined in Section~\ref{sec:bursts} 
is too local to recover from such extensive damage, leaving
the whole hierarchy endangered.
So we add a new mechanism to \( M_{1} \) that
will just try to restore the colony structure of a large enough portion of the
tape (of the extent of several colonies).
The task of restoring the original information is left to higher levels (whose simulation
now can continue).

All machines above \( M_{1} \) in the hierarchy live only in simulation: the hardware is \( M_{1} \).
Moreover, the \( M_{k} \) with \( k>1 \)
will not be ordinary Turing machines, but \df{generalized} ones,
with some new features seeming necessary in a simulated Turing machine:
allowing for some ``disordered'' areas of the tape not obeying the transition function,
and occasionally positive distance between neighboring tape cells.

A tricky issue is ``forced self-simulation''.
Each machine \( M_{k} \) can be implemented on a universal machine using as inputs
the pair \( (p,k) \) where \( p \) is the common program and \( k \) is the level.
Eventually, \( p \) will just be hard-wired into the definition of \( M_{1} \),
and therefore faults cannot corrupt it.
While creating \( p \) for machine \( M_{1} \),
we want to make it simulate a machine \( M_{2} \) that has the same program \( p \).
The method to achieve this is not really different from the one
applied already in some of the cellular automata and tiling papers cited, 
and is related to the proof of Kleene's fixed-point theorem (also called the recursion theorem).

Forced self-simulation can give rise to an infinite sequence of simulations, achieving
the needed robustness.
But the simulation of \( M_{k+1} \) by \( M_{k} \) uses only certain tracks of the tape.
Another track  (which we will call \( \Rider \)) will be set aside
for simulating \( \G \).
If the simulation of \( \G \) on the \( \Rider \) track of a colony-pair
does not finish in a certain number of steps,
a built-in mechanism will \df{lift} its tape content to the \( \Rider \)
field of the simulated cell-pair, allowing it to be continued in a colony-pair of the next
level (with the corresponding higher reliability).

\subsection{Structuring the noise}\label{sec:sparsity-informal}

(Some definitions for analyzing the noise.)
The set of faults in the noise model of the theorem is a set of points in time.
It turns out more convenient to use an equivalent model:
an \( \eps \)-bounded \emph{space-time} set of points.
Let us make this statement more formal.

\begin{lemma}
  Let \( \cC=(C_{1},C_{2},\dots) \) be the random sequence of configurations of a Turing machine
  with an \( \eps \)-bounded set of faults \( \Noise_{1}\subseteq\bbZ_{+} \),
  as in Definition~\ref{def:faults-eps-bounded}.
  Let \( h(t) \) be the (random) position of the head at time \( t \).
  Then the random set \( \Noise_{2}=\setOf{(h(t),t)}{t\in\Noise_{1}} \).
is an \( \eps \)-bounded subset of \( \bbZ\times\bbZ_{+} \).
\end{lemma}
\begin{proof}
  Let \( A \) be a finite subset of  \( \bbZ\times\bbZ_{+} \), and
  \( A' = \setOf{t}{(p,t)\in A} \).
  If \( A\subseteq\Noise_{2} \) then \( A'\subseteq\Noise_{1} \) and \( |A'|=|A| \).
  Hence 
\begin{align*}
 \Pbof{A\subseteq\Noise_{2}}\le\Pbof{A'\subseteq\Noise_{1}}\le \eps^{|A'|}=\eps^{|A|} .
\end{align*}
\end{proof}

The construction outlined above counts with \emph{bursts} (rectangles of space-time
containing  \( \Noise \)) increasing in size and decreasing
in frequency---which is a combinatorial set of constraints.
To derive such constraints from the above probabilistic model
the  we stratify \( \Noise \) as follows.
We will have two series of parameters:  \( \B_{1}<\B_{2}<\dotsm \) and
\( \Tu_{1}<\Tu_{2}<\dotsm \).
Here \( \B_{k} \) is the size of cells of \( M_{k} \) as represented on the tape of \( M_{1} \),
and \( \Tu_{k} \) is a bound on the time needed to simulate one step of  \( M_{k} \).

Here are some informal definitions (precise ones are given in 
Section~\ref{sec:sparsity}).
For some constants \( \beta,\gamma>1 \),
a \df{burst} of noise of type \( \pair{a}{b} \)
is a space-time set that is essentially coverable by a  \( a\times b \).
For an integer \( k>0 \) it is of \df{level} \( k \) when it is of type \( \beta(\B_{k}\times\Tu_{k}) \).
It is \df{isolated} if it is 
essentially alone in a rectangle of type \( \gamma(\B_{k+1}\times\Tu_{k+1}) \) 
First we remove such isolated bursts of level 1, then of level 2
from the remaining set, and so on.
It will be shown that with not too fast increasing sequences \( \B_{k},\Tu_{k} \), with probability 1,
this sequence of operations eventually completely erases \( \Noise \): thus each fault belongs to
a burst of ``level'' \( k \) for some \( k \).

Machine \( M_{k} \) will concentrate only on correcting isolated bursts of level \( k \) and on restoring
the framework allowing \( M_{k+1} \) to do its job.
It can ignore the lower-level bursts and will need to work correctly
only in the absence of higher-level bursts.


\subsection{Difficulties}\label{sec:novelties}

(Referring both to the program and to the concepts behind it.)
We list here some of the main problems that the paper deals with, 
and some general ways in which they will be solved or avoided.
Some more specific problems will be pointed out later, along with their solution.

\begin{description}

\item[Non-aligned colonies] A large burst of faults in \( M_{1} \) can modify the order of
entire colonies or create new ones with gaps between them.
To deal with this problem, machines \( M_{k} \) for \( k>1 \)
will be \df{generalized Turing machines}, allowing for non-adjacent cells.

\item[Clean areas]
  The tape of a generalized Turing machine will be divided, based on its content, into
  some areas called \df{clean}, the rest \df{disordered}.
  Clean areas will be essentially where the analysis
  can count on an existing underlying simulation,
  and where therefore the transition function is applicable.
  Noise can disorder the areas where it occurs.

\item[Extending cleanness]
  The predictability of the machine is decreased when the head enters into disorder.
  But the model still provides some ``magical'' properties
  helping to restore cleanness (in the absence of new noise):
  \begin{Alphenum}
  \item escaping from any area in a bounded amount of time;
 \item extension of clean intervals as the head passes in and out of them;
 \item\label{i:many-slides}
   the cleaning of an interval when passed over a certain number of times.
 \end{Alphenum}
While an area is cleaned, it will also be re-populated with cells.
Their content is not important, what matters is the restoration of predictability.

\item[Rebuilding]
The need to reproduce the cleaning properties in simulation is the
main burden of the construction.
The part of the program devoted to this is the rebuilding procedure,
invoked when local repair fails.
  It reorganizes a part of the tape having the size of a few colonies.
\end{description}

% \section{Notation}\label{sec:notation}

% Most notational conventions given here are common; some other ones will
% also be useful.

% \begin{description}

% \item [Natural numbers and integers] 
% By \( \bbZ \) we denote the set of integers.
% \begin{align*}
%    \bbZ_{>0}&=\setOf{x}{x\in \bbZ,\;  x>0}, \\
%    \bbZ_{\ge 0}&=\bbN=\setOf{x}{x\in \bbZ,\;  x\ge 0}.
% \end{align*}

% \item [Intervals]
% We use the standard notation for intervals:
% \begin{align*}
%    \clint{a}{b}&=\setOf{x}{a\le x \le b},\quad \lint{a}{b}=\setOf{x}{a\le x < b}, \\
%    \rint{a}{b}&=\setOf{x}{a< x \le b}, \quad  \opint{a}{b}=\setOf{x}{a< x < b}.
% \end{align*}
% We will also write \( \lint{a}{b} \) in place of \( \lint{a}{b}\cap \bbZ \), 
% whenever this leads to no confusion.
% Instead of \( \lint{x+a}{x+b} \), sometimes we will write 
% \begin{align*}x + \lint{a}{b}.\end{align*}

% \item [Ordered pairs]
% Ordered pairs are also denoted by \( \pair{a}{b} \),
% but it will be clear from the context whether we are
% referring to an ordered pair or open interval.

% \item [Comparing the order of a number and an interval]
% For a given number \( x \) and interval \( I \), we
% write
% \begin{align*} x \ge I \end{align*}
% if for every \( y\in I \),  \( x \ge y \).

% \item [Distance]
% The distance between two real numbers \( x \) and \( y \) is defined
% in a usual way:
% \begin{align*}
%     d(x,y)= \abs{x-y}.
% \end{align*}

% The \df{distance of a point \( x \) from interval \( I \)}  is
% \begin{align*}
%     d(x,I)= \min_{y\in I}d(x,y).
% \end{align*}

% \item [Ball, neighborhood, ring, stripe]
% A \df{ball of radius \( r>0 \), centered at point \( x \)} is
% \begin{align*}
%     B(x,r)= \setOf{y}{d(x,y)\le r}.
% \end{align*}
% An \df{\( r \)-neighborhood of interval } \( I \) is
% \begin{align*}
%     \setOf{x}{d(x,I)\le r}.
% \end{align*}
% An \df{\( r \)-ring} around interval \( I \) is
% \begin{align*}
%     \setOf{x}{d(x,I)\le r \txt{ and } x \notin I}.
% \end{align*}
% An \df{\( r \)-stripe to the right of interval \( I \)} is
% \begin{align*}
%     \setOf{x}{d(x,I)\le r \txt{ and } x \notin I \txt{ and } x>I}.
% \end{align*}

% \item[Logarithms] Unless specified differently,
% the base of logarithms throughout this work is 2.

% \end{description}

\subsection{Structuring the noise formally}\label{sec:sparsity}

(This purely mathematical section derives the combinatorial noise
constraints from the probabilistic one.)
If we modeled noise as a set of time points then a burst of faults would be a time
interval of size \( \beta\Tu_{k} \) and might affect a space interval as large as \( \beta\Tu_{k} \),
covering many times more simulated cells of level \( k \).
Therefore we model noise as a set of space-time points; this does not change the independence
assumption of the main theorem.

\begin{definition}\label{def:isolation}
Let \( \r=\pair{r_{1}}{r_{2}} \), \( r_{1}, r_{2}> 0 \)
be a two-dimensional nonnegative vector.
A \df{rectangle of radius} \( \r  \) \df{centered} at point  \( \x \) is
\begin{align}\label{eq:ball1}
  B(\x,\r) = \setOf{\y}{\abs{y_{i} - x_{i}} < r_{i}, i=1,2}.
\end{align}  
Let \( E\subseteq \bbZ\times\bbZ_{\ge 0} \) be a space-time set (to be considered our noise set).
A point \( \x \) of \( E \) is \df{\( \pair{\r}{\r^{*}} \)-isolated} if
\(  E \cap B(\x,\r^{*})\subseteq B(\x, \r)  \),
that is all points of \( E \) that are \( \r^{*} \)-close to \( x \) are also \( \r \)-close.
A set \( E \) is called \( \pair{\r}{\r^{*}} \)-\df{sparse} if each of its points is \( \pair{\r}{\r^{*}} \)-isolated.
\end{definition}

The following lemma will justify talking about bursts of faults.

\begin{lemma}\label{lem:bursts}
  Suppose that the set \( E \) is \( \pair{\r}{\r^{*}} \)-sparse.
  Then in every rectangle \( U \) of size \( r^{*}_{1}\times r^{*}_{2} \), 
\( U\cap E \) is covered by some rectangle of size \( r_{1}\times r_{2} \).
\end{lemma}
\begin{proof}
  Let \( U \) be a rectangle of size \( r^{*}_{1}\times r^{*}_{2} \), and suppose that \( U\cap E \) is not
  covered by a rectangle of size \( r_{1}\times r_{2} \).
  Then either the horizontal projection of \( E\cap U \) is larger than \( r_{1} \) or the vertical one
  is larger than \( r_{2} \), hence there is a pair of points \( \x,\y\in E \) not covered by a single
  rectangle of size \( r_{1}\times r_{2} \).
  But then \( U\subseteq B(\x,\r^{*}) \) and \( \y\not\in B(\x,\r) \), hence \( \x \)
  is not \( (\r,\r^{*}) \)-isolated contrary to the assumption of \( (\r,\r^{*}) \)-sparsity.
\end{proof}

\begin{definition}\label{def:sparsity}
  Let \( \gamma> 1 \), \( \beta> 4\gamma \) be parameters, and let
  \begin{align*}
  1 &=\B_{1}<\B_{2}<\dotsm,\quad
  1=\Tu_{1}<\Tu_{2}<\dotsm,
\\ &\Tu_{k+1}/\Tu_{k},\; \B_{k+1}/\B_{k}\ge 2\beta
\end{align*}
be sequences of integers to be fixed later.
For a space-time set \( E\subseteq\bbZ\times\bbZ_{\ge 0} \), let \( E^{(1)} = E \).
For \( k>1 \) let \( E^{(k+1)} \) be obtained by deleting from \( E^{(k)} \) the
\( \pair{\beta\pair{\B_{k}}{\Tu_{k}}}{\gamma\pair{\B_{k+1}}{\Tu_{k+1}}} \)-isolated points.
Set \( E \) is \( k \)-\df{sparse} if \( E^{(k+1)} \) is empty.
It is simply \df{sparse} if \( \bigcap_{k}E^{(k)}=\emptyset \).
When \( E=E^{(k)} \) and \( k \) is known
then we will denote \( E^{(k+1)} \) simply by \( E^{*} \).
\end{definition}

The following lemma connects the above defined sparsity notions to the requirement
of small fault probability.

\begin{lemma}[Sparsity]\label{lem:sparsity}
Let \( \Q_{k} = \B_{k+1}/\B_{k} \),  \( \U_{k} = \Tu_{k+1}/\Tu_{k} \), and
\begin{align}\label{eq:growth-assumption}
  \lim_{k\rightarrow\infty}\frac{\log \Q_{k}\U_{k}}{1.5^k}=0.
\end{align}
For sufficiently small \( \eps \), for every \( k\ge 1 \) the following holds.
Let \( E\subseteq \bbZ\times\bbZ_{\ge 0} \) 
be a random set that is \( \eps \)-bounded as in Definition~\ref{def:faults-eps-bounded}.
Then for each point \( \x \)  and each \( k \),
 \begin{align*}
   \Pbof{B(\x,\pair{\B_{k}}{\Tu_{k}})\cap E^{(k)}\neq\emptyset} < \eps \cdot 2^{-1.5^{k-1}}.
 \end{align*}
As a consequence, the set \( E \) is sparse with probability 1.
\end{lemma}

This lemma allows a doubly exponentially increasing sequence \( \U_{k} \), resulting
in relatively few simulation levels as a function of the computation time.


\subsection{Generalized Turing machines}\label{sec:TM}

(This section, together with Section~\ref{sec:traj},
introduces the key concepts used in the proof.)
Let us recall that a one-tape Turing machine is defined by a
finite set \( \Gamma \) of \df{internal states},
a finite alphabet \( \Sigma \) of \df{tape symbols}, a transition function \( \delta \),
and possibly some distinguished states and tape symbols.
At any time, the head is at some integer position \( \h \), and is observing the tape
symbol \( A(\h) \).
The meaning of \( \delta(a,q)=(a',q',d) \) is that if \( A(\h)=a \) and the state is \( q \) then
the \( A(\h) \) will be rewritten as \( a' \) and \( \h \) will change to \( \h+d \).

We will use a model that is slightly different, but has clearly the same expressing power.
(Its advantage is that it is a little more convenient to describe its simulations.)
There are no internal states, but the head observes and modifies a \emph{pair} of
neighboring tape cells at a time; in fact, we imagine it to be positioned between these
two cells called the \df{current cell-pair}.
The \df{current cell} is the left element of this pair.
Thus, a Turing machine is defined as \(    (\Sigma,\tau) \) where
the tape alphabet \( \Sigma \) contains at least the distinguished
symbols \( \blank,0,1 \) where \( \blank \) is called the \df{blank symbol}.
The \df{transition function} is
\(  \tau\colon\Sigma^{2}\to \Sigma^{2}\times\{-1,1\} \).
A \df{configuration} is a pair \( \xi = (A,\h) = (\xi.\tape,\xi.\pos) \)
where  \( \h\in\bbZ \) is the \df{current} (or \df{observed)}
head position, (between cells \( h \) and \( h+1 \)),
and \( A\in\Sigma^{\bbZ} \) is the \df{tape content}, or \df{tape configuration}:
in cell \( p \), the tape contains the symbol \( A(p) \).
Though the tape alphabet may contain
non-binary symbols, we will restrict input and output to binary.
The tape is blank at all but finitely many positions.

As the head observes the pair of tape cells
with content \( \va=(a_{0},a_{1}) \) at positions \( \h \), \( \h+1 \) denote \(  (\va',d)=\tau(\va)  \).
The transition \( \tau \) will
change tape content at positions \( \h \), \( \h+1 \) to \( a'_{0} \), \( a'_{1} \),
and move the head to tape position to \( \h+d \).
A \df{fault} occurs at time \( t \) if the output \( (\va',d) \)
of the    transition function at this time is replaced with some other value
(which then defines the next configuration).

The machines that occur in simulation will be a generalized version of the above model,
allowing non-adjacent cells and areas called ``disordered''
in which the transition function is non-applicable.
A mere convenience feature is two integer parameters:
the cell body size \( \B\ge 1 \) and and an upper bound \( \Tu\ge 1 \) on the transition time.
These allow placing all the different Turing
machines in a hierarchy of simulations onto the same space line and the same time line.

\begin{definition}[Generalized Turing machine]\label{def:gen-TM}
  A \df{generalized Turing machine} \( M \) is defined by a tuple
  \begin{align}\label{eq:gen-TM}
    (\Sigma, \tau, \B, \Tu, \passno),
  \end{align}
  where \( \Sigma \) is the \df{alphabet}, and
\begin{align*}
  \tau: \Sigma^{2}\times\{\True,False\}\to \Sigma^{2}\times\{-1,1\}  .
\end{align*}
is the \df{transition function}.
In  \( \tau(a,b,\alpha) \) the argument \( \alpha \) is \( \True \) if the pair of observed cells is
adjacent (no gap between them), and \( \False \) otherwise.
Among the elements of the tape alphabet we distinguish the input-output element \( 0,1 \),
a special symbol \( \Vacant \) and a subset \( \New \).
\( \Vacant \) plays the role of a blank symbol (the absence of a cell),
and the state of newly created cells is in \( \New \).

In the definition of tape configurations we will add another symbol: \( \Bad \) will
mark \df{disordered} areas of the tape.
The transition function \( \tau \) has no inputs or outputs that are \( \Bad \) or \( \Vacant \).
Let \( \tau(a,b,\alpha) = (a',b',d) \).
We can have \( a'\in\New \) or \( b'\in\New \) only if \( a,b\not\in\New \) and \( \alpha=\False \),
that is the observed cells are not adjacent.
Even then we can have \( a'\in\New \) only if \( d=-1 \) and \( a'\in\New \) only if \( d=1 \). 
The effect of the transition function on configurations will be explained in
Definition~\ref{def:dictated}.

The integer \( \passno \) will play the role of the number of passes needed to clean an area (see below).
\end{definition}

A formal definition of a configuration of a generalized Turing machine is given in
Section~\ref{sec:gen-TM}, though it is essentially defined by the tape content \( A \) and the head
position.
A point \( p \) is \df{clean} if  \( A(p)\ne\Bad \).
A set of points is \df{clean} if it consists of clean points.
We say that there is a \df{cell} at a position \( p\in\bbZ \) if the interval
\( p+\lint{0}{\B} \) is clean and \( A(p)\ne \Vacant \).
In this case, we call the interval \( p+\lint{0}{\B} \) the \df{body} of this cell.
Cells must be at distance \( \ge\B \) from each other, that is their
bodies must not intersect.
If their bodies are at a distance \( <\B \) from each
other (with a clean interval containing both) then they are called \df{neighbors}.
They are called \df{adjacent} if this distance is \( 0 \).

A sequence of configurations conceivable as a computation will be called a ``history''.
For standard Turing machines, 
the histories that obey the transition function could be called ``trajectories''.
For generalized Turing machines the definition of trajectories is more complex; it
allows some limited violations of the transition function, while providing the mechanisms
for eliminating disorder.
Let \(    \Noise\subseteq \bbZ\times\bbZ_{\ge 0} \)
denote the set of space-time points at which faults occur.
Section~\ref{sec:traj} below will define a certain subset of possible histories
called \df{trajectories}.
In order to motivate their choice, we first introduce the notion of simulation.

 \subsection{Simulation}\label{sec:sim}

 (Here we introduce the notion of simulation used in the proof.
 It relies on the concept of trajectories defined in Section~\ref{sec:traj},
 but also motivates it.)
Until this moment, we used the term ``simulation'' informally, to denote
a correspondence between configurations of
two machines which remains preserved during the computation.
In the formal definition, this correspondence will essentially be a code
\( \varphi=(\varphi_{*},\varphi^{*}) \).
The \emph{decoding} part of the code is the more important.
We want to say that machine \( M_{1} \) simulates machine \( M_{2} \) via
simulation \( \varphi \) if whenever \( (\eta, \Noise) \) is a trajectory of \( M_{1} \) 
then \( (\eta^{*},\Noise^{*}) \),
defined by \( \eta^{*}(\cdot,t)=\varphi^{*}(\eta(\cdot,t)) \), is a
trajectory of \( M_{1} \).
Here, \( \Noise^{*} \) is computed by the residue operation (deleting isolated bursts)
as in Definition~\ref{def:sparsity}.
We will make, however, two refinements.
First, we require the above condition only for
those \( \eta \) for which the initial configuration
 \( \eta(\cdot,0) \) has been obtained by encoding, that is it has the form 
\( \eta(\cdot,0)=\varphi_{*}(\xi) \).
Second, to avoid the transitional ambiguities in a history,
we define the simulation decoding as a mapping \( \Phi^{*} \)
between \emph{histories}, not just configurations:
\( \Phi^{*}(\eta,\Noise)=(\eta^{*},\Noise^{*}) \).

\begin{sloppypar}
\begin{definition}[Simulation] \label{def:simulation-central}
  Let \( M_{1},M_{2} \) be two generalized Turing machines, and let
  \( 
    \varphi_{*}:\Configs_{M_{2}} \to \Configs_{M_{1}} \)
be a mapping from configurations of \( M_{2} \) to those of \( M_{1} \), such that it maps
starting configurations into starting configurations.
Let \(    \Phi^{*}:\Histories_{M_{1}} \to \Histories_{M_{2}} \) be a mapping.
The pair \( (\varphi_{*}, \Phi^{*})  \)
is called a \df{simulation} (of \(  M_{2}  \) by \(  M_{1}  \)) if for every
trajectory \(  (\eta, \Noise)  \) of \( M_{1} \) with initial
configuration \(  \eta(\cdot,0)=\varphi_{*}(\xi)  \),
the history \(  (\eta^{*},\Noise^{*})=\Phi^{*}(\eta,\Noise)  \) is
a trajectory of machine \(  M_{2}  \).
\end{definition}
  \end{sloppypar}

In the noise-free case it is easy to find examples of simulations.
However, in the cases with noise, finding any nontrivial example 
is a challenge, and depends on a careful definition of trajectories for generalized Turing machines.

\subsection{Trajectories}\label{sec:traj}

(This completes the definition of the central concept of the
proof---modulo the natural definitions spelled out in Section~\ref{sec:gen-TM}.)
The set of trajectories of a generalized Turing machine \( M \)
is defined in terms of constraints imposed on the fault-free parts of a history.
We discuss these properties first informally.

\begin{description}
\item[Transition Function] This property says (in more precise terms)
that in a clean area, the transition function is obeyed.

\item[The Spill Bound] limits the extent to which a disordered interval can spread while
the head is in it.

\item[Escape] limits the time for which the head can be trapped in a small area.

\item[Attack Cleaning] erodes disorder as the head repeatedly enters and leaves it.

\item[Pass Cleaning] cleans the interior of an
  interval if the head passes over it enough times.
  
\end{description}

\begin{remark}
The Pass Cleaning property is only used in the proof of the other trajectory properties
(and itself) for the simulated trajectory \( \eta^{*} \).
Without it, it could happen that
the head slides over a large disordered area many times (staying inside) and, occasionally,
extends it by new faults.  
\end{remark}

The definition below depends on the notions of current cell-pair, switch and dwell period given in
 in Section~\ref{sec:gen-TM}, but should be understandable as it is.

\begin{definition}\label{def:dictated}
Suppose that at times \( t' \) before a switching time \( t \) but after 
any previous switch, the current cell-pair \( (x,y) \) has state \( \va = (a,b)\).
Let \( (a',b',d) =\tau(a,b,\alpha) \), where \( \alpha=\True \) if the cell-pair is adjacent and \( \False \)
otherwise.
Let \( u,v \) be the states of the cells \( x,y \) after the transition, and
let \( x',y' \) be the new current cell pair.
We say that the switch is \df{dictated by the transition function} if the following holds.
We state the conditions for \( d=1 \), the case \( d=-1 \) is analogous.
\begin{itemize}
\item \( u=a' \).
  
  \item Suppose \( b'\not\in\New \); then \( v=b' \), \( x'=y \).
    If cell \( y \) has a neighbor \( z \) on the right then \( y'=z \).
    Else a new adjacent neighbor \( z \) is created on the right of \( y \)
    with a state in \( \New \), and again \( y'=z \).

  \item If \( b'\in\New \) (in which case \( \alpha=\False \) and \( x,y \) are not adjacent)
    then \( v=\Vacant \) (cell \( y \) is erased), \( x'=x \), and a cell \( y' \) adjacent to \( x \) on the right
    is created with state \( b' \).
    We will say that cell \( y \) is \df{replaced} with the new cell \( y' \).
\end{itemize}
\end{definition}

As a consequence of this definition, new cells are created
automatically when the head would step onto a vacant area,
and whenever a cell is killed another one is created automatically in a place overlapping with its body.

We will use the following constants:
\begin{align}\label{eq:cns.traj}
  \CSpill =2,\;
  \CMarg = 13,\;
  \CPass = 3\CMarg,\;
  \CEsc = 7.
\end{align},
and we will assume
\begin{align}\label{eq:beta-lb}
  \beta\ge \CPass.
\end{align}

% \begin{definition}
%   For a space-time path \( P \) of the head and an interval \( I \),
% let \( P_{u:v} \) be its part over the time interval \( \lint{u}{v} \).
% We write \( P_{:v} \) for the part from start to \( v \) and \( P_{u:} \)
% for the part from \( u \) to end.
% A part \( P_{u:v} \)
% is a \df{pass} of \( I \) if \( P \) enters \( I \) at time \( u \) and leaves it on the other side
% at time \( v \) (without leaving \( I \) before).
% \end{definition}

 \begin{definition}\label{def:interior}
  For a set \( K \) on the line,  and some real \( c \) let us define its \( c \)-\df{interior}
  \(  \Int(K,c) \) as the set of those points of \( K \) that are at a distance \( \ge c \) from
  its complement.
  For an interval \( K = \lint{a}{b} \), we this is \( \lint{a+c}{b-c} \).
  In this case, will use it also  with negative \( c \); then ``interior'' is really an extended
  neighborhood of \( I \).
 \end{definition}

  In the following definition, it is important to keep in mind the difference between noise and disorder.
  A noise-free space-time rectangle can very well contain disordered areas on the tape.
  
  \begin{definition}[Trajectory]\label{def:traj}
\begin{sloppypar}
   A history  \( (\eta, \Noise) \) of a generalized Turing 
machine~\eqref{eq:gen-TM} with \(\eta(t) =\)
\( (A(t), \h(t), \vhc(t)) \)
is called a \df{trajectory} of \( M \) if the following conditions hold, in any 
noise-free space-time interval \( I\times J \).
  \end{sloppypar}
\begin{description}

\item[Transition Function]\label{i:def.traj.transition}
Consider a switch, where the current cell-pair \( \vhc \)
is inside a clean area, by a distance of at least \( 2.5\B \).
Then the new state of the current cell-pair and
the direction towards the new current head position
are dictated by the transition function.
We further require that if the head moved right and \( \vhc \) has no 
right neighbor cell then a new adjacent right neighbor cell is created.
Similarly in the left direction.

The only change on the tape occurs on the interval enclosing the new and old current cells.
Further, the length of the dwell period before the switch is bounded by \( \Tu \).

\item[Spill Bound]\label{i:spill-bound}
  A clean interval can shrink by at most \( \CSpill \B \) while it does not contain the head.

\item[Escape] \label{i:def.traj.escape}
  The head will leave any interval of size \( \le \lambda\B \) with \( 1\le\lambda\le 3\beta \)
  within time \( \CEsc\lambda^{2}\Tu \).

\begin{sloppypar}
\item[Attack Cleaning] \label{i:def.traj.attack-cleaning}
Suppose that the current cell-pair is at the end of a clean interval \( \lint{a}{b} \) of size
\( \ge (\CMarg+1)\B \), with the head at position \( x \).
Suppose further that the transition function directs the head right.
Then by the time the head comes back to \( x-\CMarg \B \), the clean interval 
extends at least to \( \lint{a}{b+\B/2} \).
Similarly when ``left'' and ``right'' are interchanged.
 \end{sloppypar}

\item[Pass Cleaning]
    Suppose that a path \( P \) makes at least \( \passno \) passes over an interval \( I \)
  of size \( \le\CPass\B \).
  Then at some time during \( P \) the interior \( \Int(I, \CMarg\B) \) of \( I \) becomes clean.

\end{description}
\end{definition}

Recall that we will have a hierarchy of simulations \( M_{1}\to M_{2}\to \dotsm \) where
machine \( M_{k} \) simulates machine \( M_{k+1} \).
Our construction will set \( \passno=8k + O(1) \) for \( M_{k} \).
This can be interpreted as saying that each 8 passes will raise the ``organization level''.

\subsection{Scale-up}

Above, we have set up the conceptual structure of the construction and the proof.
Here are some of the parameters: 

\begin{definition}\label{def:hier-params}
  Let
  \(
   \Q_{k}=c_{1}\cdot 2^{1.2^{k}},\;
   \U_{k} = \Q_{k}^{3}=c_{1}^{3}\cdot 2^{3\cdot 1.2^{k}},\;
   \passno_{k}=8 k + c_{2}
\)
for appropriate constants \( c_{1},c_{2}>0 \).
 These sequences clearly satisfy~\eqref{eq:growth-assumption}, and
 define \( \B_{k}=\B_{1}\prod_{i<k}\Q_{i} \), 
 \( \Tu_{k}=\Tu_{1}\prod_{i<k}\U_{i} \).
\end{definition}

What remains is the definition of the simulation program and the decoding \( \Phi^{*} \),
and the proof that with this
program, the properties of a trajectory \( (\eta,\Noise) \) of machine \( M=M_{k} \) imply
that the history \( \Phi^{*}(\eta,\Noise)=(\eta^{*},\Noise^{*}) \) obeys the same trajectory
requirements on the next level.
The program is described in Sections~\ref{sec:sim-struc}-\ref{sec:healing}.
The most combinatorially complex part of the proof of trajectory properties
is in the key Section~\ref{sec:cleaning}, proving the trajectory properties related to bounding and
eliminating disorder.
Section~\ref{sec:computation} wraps up the proof of the main theorem.
% (Some parts of the paper will get added detail in the final version, but the present version
% leaves no essential question unanswered.)

% \newpage


\section{Some formal details}

We give here some details that were postponed from the overview section.

\subsection{Examples}\label{sec:examples}

The following examples show the difficulties responsible for various complexities of the
construction and proof.
Some of them may not be completely understandable without the details of the following program.
You can skip these examples safely, and return to them later when wondering
about the motivation for some feature.

\begin{example}[Need for zigging]\label{xmp:zig}
  When the head works in a colony of machine \( M_{1} \)
  performing a simulation of a cell of machine \( M_{2} \), it works in sweeps across the colony.
  But a small burst of faults could reverse the head in the middle of a sweep, leaving it uncompleted.
  This way local faults could create non-local inconsistency.

\end{example}

To handle the problem of Example~\ref{xmp:zig}, the head will proceed in zigzags: every
  step advancing the head in the simulation
  is followed by \( \Z \) steps 
  of going backward and forward again (with parameter \( \Z \) chosen appropriately), checking consistency
  (and starting a healing process if necessary).
  This will also enable the head to progress into a large
  disordered area, preventing it from being fooled repeatedly into going away, this way
  solving an even more serious problem.

\begin{example}[Need for feathering]\label{xmp:feather}
  Some big noise can create a number of intervals \( I_{1},I_{2},\dots,I_{n} \)
  consisting of colonies of machine \( M_{1} \), each interval with its own simulated head,
  where the neighboring intervals are in no relation to each other.
  When the head is about to return from the end of \( I_{k} \)
  (never even to zig beyond it, see the discussion after Example~\ref{xmp:zig}),
  a small burst of faults can carry it over to \( I_{k+1} \) where
  the situation may be symmetric: it will continue the simulation that \( I_{k+1} \) is performing.
  (The rightmost colony of \( I_{k} \) and the leftmost colony of \( I_{k+1} \) need not be complete:
  what matters is only that the simulation in \( I_{k} \) would not bring the head beyond its right end,
  and the simulation in \( I_{k+1} \) would not bring the head beyond its left end.)

  The head can be similarly captured to \( I_{k+2} \), then much later back from \( I_{k+1} \) to \( I_{k} \),
  and so on.
  This way the restoration of structure in \( M_{2} \) may be delayed too long.
\end{example}

The device by which we will mitigate the effect of this kind of capturing is another property of the
the movement of the head which will call \df{feathering}:
if the head turns back from a tape cell then next time it must go beyond.
This requires a number of adjustments to the program (see later).

\begin{example}[Two slides over disorder]
  This example shows the possibility for the head to slide twice over disorder without cleaning it.
  
Consider two levels of simulation as outlined in Section~\ref{sec:hier}: 
machine \( M_{1} \) simulates \( M_{2} \) which simulates \( M_{3} \).
The tape of \( M_{1} \) is subdivided into colonies of size \( \Q_{1} \).
A burst of faults on level 1 has size \( O(1) \), while a burst on level 2 has size \( O(\Q_{1}) \).

Suppose that \( M_{1} \) is performing a simulation in colony \( C_{0} \).
An earlier big burst may have created a large interval \( D \) of disorder
on the right of \( C_{0} \), even reaching into \( C_{0} \).
For the moment, let \( C_{0} \) be called a \df{victim} colony.
Assume that the left edge of \( D \) represents the last stage of a transfer operation to the right neighbor 
colony \( C_{0}+Q_{1} \).
When the head, while performing its work in \( C_{0} \), moves close to its right end, a small burst may 
carry it over into \( D \).
There it will be ``captured'', and continue the (unintended) right transfer operation.
This can carry the head, over several successful colony simulations in \( D \), to some
victim colony \( C_{1} \) on the right from which it will be captured to the right similarly.
This can continue over new and new victim colonies \( C_{i} \) (with enough space between them to
allow for new faults to occur), all the way inside the disorder \( D \).
So the \( M_{2} \) cells in \( D \) will fail to simulate \( M_{3} \).

After a while the head may return to the left in \( D \)
(performing the simulations in its colonies).
When it gets at the right end of a victim colony \( C_{i} \), a burst of faults might move it back there.
There is a case when \( C_{i} \) now can just continue its simulation and then send the head
further left: when before the head was captured on its right,
it was in the last stage of simulating a left turn of the head of machine \( M_{2} \).

In summary, a big burst of faults
can create a disordered area \( D \) which can capture the head and on which the head can slide
forward and back without recreating any level of organization beyond the second one.
\end{example}

\begin{example}[Many slides over disorder]\label{xpl:unbounded}
  Let us describe a certain ``organization'' of a disordered area in which an unbounded number of passes
  may be required to restore order.
For some \( n<0 \), let the cells of \( M_{1} \) at positions
\( x_{-\Q_{1}},\dots,x_{n} \), where \( x_{i+1}=x_{i}+\B_{1} \),
represent part of a healthy colony \( C(x_{-\Q_{1}}) \) starting at \( x_{-\Q_{1}} \), where \( x_{n} \)
is the rightmost cell of \( C(x_{-\Q_{1}}) \)
to which the head would come in the last sweep before
the simulation will move to the \emph{left} neighbor colony \( C(x_{-2\Q_{1}}) \).
Let them be followed by cells \( x_{n+1},\dots, x_{\Q_{1}-1},\dots\)
which represent the last sweep of a transfer operation to the \emph{right} neighbor colony \( C(x_{0}) \).
If the head is in cell \( x_{n} \), a burst of faults can transfer it to \( x_{n+1} \).
The cell state of \( M_{2} \) simulated by \( C(x_{-\Q_{1}}) \) need to be in \emph{no relation} to 
the cell state of \( M_{2} \) simulated by \( C(x_{0}) \).
This was a capture of the head by a burst of \( M_{1} \) across the point 0, to the right.

We can repeat the capture scenario, say around points \( i \Q_{1}\Q_{2} \) for \( i=1,2,\dots \),
and this way cells of \( M_{3} \) simulated by \( M_{2} \) (simulated by \( M_{1} \))
can be defined arbitrarily, with no consistency needed between any two neighbors.
(We did not write \( i \Q_{1} \) just in case bursts are not allowed in neighboring colonies.)
In particular, we can define them to implement a \emph{leftward} capture scenario
via level 3 bursts at points \( i \Q_{1}\Q_{2}\Q_{3}\Q_{4} \), allowing to simulate arbitrary cells of \( M_{5} \)
with no consistency requirement between neighbors.
So \( M_{5} \) could again implement a rightward capture scenario, and so on.
In summary, a malicious arrangement of disorder and noise allows \( k \) passes
after which the level of organization is still limited to level \( 2 k + 1 \).
\end{example}

Our construction will ensure that, on the other hand,
\( O(k) \) passes (free of \( k \)-level noise) will restore organization to level \( k \).
This property of the construction will be incorporated into our definition of a generalized
Turing machines as the ``magical'' property~\eqref{i:many-slides} above.

\subsection{Codes}\label{sec:codes}

The input of our computation will be encoded by some error-correcting code,
to defend against the possibility of losing information even at the first reading.

\begin{definition}[Codes]\label{def:codes}
    Let \( \Sigma_{1},\Sigma_{2} \) be two finite alphabets.
    A \df{block code} is given by a positive integer \( \Q \)---called
    the \df{block size}---and a pair of functions
    \begin{align*}
            \psi_{*} :\Sigma_{2}\to\Sigma_{1}^{\Q},
            \quad
            \psi^{*}:\Sigma_{1}^{\Q}\to\Sigma_{2}
    \end{align*}
    with the property \( \psi^{*}(\psi_{*}(x))=x \).
    Here \( \psi_{*} \) is the encoding function (possibly introducing redundancy)
    and \( \psi^{*} \) is the decoding function (possibly correcting errors).
    The code is extended to (finite or infinite) strings by encoding each letter individually:
\begin{align*}
 \psi_{*}(x_{1},\dots,x_{n})=\psi_{*}(x_{1})\dotsm\psi_{*}(x_{n}) .
\end{align*}

\end{definition}

\subsection{Proof of the sparsity lemma}

\begin{proof}[Proof of Lemma~\ref{lem:sparsity}]
  The proof uses slightly more notation than it would if we simply assumed independence
  of faults at different space-time sites, but it is essentially the same.

  Let \( \cE_{k}(\x) \) be the event  \( B(\x,\pair{\B_{k}}{\Tu_{k}})\cap E^{(k)}\neq\emptyset \).
  Let \( \cM=\cM_{k}(\x) \) be the set of minimal sets \( A\subseteq \bbZ\times\bbZ_{+} \)
with  \( A\subseteq E\imp \cE_{k}(\x) \).

  \begin{claim}
    Each set in \( \cM_{k}(\x) \) is contained in \( B(\x,2\gamma(\B_{k},\Tu_{k})) \).
  \end{claim}
  \begin{proof}
    The statement is clearly true for \( k=1 \).
    Suppose it is true for \( k \), let us prove it for \( k+1 \).
    The event \( \cE_{k+1}(\x) \) holds if and only if \( \x\in E \) and there is some point \( \y \)
    in \( E^{(k)}\cap B(\x,\gamma(\B_{k+},\Tu_{k+1}))\setminus B(\x,\beta(\B_{k},\Tu_{k})) \).
    Then by the inductive assumption, \( A\subseteq E \) for some
    set \( A\subseteq B(\y,2\gamma(\B_{k},\Tu_{k})) \),
    with the property \( A\subseteq E\imp \cE_{k}(\y) \).
    Then \( A\cup\{\x\}\subseteq E\imp \cE_{k+1}(\x) \).
    Also 
\begin{align*}
  A\subseteq B(\x,(\gamma\B_{k+1}+2\gamma\B_{k},\gamma\Tu_{k+1}+2\gamma\Tu_{k}))
\subseteq B(\x,2\gamma(\B_{k+1},\Tu_{k+1})),
\end{align*}
since \( \Tu_{k+1}/\Tu_{k}> 2 \), \( \B_{k+1}/\B_{k}> 2 \).
\end{proof}

Let \(  f_{k}(\x)= \sum_{A\in\cM}\eps^{|A|} \).
By the union bound we have \( \Prob(\cE_{k}(x))\le f_{k}(\x) \).

Let \( p_{k}= \eps\cdot 2^{-1.5^{k-1}} \).
We will prove \(   f_{k}(\x) < p_{k} \) by induction.
For \( k=1 \), rectangles \( B(\x_{i},\pair{\B_{1}}{\Tu_{1}}) \) have size \( 1 \), so
by the \( \eps \)-boundedness, \( f_{1}(\x)<\eps \).
 Assume that the statement holds for \( k \), we will prove it for \( k+1 \).

 Suppose \( \y \in E^{(k)}\cap B(\x,\pair{\B_{k+1}}{\Tu_{k+1}}) \).
According to the definition of \( E^{(k)} \),  there is a point
\begin{align}\label{eq:sparse-as}
 \vek{z} \in
 B(\y,\gamma\pair{\B_{k+1}}{\Tu_{k+1}})\cap E^{(k)}\setminus B(\y,\beta\pair{\B_{k}}{\Tu_{k}}).
 \end{align}
Consider a standard partition of space-time into rectangles \(  K_{p}=B(\vek{c}_{p},(\B_{k},\Tu_{k})) \).
Let 
\begin{align*}
       I&=\setOf{p}{K_{p}\cap B(\x,\gamma\pair{\B_{k+1}}{\Tu_{k+1}})\ne\emptyset}.
 \end{align*}
 We are only interested in rectangles \( K_{p} \) with \( p\in I \).
 Let
\begin{align*}
  K'_{p}=B(\vek{c}_{p},((2\gamma+1)\B_{k},(2\gamma+1)\Tu_{k})) .
\end{align*}
If \( K_{i},K_{j} \) are the rectangles in this partition containing \( \y \) and \( \vek{z} \), then
\( K'_{i}\cap K'_{j}=\emptyset \).
This follows from the fact that \( \abs{y_{1} - z_{1}}>\beta\B_{k} \),
\( \abs{y_{2} - z_{2}}>\beta\Tu_{k} \), and \( \beta> 4\gamma \) 
in Definition~\ref{def:sparsity}.
By the above Claim, the event \( \y\in E^{k} \) can be written as
\( \bigcup_{A\in\cM_{k}(\y)}\{A\subseteq E\} \)
where \( A\subseteq B(\y,2\gamma(B_{k},\Tu_{k}))\subseteq K'_{i} \)
for each \( A\in\cM_{k}(\y) \).
Similarly for \( \vek{z} \).
Let \( \cM(i)=\bigcup_{\y\in K_{i}}\cM_{k}(\y) \), then each set \( A\in\cM(i) \) is in \( K'_{i} \).
The disjointness of \( K'_{i} \) and \( K'_{j} \) and the inductive assumption implies
\begin{align}\nonumber
  f_{k+1}(\x) &\le \sum_{i,j\in I, K'_{i}\cap K'_{j}=\emptyset}\sum_{A\in\cM(i),A'\in\cM(j)}\eps^{|A|+|A'|}
   =\sum_{i,j\in I, K'_{i}\cap K'_{j}=\emptyset}f_{k}(\vek{c}_{i})f_{k}(\vek{c}_{j})
  \\\label{eq:sparsity.last-line}&\le |I|^{2}p_{k}^{2} = |I|^{2}\eps^{2} 2^{-1.5^{k}}\cdot 2^{-0.5\cdot 1.5^{k-1}}
       = p_{k+1}\eps |I|^{2}2^{-0.5\cdot 1.5^{k-1}}.
\end{align}
We have  \( |I|\le (2\gamma \Q_{k}+1)(2\gamma\U_{k}+1) \).
Since \( \lim_{k}\frac{\log\U_{k}\Q_{k}}{1.5^k}=0 \), 
the multiplier of \( p_{k+1} \) in~\eqref{eq:sparsity.last-line} is \( \le 1 \) for sufficiently small  \( \eps \).
\end{proof}

\subsection{Configuration, history}\label{sec:gen-TM}

A configuration, as defined below, contains a pair of positions
\( \vhc = (\hc_{0},\hc_{1}) \) called the \df{current cell-pair}:
In difference to the Turing machines of Section~\ref{sec:TM},
the position of the head may not be exactly between the current cells: this allows the model
to fit into the framework where 
a generalized Turing machine \( M^{*} \) is simulated by some (possibly
generalized) Turing machine \( M \).
The head \( h \) of \( M \)---made equal to that of \( M^{*} \)---may
oscillate inside and around the current cell-pair of \( M^{*} \).

\begin{definition}[Configuration]\label{def:config}
    A \df{configuration} \( \xi \) of a generalized Turing machine~\eqref{eq:gen-TM} is a tuple
    \begin{align*}
      (A,\h,\vhc) = (\xi.\tape,\xi.\pos, (\xi.\curcell_{0},\xi.\curcell_{1}))
    \end{align*}
    where \( A:\bbZ\to\Sigma \) is the tape, \( \h \in\bbZ \) is the head position, \( \vhc\in\bbZ^{2} \)
    is the current cell-pair.
    We have \( A(p)=\Vacant \) in all but finitely many positions \( p \).
Whenever the interval \( \h+\lint{-4\B}{4\B} \) is clean the current cell-pair
must be within it.
Let
    \begin{align*}
         \Configs_{M}
    \end{align*}
    denote the set of all possible configurations of a Turing machine \( M \).
\end{definition}

The above definitions can be localized to define a configuration 
over a space interval \( I \) containing the head.

\begin{definition}[History]
For a generalized Turing machine~\eqref{eq:gen-TM}, consider
a sequence \( \eta = \) \( ( \eta(0,\cdot),\) \( \eta(1,\cdot),\) \( \dots) \),
along with a noise set \( \Noise \).
Let \( \h(t)= \eta(t,\cdot).\pos \) be the position of head.

A \df{switching time} is a noise-free time when any part of \( \eta \) other than \( \h(t) \)
changes.
A \df{dwell period} is the interval between any consecutive pair of
switching times with the property that the
space-time rectangle between them and containing the head is clean and noiseless.

The pair \(  (\eta,\Noise) \) will be called a \df{history}
of machine \( M \) if the following conditions hold.
\begin{itemize}
\item \( \abs{\h(t) - \h(t')} \le \abs{t' - t} \).
  
\item In two consecutive configurations, the content \( A(p,t) \) of the positions \( p \)
  not in \( \h(t) + \lint{-2\B}{2\B} \) remains the same.
\item At each noise-free switching time the head is on the new current cell-pair:
  \( \hc_{0}(t)=\h(t) \).
(In particular, when at a switching time a current cell becomes
\( \Vacant \), the head must already be elsewhere.)

\item The length of dwell periods is at most \( \Tu \).

\end{itemize}
The above definition can be localized to define a history \( I\times J \) containing the head.
Let
\begin{align*}
  \Histories_{M}
\end{align*}
denote the set of all possible histories of \( M \).
\end{definition}



\subsection{Hierarchical codes}\label{sec:hier-codes}

Recall the notion of a code in Definition~\ref{def:codes}.

\begin{definition}[Code on configurations]\label{def:configuration-code}
\begin{sloppypar}
 Consider two generalized Turing machines \( M_{1},M_{2} \) with the corresponding
alphabets and transition functions, where \( \B_{2}/\B_{1} \) is an integer denoted \( \Q=\Q_{1} \).
Assume that a block code
\(
   \psi_{*}:\Sigma_{2}\to\Sigma_{1}^{\Q}
\)
is given, with an appropriate decoding function, \( \psi^{*} \).
Symbol \( a\in\Sigma_{2} \), is interpreted as the content of some tape square.
\end{sloppypar}

This block code gives rise to a \df{code on configurations}, that is a pair of functions
    \begin{align*}
        \varphi_{*} :\Configs_{M_{2}} \to \Configs_{M_{1}},
        \quad
        \varphi^{*}:\Configs_{M_{1}} \to \Configs_{M_{2}}
    \end{align*}
    that encodes some (initial) configurations \( \xi \) of \( M_{2} \) into configurations of \( M_{1} \):
    each cell of \( M_{2} \) is encoded into a colony of \( M_{1} \) occupying the same interval.
    Formally, assuming \( \xi.\curcell_{j}=\xi.\pos+(j-1)\B_{2} \), \( j=0,1 \) 
    we set \( \varphi_{*}(\xi).\pos = \xi.\pos \),
    \( \varphi_{*}(\xi).\curcell_{j}= \varphi_{*}(\xi).\pos+(j-1)\B_{2} \),
  and
\begin{align*}
 \varphi_{*}(\xi).\tape(i\B_{2},i\B_{2}+\B_{1}, \dots, (i+1)\B_{2} - \B_{1}) = \psi_{*}(\xi.\tape(i)).
 \end{align*}
 \end{definition}


\begin{definition}[Hierarchical code]\label{def:hierarchical-code}
For \( k\ge 1 \), let \( \Sigma_{k} \) be an alphabet, of a generalized Turing machine \( M_{k} \).
Let \( \Q_{k}=\B_{k+1}/\B_{k} \) be an integer (viewed as colony size), let \( \varphi_{k} \)
be a code on configurations defined by a block code
  \begin{align*}
       \psi_{k}: \Sigma_{k+1}\to \Sigma_{k}^{\Q_{k}}
  \end{align*}
as in Definition~\ref{def:configuration-code}.
The sequence \( (\Sigma_{k},\varphi_{k}) \), (\( k\ge 1) \),  is
called a \df{hierarchical code}.
For this hierarchical code, configuration \( \xi^{1} \) of \( M_{1} \)
is called a \df{hierarchical code configuration} of height \( k \) if a sequence
of configurations \( \xi^{2},\xi^{3},\dots,\xi^{k} \) of \( M_{2},M_{3},\dots,M^{k} \) exists with
\begin{align*}
 \xi^{i}=\varphi_{*i}(\xi^{i+1})
 \end{align*} 
for all \( i \).
If we are also given a sequence of mappings \( \Phi^{*}_{1} \), \( \Phi^{*}_{2} \), \( \dots \) 
such that for each \( i \), the pair \( (\varphi_{i*},\Phi_{i}^{*}) \),
is a simulation of \( M_{i+1} \) by \( M_{i} \) 
then we have a \df{hierarchy of simulations} of height \( k \).
\end{definition}

We will construct a hierarchy of simulations whose height grows during the
computation---by a mechanism to be described later.


\section{Simulation structure}\label{sec:sim-struc}

In what follows we will describe the program of the reliable Turing machine:
a hierarchical simulation in which simultaneously each \( M_{k+1} \) is simulated
by \( M_{k} \), with an added mechanism to
raise the height of the hierarchy when needed.
Most of the time, we will write \( M=M_{k} \),  \( M^{*}=M_{k+1} \).
Ideally, cells will be grouped into colonies of size \( \Q=\B^{*}/\B \).
Simulating one step of \( M^{*} \) takes a sequence of steps of \( M \)
constituting a \df{work period}.
Machine \( M \) will perform the simulation as long as the noise
in which it operates is \( (\beta\pair{\B}{\Tu}, \gamma\pair{\B^{*}}{\Tus}) \)-sparse
(as in Definition~\ref{def:isolation}).
This means, informally, that a burst of noise affects at most \( \beta \) consecutive tape cells,  
and there is at most one burst in any \( \gamma \)  neighboring work periods.
A design goal for the program is to
correct a burst within space much smaller than a colony.

\df{Modes} were introduced in Section~\ref{sec:language}.
Ordinary simulation proceeds in the normal mode. 
To see whether consistency, that is the basic tape pattern
supporting simulation, is broken somewhere, a very local precaution will be taken in each step:
each step will check whether the current cell-pair is allowed in a healthy configuration.
If not then the mode of the current pair will be changed into \df{healing}.
We will also say that \df{alarm} will be called.
On the other hand, the state may enter into \df{rebuilding} mode on some indications that
healing fails.


\subsection{Error-correcting code}\label{sec:coding}

Let us add error-correcting features to the block codes introduced in
Definition~\ref{def:codes}.

\begin{sloppypar}
\begin{definition}[Error-correcting code]\label{def:err-code}
A block code is \( (\beta,t) \)-\df{burst-error-correcting},
if for all \( x\in\Sigma_{2} \), \( y\in\Sigma_{1}^{\Q} \) we
have \( \psi^{*}(y)=x \) whenever \( y \) differs from
\( \psi_{*}(x) \) in at most \( t \) intervals of size \( \le\beta \).
For such a code, we will say that a word \( y\in\Sigma_{1}^{\Q} \) is \( r \)-\df{compliant}
if it differs from a codeword of the code by at most \( r \) intervals of size \( \le\beta \).
\end{definition}
  \end{sloppypar}

\begin{example}[Repetition code]\label{xmp:tripling}
  Suppose that \( \Q\ge 3\beta \) is divisible by 3,
  \( \Sigma_{2}=\Sigma_{1}^{\Q/3} \), \( \psi_{*}(x)=xxx \).
  If \( y=y(1)\dots y(\Q) \), then \( x=\psi^{*}(y) \) is defined by
    \( x(i)=\maj(y(i),y(i+\Q/3),y+2\Q/3) \).
    For all \( \beta\le \Q/3 \), this is a
    \( (\beta,1) \)-burst-error-correcting code.
    If we repeat 5 times instead of 3, we get a \( (\beta,2) \)-burst-error-correcting
    code.
  \end{example}

  \begin{example}[Reed-Solomon code]\label{xmp:Reed-Solomon}
    There are much more efficient such codes than just repetition.
    One, based on the Reed-Solomon code, is outlined in Example 4.6
    of~\cite{GacsSorg01}.
    If each symbol of the code has \( l \) bits then the code can be up to \( 2^{l} \) symbols long.
    Only \( 2 t\beta \) of its symbols need to be redundant in order
    to correct \( t \) faults of length \( \beta \).
  \end{example}

Consider a (generalized) Turing machine 
\( (\Sigma,\tau) \) simulating some Turing machine \( (\Sigma^{*},\tau^{*}) \).
We will assume that the alphabet \( \Sigma^{*} \) is a subset of the set of  binary strings
\( \{0,1\}^{l} \) for some \( l<\Q \).

We will store the coded information in the interior of the colony, since it is more exposed 
to errors near the boundaries.

\begin{definition}\label{def:colony-interior}
Let 
\begin{align*}
  \PadLen 
\end{align*}
be a parameter to be defined later (in Definition~\ref{def:PadLen}).
A cell belongs to the \df{interior} of a colony spanning an interval \( I \)
if it is in \( \Int(I,\PadLen) \) (with the interior as in Definition~\ref{def:interior}).
% The set \( \Int(I,\F)\setminus\Int(I,\PadLen) \) will be called the \df{turn region}.
\end{definition}

Let \( (\upsilon_{*}, \upsilon^{*}) \) be a \( (\beta,2) \)-burst-error-correcting block code
with
\begin{align*}
  \upsilon_{*}: \{0,1\}^{l} \cup \set{\emptyset}
   \to\{0,1\}^{(\Q-2\cdot\PadLen)\B}.
  % \upsilon_{*}: \{0,1\}^{l} \cup \set{\emptyset}
  %  \to\{0,1\}^{Q\B}.
\end{align*}
We could use, for example, the repetition code of Example~\ref{xmp:tripling}.
Other codes are also appropriate, but we require that there are some fixed Turing machines
\( \Encode \) and \( \Decode \) computing them:
 \begin{align*}
   \upsilon_{*}(x)=\Encode(x),\quad 
   \upsilon^{*}(y)=\Decode( y).
 \end{align*}
Also, these programs must work in quadratic time and linear space on a one-tape
Turing machine (as the repetition code certainly does).

Recall that our Turing machine has some special states, among others: \( 0,1,\new_{0},\new_{1} \).
We require that at least some of these, namely \( \new_{0} \) and \( \new_{1} \) have encodings
that are especially simple: so \( \upsilon_{*}(\new_{0}) \) and \( \upsilon_{*}(\new_{1}) \) can be
written down in a single pass of the Turing machine \( M \).

Let us now define the block code \( (\psi_{*}, \psi^{*}) \) used below in the
definition of the configuration code \( (\varphi_{*}, \varphi^{*}) \)  
outlined in Section~\ref{sec:hier-codes}:
\begin{equation}\label{eq:psi}
   \psi_{*}(a)  = 0^{\PadLen}\upsilon_{*}(a)0^{\PadLen}.
\end{equation}
The decoded value \( \psi^{*}(x) \) is obtained by first removing \( \PadLen \)
symbols from both ends of \( x \) to get \( x' \), and then computing \(
\upsilon^{*}(x') \).
% Let us now define the block code \( (\psi_{*}, \psi^{*}) \) used below in the
% definition of the configuration code \( (\varphi_{*}, \varphi^{*}) \)  
% outlined in Section~\ref{sec:hier-codes} will be equal to \( (\upsilon_{*},\upsilon^{*}) \).
 It will be easy to compute the configuration code from \( \psi_{*} \),
once we know what fields there need initialization.

% \section{Specifying a Turing machine}\label{sec:specifying}

% \subsection{Universal Turing machine}\label{sec:UTM}

% We define universal Turing machines in a way that allows for rather general ``programs''.

% \begin{definition}[Standard pairing]
% For a (possibly empty) binary string\\ \( x=x(1)\dotsm x(n) \) let us introduce the map
%  \[
%    \ang{x} = 0^{\abs{x}}1 x,
%  \]
% Now we encode pairs, triples, and so on, of binary strings as follows:
%  \begin{align*}
%         \ang{s,t} &=\ang{s}t,
% \\ \ang{s,t,u} &= \ang{\ang{s,t},u},
%  \end{align*}
% and so on.

% As in~\eqref{eq:Sigma_k}, we will view
% tape symbols as binary strings of a certain length.
% Also, if we write \( \ang{i,u} \) where \( i \) is some number, it is understood
% that the number \( i \) is represented in a standard way by a binary string.
% \end{definition}

% In the main result, we only consider the reliable simulation of a machine that outputs a single symbol.
% But the construction itself uses also machines with longer outputs, so here is a convention.

% \begin{definition}[Computation result, universal machine]
%  Assume that a Turing machine \( M \) starting on binary \( x \),
\( 
 \)
%  halts at some time \( t \) (``halting''' can be defined by any convention, even just writing a blank at position 0).
%  Then the longest (possibly empty) binary string found starting at position
%  1 is called the \df{computation result} \( M(x) \).
% We will write
%  \begin{align*}
%    M(x,y)=M(\ang{x,y}),\quad M(x,y,z)=M(\ang{x,y,z}),
%  \end{align*}
% and so on.

% A Turing machine \( U \) is called \df{universal} among Turing machines with
% binary inputs and outputs, if for every Turing machine \( M \),
% there is a binary string \( p_{M} \) such that for all \( x \) we have
% \( U(p_{M},x)=M(x) \).
% \end{definition}

% Let us introduce a special kind of universal Turing machines, to be
% used in expressing the transition functions of other Turing machines.
% % These are just the Turing machines for which the so-called \( s_{mn} \) theorem
% % of recursion theory holds with \( s(x,y)=\ang{x,y} \).

% \begin{definition}[Flexible universal Turing machine]\label{def:univ-TM}
% A universal Turing machine will be called \df{flexible} if 
% whenever \( p \) has the form \( p=\ang{p',p''} \) then
% \begin{align*}
%  U(p,x)= U(p',\ang{p'',x}).
%  \end{align*}
% % (Even if \( x \) has the form \(x =\ang{x',x''} \), this definition chooses
% % \( U(p',\ang{p'',x}) \) over \( U(\ang{p,x'},x'') \), that is starts with 
% % parsing the first argument.)
% \end{definition}

% On input \( \ang{p,x} \), a flexible machine first checks whether its ``program'' \( p \) 
% has the form \( p=\ang{p',p''} \).
% If yes, then it applies \( p' \) to the pair \( \ang{p'',x} \).
% (Otherwise it just applies \( p \) to \( x \).)
% It is easy to see that there are flexible universal Turing machines.

% \begin{definition}[Transition program]
%   Consider an arbitrary Turing machine \( M \) with alphabet
% \( \Sigma \), and transition function \( \tau \).
% A binary string \( \pi \) will be called a \df{transition program} of \( M \) if
% whenever \( \tau(\va)=(\va',j) \) we have \( U(\pi,\va)=\ang{\va,j} \).
% We will also require that the computation induced by the program makes
% \( O(\abs{\pi}+\abs{a}) \) left-right turns, over a length of tape \( O(\abs{\pi}+\abs{a}) \).
% \end{definition}

% In our simulations of a Turing machine \( M_{2} \) on some other machine \( M_{1} \),
% the transition program of \( M_{2} \) will just provide a way to compute
% the (local) transition function of \( M_{2} \) by the universal machine;
% it does not organize the rest of the simulation.

% \begin{remark}
%  In the construction of universal Turing machines provided by the textbooks
% (though not in the original one given by Turing), the program is generally a string
% encoding a table for the transition function \( \tau \) of the simulated machine \( M \).
% Other types of program are imaginable: some simple transition functions can
% have much simpler programs.
% However, our fixed machine is good enough (similarly to the optimal machine
% for Kolmogorov complexity).
% If some machine \( U' \) simulates \( M \) via a
% very simple program \( q \), then
%  \begin{align*}
%      M(x)=U'(q,x) = U(p_{U'},\ang{q,x}) = U(\ang{p_{U'},q},x),
%  \end{align*}
% so \( U \) simulates this computation via the program \( \ang{p_{U'},q} \).
% \end{remark}

\subsection{Rule language}\label{sec:language}

The generalized Turing machines \( M_{k} \) to be defined
differ only in the parameter \( k \).
We will denote therefore \( M_{k} \) frequently simply by \( M \),
and \( M_{k+1} \), simulated by \( M_{k} \),  by \( M^{*} \).
Similarly we will denote the colony size \( \Q_{k} \) by \( \Q \).

We will describe the transition function
\( \tau_{k}=\tau \)  mostly in an informal way, as procedures of a program,
these descriptions are readily translatable into a set of \df{rules}.
Each rule consists of some (nested) conditional statements,
similar to the ones seen in an ordinary program:
 ``\textbf{if} \textit{condition} \textbf{then} \textit{instruction}
\textbf{else} \textit{instruction}'', 
where the condition is testing values of some fields of the observed cell-pair, and
the instruction can either be elementary, or itself a conditional statement. 
The elementary instructions are an \df{assignment} of a value to a field
of a cell symbol, or a command to move the head.
It will then be possible to write one fixed \emph{interpreter} Turing machine that carries
out these rules, assuming that the whole set of rules is a string and each field is also represented
as a string.

Assignment of value \( x \) to a field \( y \) of the state or cell symbol will
be denoted by \( y \gets x \).
% We will also use some conventions introduced by the C language:
% namely,
% \( x\gets x+1 \) and \( x\gets x-1 \) are abbreviated to \( \increment{x} \) and
% \( \decrement{x} \) respectively.

% Rules can also have parameters, like \( \ruSwing(a,b,u,v) \).
% Since each rule is called only a constant number of times in the whole program,
% the parametrized rule can be simply seen as a shorthand.


\subsection{Fields}\label{sec:fields}

% \begin{sloppypar}
% For the machine \( M \) we are constructing, each tape symbol will 
% be a tuple \( q=(q_{1},q_{2},\dots,q_{k}) \),
% where the individual elements of the tuple will be called \df{fields}, and will
% have symbolic names.
% For example, we will have fields \( \Addr \) and \( \Drift \),
% and may write \( q_{1} \) as \( q.\Addr \) or just \( \Addr \), 
% \( q_{2} \) as \( q.\Drift \) or \( \Drift \), and so on.
% \end{sloppypar}

% The array of values of the same field of the cells will be called a \df{track}.
% Thus, we will talk about the \( \Hold \) track of the tape, carrying the
% \( \Hold \) fields of the cells.
%  Each field of a cell has a possible value
% \( \emptyset \) whose approximate meaning is ``undefined''.

In what follows we describe some of the most important fields we will use in the cells;
others will be introduced later.

A properly formatted configuration of \( M \) splits the tape into blocks of \( \Q \)
consecutive cells called \df{colonies}.
One colony of the tape of the simulating
machine represents one cell of the simulated machine.
The two colonies that correspond to the current cell-pair of the
simulated machine is scanning is called the \df{base colony-pair}.
The formal definition of a colony-pair (as well as some other concepts) must have two
forms: one for the program, based on some field values in cells,
and one for our reasoning about the history.

Sometimes the left base colony will just be called the \df{base colony}.
Most of the computation proceeds over the base colony-pair.
The direction of the simulated head movement, once figured out by the computation,
is called the \df{drift}.
The neighbor colonies of the base colony-pair may not be adjacent, in which case the cells will form
a \df{bridge} between them.
Possible space between neighbor colonies other the base colony-pair will be filled by stem cells (see below).

Here is a description of some of the fields:
\begin{description}
\item[Mode] The present behavior of the computation will be characterized by
a field of the current cell-pair called the \df{mode}:
 \begin{align*}
   \Mode\in\{ \Normal,\Healing, \Rebuilding,\Booting \}.
 \end{align*}
 If its value is \( \Normal \) we will say that the computation is in \df{normal} mode.
 In this case, the machine is engaged in the regular business of simulation.
The \df{healing} mode tries to correct some local fault due to a couple of neighboring
bursts of faults (of size \( \beta \)),
while the \df{rebuilding} mode attempts to restore the colony structure
on the scale of a couple of colonies.
The \df{booting} mode is used for setting up the structure initially and for starting or continuing the
simulation of the Turing machine \( \G \) of the main theorem.

\item[Info] The  \( \Info \) track of a colony of \( M \)
  contains the string that encodes the content of the simulated cell of \( M^{*} \).

\item[Address] The field \( \Addr \)
of the cell shows the position of the cell in its colony:
it takes values in \( \lint{0}{\Q} \).

\item[Drift] The direction in \( \{-1,1\} \) in which the simulated head moves will be recorded on the track
 \( \Drift \).

\item[Sweep] The \( \Sweep \)
  field keeps track of the number of sweeps that the head made during the work period.

\item[Kind] Cells will be designated as belonging to a number of
  possible \df{kinds}, signaled by the field \( \Kind \)
with values \(  \New, \Booting, \Stem, \Member_{0},\Member_{1},\Bridge, \Outer \).
Here is a description of their role.
\begin{itemize}
\item The kind \( \New \) has been discussed before.
\item A cell is of the \( \Booting \) kind if it is on the top level of simulation (see Section~\ref{sec:hier}).

\item Cells of the base colony-pair are of type \( \Member_{0} \) and \( \Member_{1} \) respectively.
  Members of other colonies have the kind \( \Outer \).

\item If the two base colonies are close but not adjacent then there will be \( <\Q \)
  adjacent cells of type \( \Bridge \) between them, extending the left
  base colony towards the right one.
% Field \( \BridgeDir \) has values \( -1,1 \) showing the direction of the bridge.
% If it is \( 1 \) then the bridge is adjacent on the right to a colony and continues (modulo \( \Q \))
% its addresses.
% If it is \( -1 \) then it is doing this towards the left.

\item \( \Stem \) is the kind of cells filling the space in between colonies other than the two base colonies.
  They may not have yet been assigned another role, and their previous role may have been erased.
\end{itemize}

\item[Heal, Rebuild] During healing, some special fields of the state and cell are used,
  treated as subfields of the field \( \Heal \).
In particular, there will be a \( \Heal.\Sweep \) field.
During rebuilding, we will work with subfields of the field \( \Rebuild \).
A cell will be called \df{marked for rebuilding} if \( \Rebuild.\Sweep\ne 0 \).

\end{description}

\begin{remark}
  The \( \Outer \) kind is redundant:
  whether a cell is outer can be computed from its \( \Drift \) and \( \Sweep \) fields.
  But we use it for clarity.
\end{remark}

\subsection{Head movement}\label{sec:sweep}

The global structure of a work period is this:
\begin{description}

\item[Simulation phase]
Compute the new state of the simulated cell-pair, and the simulated direction (called the drift).
Then check the ``meaningfulness'' of the result.

\item[Transfer phase]
  The head moves into the neighbor colony-pair
  in the simulated head direction called drift (creating and destroying bridges if needed).
  Redundancy is used to protect this movement from faults.
\end{description}

During the work period the head sweeps, roughly, back-and-forth between
the ends of the base colony-pair.
The field \( \Sweep \) keeps track of the number of sweeps made within the work period.
This together with the address and kind of the current cell is used by the program to determine
the actions to be performed.

\begin{definition}[Front]\label{def:front}
As the head sweeps in a certain direction, it increases \( \Sweep \) field by 1.
  The last site in which this increase occurred will be called the \df{front}. 
\end{definition}

Globally in a configuration, due to earlier faults, there may be more than one front, but locally
we can talk about ``the'' front without fear of confusion.
The direction of the sweep \( s \) is determined by its parity:
\begin{align*}
  \dir(s)=(-1)^{s + 1}.
\end{align*}

 Bridges between colonies present some extra complication---let us address it.

\begin{definition}[Gaps]\label{def:gaps}
If the bodies of two cells are not adjacent, but are at a distance \( <\B \) then the space
between them is called a \df{small gap}.
We also call a small gap such a space between the bodies of two colonies.
On the other hand, if the distance of the bodies of two colonies is \( >\B \) 
but \( <\Q\B \) then the space between them is called a \df{large gap}.
\end{definition}

A large gap between two colonies will be filled by a bridge when they become a base colony-pair.
A bridge is always extending the left member colony, except in possibly in the two transfer sweeps while
the colony pair is moved.
Building a bridge or making repairs may involve
``killing'' some cells that are in the way and replacing them with new ones, and
may involve the replacement action as in Definition~\ref{def:dictated}.

 Due to the zigging and feathering requirements mentioned in Section~\ref{sec:novelties},
 there will be two kinds of turns: \df{small} turns and \df{big} turns.
 The process uses the parameters
\begin{align}\label{eq:FDef}
 \Z = \passno^{1+\rho},\; \F = \Z\passno^{2+\rho}
\end{align}
with \( \rho>0 \).
The choices will be motivated in Sections~\ref{sec:feathering} and~\ref{sec:pass-cleaning}.

\subsubsection{Zigging}\label{sec:zigging}

A \df{zigzag} movement will be superimposed on sweeping,
so that the head can check the consistency of a few cells around the front.
The process creates a \df{frontier zone} of about \( 2\Z \) cells in both directions around the front,
where \( \Z \) was defined in~\eqref{eq:FDef}.
This interval is marked by the values of the field
\begin{align*}
  \ZigAddr\in\lint{-2\Z}{2\Z}
\end{align*}
which is undefined elsewhere.
Every second step of progress, the head will perform a forward-backward-forward
zigzag checking and updating the zone.
The turns while doing this are \df{small turns} defined in Section~\ref{sec:feathering},
a few more steps (normally at most 2) may be needed to find a turning point.

The counting for zigging can be done locally, in the current cell-pair, counting the number
of steps needed to move away from the front.
For moving back to the front, the counter is not even needed.
% However, a track
% \begin{align*}
%  \frontDist   
%  \end{align*}
%  will show, in the \( \Z/2 \) cells behind the front, the distance to the front.
%  This will be updated in each zig.
%  This will allow recognizing two colliding frontier zones of the rebuilding process,
%  see Section~\ref{sec:rebuilding}.
 
\begin{remarks}\label{rem:zigging-choices}
  \begin{enumerate}
  \item The need for backward zigging was explained in Example~\ref{xmp:zig}.
  \item The forward-zigging property and the frontier zone
    will be used in the proof of Lemma~\ref{lem:pass-clean}.
    We will need to show there that
    in the absence of new noise, after a constant number of passes, a clean interval \( J \)
    of size, say, \( \ge 6\Z\B \) will extend to the right until it reaches
    the end of a colony-pair or of a rebuilding area.
    Forward zigging will prevent any disorder from turning the head back prematurely.
  \item The choice of  \( \Z \) in~\eqref{eq:FDef} will be justified in the same proof; 
    it also (generously) lower-bounds the size of new noise capable of turning back the head.
  \end{enumerate}
\end{remarks}

\subsubsection{Feathering}\label{sec:feathering}

Example~\ref{xmp:feather} above suggest that our Turing machine
should have the property that between two right-to-left turns
on the same point \( x \), it should pass \( x \) at least once (similarly for left-to-right turns).
We will call this property \df{feathering},
referring to the picture of the path of the head in a space-time diagram.
In fact in some cases we will require more:

\begin{definition}\label{def:feathering}
  A Turing machine has the \( c \)-\df{feathering} property for a \( c>0 \), if  after
a right-to-left turn on point \( x \), the next right-to-left turn at a point \( \ge x \)
must be at a point \( \ge x + c\B \), and similarly for left-right turns.  
\end{definition}

 The following example suggests that any computation can be reorganized to accomodate feathering,
at the price of a logarithmic factor in time.

\begin{example}\label{xmp:feathering}
Suppose that, arriving from the left at position 1, the head decides to turn left again.
In repeated instances, it can then turn back at the following sequence of positions:
\begin{align*}
 1, 2, 1, 3, 1, 2, 1, 4, 1, 2, 1, 3, 1, 2, 1, 5, 1, 2, 1, 3, 1, 2, 1, 4, 1, 2, 1, 3, 1, 2, \dots
 \end{align*}
\end{example}

If in the original execution the head turned back \( t \) consecutive
times to the left from position \( p \), then now it will 
turn back from somewhere in a zone of size \( O(\log t) \) to the right of \( p \) in 
each of these times.
(Computing the exact turning point is not necessary.)

Our simulating Turing machine will have two different feathering properties: it will 
obey 1-feathering for all its turns, but on certain kinds of turn called \df{big turn}
will obey \( \F \)-feathering for the parameter \( \F \) defined in~\eqref{eq:FDef}.

To remember a turn, a field
\begin{align*}
 \Turned,
\end{align*}
whose default value is 0, will be set to 1.
Suppose that the head arrives at a cell-pair \( (x,y) \) from the left.
If \( y \) has \( \Turned=1 \) then the head is not allowed to turn left.
If it has \( \Turned=0 \) and the head turns left then \( y \) gets \( \Turned\gets 1 \).
In both cases, \( x \) gets \( \Turned\gets 0 \).

Suppose that the current cell-pair is \( (x,y) \), and
the next step replaces \( y \) by some \( y' \) as in Definition~\ref{def:dictated}. 
Then \( y' \) inherits the \( \Turned \) value of \( y \).

Analogous rules hold when left and right are exchanged.

The set \( \New \) of states will only have two elements, \( \new_{0} \) or \( \new_{1} \), 
where \( \new_{i} \) is a state with field \( \Turned=i \).
When a replacement operation takes place as in Definition~\ref{def:directed}, then
the \( \Turned \) field of the cell being replaced will be inherited by the cell replacing it.

A ``big turn'' (see below)
will be allowed only in a distance at least \( \F \) from the just passed place of a previous
big turn.

\begin{remark}\label{rem:no-kill-on-turn}
As a consequence of the above rule, a cell will \emph{never be killed} just when
the head turned back from it.
\end{remark}

\begin{definition}[Digression]\label{def:digression}
Whenever a turn is postponed since the head is not allowed to turn due to feathering,
the simulation to be carried out by the head is suspended until the head returns.
This is called a \df{digression}.
\end{definition}

\begin{definition}\label{def:PadLen}
Let 
\begin{align}\label{eq:PadLen}
  \PadLen &= 4\F\log\Q.   
\end{align}
For an interval \( I \) containing a colony pair we call the 
the \df{turn region} the set \( \Int(I,-\PadLen)\setminus C \), that is the close
outside neighborhood of \( I \).
\end{definition}

\begin{description}
\item[Small turn]
  Small turns will be done at zigging during normal and healing mode (see later): the head
  will turn back only at a cell with \( \Turned=0 \).
  If one is not found within \( 3\Delta \) steps (where \( \Delta \) is defined in~\eqref{eq:Delta} below)
  then call alarm but still don't turn.
  Such an event will be called \df{small turn starvation}.

  In normal mode, a zigging move is done only after every two steps of moving the front:
  this leaves every second cell with \( \Turned=0 \) in the wake of this movement.

\item[Big turn]
 Big turns will be done during booting, and the ends of normal and rebuilding sweeps.
  Consider for example a right-to-left turn; left-to-right turns are similar.
  It will be attempted at the colony end or the end of a rebuilding area
  at some position \( A_{0} \).
  Due to the organization below and the example above, in all ``normal'' circumstances,
the turn will succeed somewhere in the turn region to the right of
\( A_{0} \), as in Definition~\ref{def:PadLen}.
The front will be carried until to the actual turning place, and then withdrawn back to \( A_{0} \).
The sweep number will increase by 1 only when the head continues left from \( A_{0} \).

Big turns are governed with the help of the following fields:
\begin{align*}
   \leftTurnDist, \rightTurnDist, \bigDigression, \totalBigDigression.
\end{align*}
When attempting a big left turn the head moves right towards the planned position \( A_{0} \).
Let the sequence of the previous left turns be \( A_{1}<A_{2}<\dotsm \).
We can assume \( A_{0}\le A_{1} \), though this is not important.
Between \( A_{i-1} \) and \( A_{i} \) the distance to \( A_{i} \) is in the field \( \leftTurnDist \), where it was set
after the previous left turn from \( A_{i} \).
Let \( x \) be the address of the head.
If before reaching the goal we find
\( x-A_{1}< \Z \), then the head continues to the right of \( A_{1} \) to a distance \( \F \)
from \( A_{1} \), keeping track of this distance in the field \( \bigDigression \) (which was set to 0 at \( A_{1} \)).
If before reaching the goal we find
\( x-A_{2}< \Z \), then the head continues to the right of \( A_{2} \) to a distance \( \F \),
again keeping track of this distance in the field \( \bigDigression \) (reset to 0 at \( A_{2} \)), and so on.
There is also a counter called \( \totalBigDigression \) that is not reset at \( A_{2} \).
If after repetitions of this process, this counter
reaches \( 2\Q \) then the big turn attempt has failed: start (or restart) rebuilding,
set \( \totalBigDigression=1 \) but still don't turn: such an event will be called a \df{big turn starvation}.

When the planned big turn succeeds then on the way back towards the left, \( \leftTurnDist \) is set to the
distance from the new left turn position, while the variables \( \bigDigression,\totalBigDigression \) are reset to 0.
\end{description}

\begin{definition}\label{def:footprint}
  The first \( \Z \) cells on the left of the left turn, with their track \( \leftTurnDist=0 \) to \( \Z \),
  will be called the \df{footprint} of the big left turn.
  Similarly for big right turns.
\end{definition}

Machine \( M \) will have the property that after a fault-free
path passed over a clean interval, both small turns and big turns can happen without too
long digressions.
We give here only an informal argument; formal proof must wait until 
a complete definition of the simulation.
Zigs are by the definition spaced by \( \ge 2 \) cells apart, making sure that the points
with \( \Turned=1 \) are in general at a distance of \( \ge 2 \) apart.
Healing can create only a constant number of segments of \( \Turned=1 \) of size \( \le 3\Delta \)
with \( \Delta \) defined in~\eqref{eq:Delta}.
As for big turns, as indicated in Example~\ref{xmp:feathering} (for \( \F=1 \)),
a big turn attempt will be delayed by at most \( \F \) times the logarithm
of the total number of big turns inside a colony or a rebuild area.

The simulated Turing machine will also have the feathering property,
therefore the simulation will not turn back 
from one and the same colony repeatedly, without having passed it in the meantime.

\begin{sloppypar}
\begin{remark}\label{rem:big-turns}
  The size of the parameter \( \F \) is motivated by the proof of Lemma~\ref{lem:pass-clean}.
  Here is a sketch of the argument (it can be safely skipped now).
   At some time \( t_{0} \) in some interval \( I \)
  we will have clean subintervals \( J_{k}(t_{0}) \), \( k=1,2,\dots \)
  of size \( \ge 6\Z\B \) in which no fault will appear, and which are separated from each other by areas of
  size \( O(\passno^{2}\Z\B)\ll\F\B \).
  For times \( t>t_{0} \) we will track the maximal clean intervals \( J_{k}(t) \) containing
  the middle of \( J_{k}(t_{0}) \).

  Assume that the head passes over \( I \) noiselessly left to right and later
  also noiselessly from right to left.
  If the head moves in a zigging way to the
  right then the Attack Cleaning property will clean out the area between \( J_{i}(t) \) and \( J_{i+1}(t) \),
  joining them.
  This does not happen only in case of a programmed turn
  from the right end of \( J_{i}(t) \), in the course of the simulation or rebuilding.
  But then in the next pair of passes over \( I \), the feathering property implies that
  the programmed turn from the end of \( J_{i}(t) \) is at least a distance \( \F\B \) to the right.
  Our choice of \( \F \) implies that then \( J_{i}(t) \) will be joined to \( J_{i+1}(t) \).
  So two noise-free passes would join all the intervals \( J_{i}(t) \) into a clean area.  
\end{remark}  
\end{sloppypar}

\subsection{Simulation phase}\label{sec:simulation-phase}

The simulation phase, called the \( \Compute \) rule, computes new values for current cell-pair of the
simulated machine \( M^{*} \) represented by the current (base) colony-pair,
and the direction of the move of the head of  \( M^{*} \).
The cell state of \( M^{*} \) will be stored on the track \( \Info \) of the
representing colony.
The move direction of \( M^{*} \) 
will be written into the \( \Drift \) field of \emph{each} cell of the base colony-pair
(so the whole track must be filled with the same symbol \( d\in\{-1,1\} \).

Let
\begin{align}\label{eq:stain}
   \cns{stain} 
\end{align}
be a constant to be specified later.
The rule \( \Compute \) relies on some fixed \( (\cns{stain}\beta, 2) \) burst-error-correcting
code, moreover it expects each of the words found on the \( \Info \) track to be
2-compliant (Definition~\ref{def:err-code}).
There is a rule \( \rul{ComplianceCheck} \) to check whether a word is \( 2 \)-compliant.

The rule \( \Compute \) starts with making sure that the input colonies
are compliant.
Then essentially repeats 3 times
the following \df{stages}: decoding, applying the transition, encoding.
It uses some additional tracks like \( \Work \) for most of the computation.
 The \( \Info \) track will not be modified before all the \( \Hold[j] \) tracks are written.

In more detail:
\begin{enumerate}
\item At the start, the current cell-pair is the left pair of cells of the left
  member of the base colony-pair.
  The \( \Sweep \) values of all cells are maximal.
  Everywhere outside the base colony-pair, the \( \Drift \) values are pointing
  towards it.

\item\label{i:turn-region}
  During the execution of this rule, the head sweeps the base colony-pair.
  The big turns for changing the sweep direction will happen in the turn region outside as in
  Definition~\ref{def:PadLen}.
  If there is no neighboring colony then outer adjacent stem cells will be used, or added as needed.  

\item For \( j=1,\dots,3 \), call \( \rul{ComplianceCheck} \) on the \( \Info \) track of
  both colonies of the pair, and
  write the resulting bit into the \( \fld{Compliant}_{j} \) track of each.
  
  Then pass through each colony of the pair and for each address \( i \),
  if in the cell with this address, the majority
  of \( \fld{Compliant}_{j} \), \( j=1,\dots,3 \) is false, then turn this cell
  into the \( i \)th cell of the colony representing the state \( \new_{0} \).
  Recall that in Section~\ref{sec:coding}, we required that the codes of the
  states \( \new_{i} \), \( i=0,1 \) are simple enough so that they can be written in a single pass.

  (We could have used any other state instead of \( \new_{0} \) here: just some simple default
  state is needed.)

\item For \( j=1,\dots,3 \)       % Why was here 5 times instead of 3?
  % if \( \Addr \in \set{0, \dots, \Q-1} \)
  do 
  \begin{enumerate}
    
  \item Calling by \( \va \) the pair of strings found on the \( \Info \) track of
    the interiors \( \Int(C,\PadLen) \) of the base colonies \( C \),
    decode it into the pair of strings \( \tilde\va=\upsilon^{*}(\va) \)
    (the current state of the simulated cell-pair), and
    store it on some auxiliary track in the base colony-pair.
    Do this by computing \( \tilde\va = \Decode(\va) \)
    on some simulated universal Turing machine.

    Each cell stores a track segment of the tape of the machine for \( \Decode \).
    When the head of \( M \) is on the cell with the simulated head of \( \Decode \)---let us
    call this the \df{head segment}---then
    one step of \( M \) simulates a number of  steps of \( \Decode \) as large as the size of this
    segment or until the simulated head leaves the segment (thus changing the head segment).

    For simplicity of analysis, each pair of sweeps
    changes only the head segment (and possibly the neighbor that becomes the new head segment).
    We accept this slowdown now.
    
  \item \label{i:comp.trans}
    Compute \( (\va',d)=\tau^{*}(\tilde\va,\alpha) \),
    where \( \alpha=\True \) if the pair of colonies is adjacent, else \( \False \).
    Since the program of the transition function \( \tau^{*} \) is not written explicitly anywhere, 
    this ``self-simulation'' step is discussed in detail in Section~\ref{sec:self-simulation}.
    
  \item\label{i:comp.write}
    Write the encoded new cell states \( \upsilon_{*}(\va') \) onto the
    \( \Hold[j].\Info \) track of the interior of the base colony-pair.
    Write \( d \) into the \( \Hold[j].\Drift \) field of \emph{each cell} of
    the left base colony.

    A field called \( \Replace \) is used.
    Its value can be undefined, or an element of the set \( \New \).
    If one of the new states of the simulated cell pair belongs to \( \New \)
    (that is, the rules dictate a replacement,
    as in Definition~\ref{def:dictated}), then write it onto the \( \Hold[j].\Replace \) track
    everywhere; else the values on the track will be undefined.
    There is enough capacity in a cell to record this value of a simulated cell
    (which can have many more states),
    since the set \( \New \) has only two possible elements in \( M^{*} \) as well as \( M \).
  \end{enumerate}

\item\label{i:vote}
  % \item Repeat the following twice (hoping that at least
  %   one repetition will be burst-free):  % Why twice?
  Sweeping through the base colony-pair,
  at each cell compute the majority of \( \Hold[j].\Info \), \( j=1,\dots,3 \),
  and write it into the field \( \Info \).
  Proceed similarly, and simultaneously, with \( \Drift \) and \( \Replace \).
  
\item\label{i:trickle-down} If the \( \Output \) field of the simulated cell is defined, write it
  into the output field of the left end-cell of each colony.
   
\end{enumerate}

The transfer phase (see Section~\ref{sec:transfer})
will use the information in the \( \Hold_{j}.\Replace \) fields.

Part~\ref{i:trickle-down} achieves that when the computation finishes on some
simulated machine \( M_{k} \),
its output value in cell 0 of \( M_{k} \) will ``trickle down'' to the output field of  cell 0 of \( M_{1} \),
as needed in Theorem~\ref{thm:main}.

As seen in this construction one can find a constant \( \CRedund \) with the property
\begin{align}\label{eq:redund}
    s_{k+1}\le\Q_{k}s_{k}\le \CRedund s_{k+1}
\end{align}
(see the definition of \( s_{k} \) in~\eqref{eq:Sigma_k}),
that is a colony of \( M_{k} \) represents a cell of \( M_{k+1} \) with redundancy
factor \( \CRedund \).
The number of steps \( \U_{k} \) taken by \( M_{k} \) needed for one work period
of simulation is \( O(\Q_{k}^{2}) \).

\begin{remark}
  There is a mechanism more economical on storage, without the full-width
  \( \Work \) and \( \Hold[j] \) tracks but with some
  added complexity, see Section~\ref{sec:redundancy}.
  This allows a space redundancy factor \( 1+\delta_{k} \) with \( \prod_{k}(1+\delta_{k})<\infty \),
  yielding a constant space redundancy factor for the whole hierarchy.
\end{remark}


\subsection{Self-simulation}\label{sec:self-simulation}

Let us elaborate step~\ref{i:comp.trans} of Section~\ref{sec:simulation-phase}.

\subsubsection{New primitives}

The simulation phase makes use of the track \( \Work \) mentioned above, and the track
\begin{align*}
   \Index
 \end{align*}
that can store a certain address of a colony.

Recall from Section~\ref{sec:language} that the program
of our machine is a list of nested
``\textbf{if} \emph{condition} \textbf{then} \emph{instruction}
\textbf{else} \emph{instruction}''
statements.
As such, it can be represented as a binary string 
 \begin{align*}
   R.
 \end{align*}
If one writes out all details of the construction of the present paper, this string \( R \)
becomes explicit, an absolute constant.
But in the reasoning below, we treat it as a parameter.

Let us provide a couple of \df{extra primitives} to the rules.
First, they have access to the parameter \( k \) of machine \( M=M_{k} \), 
to define the transition function
 \begin{align*}
            \tau_{R,k}(\va).
 \end{align*}
The other, more important, new primitive is a special instruction
 \begin{align*}
   \WriteProgramBit
 \end{align*}
in the rules.
When called, this instruction makes the assignment \( \Work\gets R(\Index) \).
This is the key to self-simulation: \emph{the program has
access to its own bits}.
If \( \Index=i \) then it writes \( R(i) \) onto the current position of the \( \Work \) track.


\subsubsection{Simulating the rules}

The structure of all rules is simple enough that they can be read and
interpreted by a Turing machine in reasonable time:

\begin{theorem}
There is a Turing machine \( \Interpr \) with the property that for
all positive integers \( k \), string \( R \) that is a
sequence of rules, and a pair of bit strings \( \va=(a_{0},a_{1}) \) with \( a_{j}\in\Sigma_{k} \),
 \begin{align*}
  \Interpr(R,0^{k},\va)=\tau_{R,k}(\va).
 \end{align*}
The computation on \( \Interpr \) takes time \( O(\abs{R}\cdot \abs{\va}) \).
\end{theorem}

The proof parses and implements the rules in the string \( R \); each of these rules
checks and writes a constant number of fields.

Implementing the \( \WriteProgramBit \) instruction is straightforward:
Machine \( \Interpr \) determines the number \( i \)
represented by the simulated \( \Index \) field, 
looks up \( R(i) \) in \( R \), and writes it into the simulated \( \Work \) field.

There is no circularity in these definitions:
  \begin{itemize}
  \item 
The instruction \( \WriteProgramBit \) is written \emph{literally}
in \( R \) in the appropriate place, as ``\(\WriteProgramBit \)''.
The string \( R \) is \emph{not part} of the rules (that is of itself).  
  \item On the other hand, the computation in
\( \Interpr(R,0^{k},\va) \) 
has \emph{explicit} access to the string \( R \) as one of the inputs.
  \end{itemize}

Let us show the computation step invoking the ``self-simulation'' in detail.
In the earlier outline, step~\ref{i:comp.trans} of Section~\ref{sec:simulation-phase}
said to compute \( \tau^{*}(\tilde\va) \)
(for the present discussion, we will just consider computing 
\( \tau^{*}(\va)=\tau_{k+1}(\va) \)), where \( \tau=\tau_{k} \),
and it is assumed that \( \va \) is available on an appropriate auxiliary track.
We give more detail now of how to implement this step:

\begin{enumerate}
\item Onto the \( \Work \) track, write the string \( R \).
To do this, for \( \Index \) running from 1 to \( \abs{R} \), 
execute the instruction \( \WriteProgramBit \) and move right.
Now, on the \( \Work  \) track, add \( 0^{k+1} \) and \( \va \).
String \( 0^{k+1} \) can be written since the parameter \( k \) is available.
String \( \va \) is available on the track where it is stored.
\begin{sloppypar}
 \item Simulate the machine \( \Interpr \) on track \( \Work \), computing
   \( \tau_{R,k+1}(\va) \).  
\end{sloppypar}
\end{enumerate}

This implements the forced self-simulation.
Note what we achieved:

\begin{itemize}
  \begin{sloppypar}
\item On level 1, the transition function \( \tau_{R,1}(\va) \) is defined completely
when the rule string \( R \) is given.
It has the forced simulation property by definition, and
string \( R \) is \emph{``hard-wired''} into it in the following way.
If \( (\va',d)=\tau_{R,1}(\va) \), then
\begin{align*}
  a'_{0}.\Work\gets R(a_{0}.\Index)
\end{align*}
whenever \( a_{0}.\Index \) represents a number between 1 and \( \abs{R} \),
and the values \( a_{0}.\Sweep \), \( a_{0}.\Addr \) satisfy the conditions
under which the instruction \( \WriteProgramBit \) is 
called in the rules (written in \( R \)).
      \end{sloppypar}

      \begin{sloppypar}
\item The forced simulation property of the \emph{simulated}
transition function \( \tau_{R,k+1}(\cdot) \) is 
achieved by the above defined computation 
step---which relies on the forced simulation property of \( \tau_{R,k}(\cdot) \).
              \end{sloppypar}
\end{itemize}

\begin{remark}
  This construction resembles the proof of Kleene's fixed-point theorem, and even more
  some self-reproducing programs (like a program \( p \) in the language C causing the computer
  to write out the string \( p \)).
\end{remark}

\subsection{Transfer phase}\label{sec:transfer}

Before the transfer phase, members of the base colony-pair \( C_{0},C_{1} \) have
cells of kind \( \Member_{0} \) and \( \Member_{1} \) correspondingly,
with a possible bridge between them.
Now the \( \Transfer \) rule takes over: control will be transferred to the
neighbor colony-pair in the direction of the simulated head movement which we called 
the \df{drift}.
During this phase, the range of the head includes the base colony-pair and a neighbor colony
in the direction of the drift called \df{target colony}, including possible bridges between them.
At the beginning of the phase, the current cell-pair is the first cell-pair of \( C_{0} \).
Big turns happen in the turn region as in part~\ref{i:turn-region} of the
description of the \( \Compute \) rule.

Consider \( \Drift=1 \).
In what follows, whenever the majority of \( \Hold[j].\Replace \), \( j=1,\dots,3 \) is observed
in a cell then we will say that this is a \df{replacement} situation.

\begin{enumerate}
\item \label{i:target}
  Suppose that we don't have a replacement situation.
  In the first sweep, the head will travel right.
  Turn all elements of \( C_{0} \) into outer cells,
  rebuild the bridge between \( C_{0} \) and \( C_{1} \) if necessary, to point from \( C_{0} \) to \( C_{1} \),
  and turn the elements of \( C_{1} \) into \( \Member_{0} \) cells.
  Then continue to the right, start a bridge (if necessary) towards the right
  (killing all possible non-adjacent stem cells in the way).
  If the right end of the bridge reaches an outer colony \( C_{2} \)
  before \( Q \) bridge cells are created, then pass to the right edge of \( C_{2} \).
  If \( Q \) bridge cells were created, stop at the right edge of this bridge---call it now \( C_{2} \).
  Then sweep back to the left end of  \( C_{1} \), while turning the cells of \( C_{2} \) to 
  kind \( \Member_{1} \).

  In both cases, actually go to a distance \( 3\F\log \Q \) from the right end of \( C_{2} \)
  before attempting to turn.
  (This way, all later attempted left turns in the next work period
  will happen to the left of this one, and so any possible cause for alarm is encountered
  already now, in the transfer process.)

\item\label{i:replace}
  In the replacement situation, build a new colony \( C'_{1} \) adjacent on the right to \( C_{0} \).
  In the first sweep, perpetuate the value \( r \) found on the \( \Replace \) track.
  Write onto the  \( \Info \) track of \( C'_{1} \) the encoding of the value \( r \).
  (This requires two steps for each created cell \( x_{i} \) of \( C'_{0} \):
  first it has value \( r\in\New \), then it gets address \( i \), and its \( \Info \) field
  gets the \( i \)th symbol of the encoding of \( r \).)
  Then continue to the end of \( C_{1} \).
  On the way back, replace the remaining elements of \( C_{1} \) with stem cells
  and set the kind of elements of \( C'_{1} \) to \( \Member_{1} \).

\end{enumerate}

A similar program is executed when \( \Drift=-1 \).
The values of \( \Drift \), \( \Replace \), \( \Sweep \) and \( \Addr \) always determine what step
to perform.
  
  The continuous fault-checking during zigging will notice
when a small burst of faults compromises this process (for example when the end of a bridge would
``bite'' into another colony), by checking whether all boundaries it finds are legal (see the definition of
health in Section~\ref{sec:health}) and trigger healing (see later).

\subsection{Booting}\label{sec:booting}

Ideally, the work of machine \( M \) starts from a single active cell-pair of the Booting kind,
with addresses \( \Q-1 \) and 0, the middle cell-pair of a yet to be built colony-pair.
The \( \Rider \) track of the cell-pair holds a tape segment of the simulated Turing machine \( \G \),
along with the simulated head.
Such a cell-pair will be called a \df{booting pair}.
The segment consisting of this cell-pair will be extended left-right by booting cells,
eventually creating a colony-pair, as follows.

\begin{description}
  \item[Main work]
Machine \( M \) performs \( \Q \) times the following:
\begin{itemize}
\item[] 
  Simulate \( \G \) in the active pair on the \( \Rider \) track
  for at most as many steps as the size of the represented
  tape segment of \( \G \), possibly stopping earlier if the represented head would exit that
  segment earlier.
  Move the active pair of \( M \) left or right as needed,
  adding cells to the representing segment, and giving them the appropriate addresses of their colonies.
  All new cells encountered must be stem cells (blanks), and all the ones in the segment already created
  must be of the Booting kind; otherwise call alarm.

  In all this, use zigging and feathering.
  Zigging uses small turns just as during simulation, but 
  whenever a turn of \( \G \) is simulated, \emph{make a big turn}
  (as defined in Section~\ref{sec:feathering}), with the necessary
  digressions (see Definition~\ref{def:digression}).
  When the active pair does not need moving, treat this as (say) a left turn from the
  point of view of feathering, making the necessary marking and digression.
  The simulation is continued only after the head returns to the active cell-pair from the digression.
  
\end{itemize}
\item[Output]
If the simulated computation of \( \G \) terminates (the \( \Output \)
field of simulated cell 0 of \( \G \) is written)
then write the same value to the \( \Output \) field of cell 0.
\item[Lifting]
  If the \( \Q \) steps of \( M \) are completed without the termination of the simulated
  \( \G \) computation, then
  create the colony-pair around the original pair of booting cells (and turn its cells into member cells).
 \df{Lift} (copy) the \( \Rider \) track of its cells into
  the \( \Rider \) track of the cell-pair simulated by it.
  Set the mode of the simulated cell-pair to \( \Booting \).
\end{description}

The only error-control during all this is the step counting (the cells are big enough
to carry a counter up to \( \Q \)), zigging, and the call of alarm mentioned in the main work above.
This serves to notice when booting cells were introduced by a fault
into a non-booting situation.
We introduce no mechanism to correct faults during the booting phase, since
we do not expect faults
during it---see the probability analysis in Section~\ref{sec:fault-estimation}.


\section{Healing and rebuilding}\label{sec:healing}

Here we define the part of the simulation program that
corrects configurations of machine \( M \) that are ``almost'' healthy.

\subsection{Health}            \label{sec:health}

\df{Health} is that part of structural integrity that can be checked locally,
and repaired locally provided it was damaged locally.
Structure is maintained with the help of a small number of fields.
The required relations among them 
allow the identification and correction of local damage.

\begin{definition}\label{def:domains}
The tuple of fields
\begin{align*}
   \Core =(\Kind,\Drift,\Replace,\Addr,\Sweep,\Rebuild.\Sweep)
 \end{align*}
 is called the \df{core}.
 Recall that a cell is said to \df{marked for rebuilding} if \( \Rebuild.\Sweep>0 \).

 An interval of non-stem adjacent neighbor cells is a \df{homogenous domain} if
 its core variables with the exception of \( \Addr \) have the same value, and
 \( \Addr \) increases left to right.
The \df{left end} of a domain is the left edge of its first cell, and its \df{right end} is 
the right edge of its last cell.
A \df{left boundary} the left end of a homogenous domain with either no left neighbor cell
or with a neighbor cell belonging to another homogenous domain.
Right boundaries are defined similarly.
\end{definition}

Health can be defined formally on the basis of the informal descriptions given here,
but the details would be tedious.
Recall Definition~\ref{def:front} of the front.

\begin{itemize}
\item   A configuration consists of intervals of non-stem neighbor cells,
  with possibly stem cells between them.
  The health for each of these intervals is defined locally.
  No cell is marked for rebuilding, that is \( \Rebuild.\Sweep=0 \).

  As a non-local condition we will require that exactly one of these intervals contains
  the front: let us call this the \df{principal interval},
  and that the drift in all other intervals is directed towards the principal one.
 
\item  In the principal interval
  there is a base colony-pair, with possibly a bridge going from one member of the pair
  to the other one.
  Let \( I \) denote the interval containing this pair.
  If the sweep inside this colony-pair shows that the \( \Compute \) rule is being performed then
  the only sweep boundary allowed inside is the front.
  All other sweep boundaries are outside \( I \), in the turn region as in Definition~\ref{def:PadLen}.

\item During the \( \Compute \) phase,
  outside the base colony-pair (both in the principal interval and elsewhere),
  all non-stem cells have their \( \Drift \) value directed towards the base colony-pair.
  There are possibly colonies of type \( \Outer \) adjacent to it and each other.
  They are called \df{left outer} colonies and their cells left outer cells, or
  \df{right outer} colonies depending on whether their drift is \( +1 \) or \( -1 \).
  Stem cells are also called outer cells (both left and right).

  In part~\ref{i:vote} of this phase, the values of \( \Drift \) and \( \Replace \) can change at the front.
  
\item  During transfer, the base colony (of the pair)
  that is in the direction of the drift is possibly extended by a bridge towards the target colony.
  At this point there is no other bridge, and the front is at the tip of the new bridge.
  
  In the later part of this sweep, the new bridge already reaches the target colony.
  If the bridge extends to a full colony then this is converted to the appropriate kinds of member
  cells in the backward sweep.
  Domains ahead and behind the front show the changes done.
  Another possible change occurring at the front is replacement, when dictated by the \( \Replace \) track.
  In this case the front has the property that, for example when replacing a colony in the right direction,
  for each member cell created to replace an old member cell, \emph{the address of the new cell is not
  larger than the address of the one it replaces}.
  
\end{itemize}

\begin{definition}\label{def:legal-boundary}
  Let us call a bondary \df{legal} if it can occur in a healthy configuration.
\end{definition}

The following lemma shows that health of an interval of non-stem neighbor cells
is locally checkable.
 
\begin{lemma}
  If an interval of neighbor cells in a tape configuration
  has only legal boundaries (including those at its ends) then it is healthy.
\end{lemma}
\begin{proof}
  In what follows we don't repeat it but each statement is forced by the kind of boundaries
  allowed.
  There are only two basic kinds: a colony boundary and the front, and what matters is the values of
  the \( \Core \) variables in the cell pair around the boundary.

  \begin{enumerate}
\item Consider an interval \( I \) of neighbor cells.
  If  \( I \) contains cells that are not outer, or it contains both left and right outer cells
  then it also contains the front.

\item Assume that \( I \) contains only left outer cells.
  Then these consist of colonies possibly separated by stem cells, with drift pointing to the right,
  and possibly a front in a right turn region.
 The situation is similar when \( I \) consists of right outer cells.

In all other cases \( I \)
also contains an interval \( K \) consisting of neighbor non-outer cells.
  
\item Let \( s \) be the maximum sweep found in \( K \).
  If \( s \) is in the computing phase then \( K \) consists
  of a base colony-pair with a possible inner bridge connecting it.
  The only possible boundaries inside are a front and the colony boundaries.
  Turn boundaries are outside it.

\item Suppose now that \( s \) is in the transfer phase: then the 
  the drift over \( K \) is constant.
  Suppose that, for example, \( \Drift=1 \).
  Look at the description of the transfer phase in Section~\ref{sec:transfer}.
  Depending on whether we are in a replacement situation (defined by the \( \Replace \) track)
  and whether the we are in the first or second sweep, the boundary at the front completely
  determines the possibilities.
  The restriction on the addresses mentioned above makes sure 
  that there is enough space for the replacement to succeed.
  \end{enumerate}
\end{proof}

The following lemma is an immediate consequence, given that health is defined by boundaries:

\begin{lemma}\label{lem:health-extension}
  Let \( \xi \) be a tape configuration that is healthy on intervals \( A_{1}, A_{2} \) 
where \( A_{1}\cap A_{2} \) contains a whole cell body of \( \xi \).
Then \( \xi \) is also healthy on \( A_{1}\cup A_{2} \).
\end{lemma}

% \begin{premark}
% Pictures!  
% \end{premark}

\begin{lemma}\label{lem:3-boundaries}
  In a healthy tape configuration, over any interval of size \( <\Q\B \) there are at most three boundaries between
  domains.
\end{lemma}
\begin{proof}
  Two colony-ends can be closer than \( \Q\B \) to each other in case of a big gap between
  two neighbor colonies.
  These and possibly the front can amount to three boundaries.
\end{proof}

In a healthy configuration, the possibilities of finding non-adjacent neighbor
cells are limited.

\begin{lemma}\label{lem:two-domains}
  An interval of size \( <\Q \) over which the configuration \( \xi \) is healthy
contains at most two maximal sequences of adjacent non-stem neighbor cells.
\end{lemma}
\begin{proof}
  By definition a healthy configuration consists of intervals covered by
  full colonies connected possibly by bridges, and possibly stem cells between these intervals.
An interval of size \( <\Q \) contains sequences of adjacent cells 
from at most two such intervals.
\end{proof}

\begin{lemma}\label{lem:infer-between}
In a healthy configuration, 
a cell's state shows whether it is an outer cell, and also its direction towards the front.
The \( \Core \) track of a homogenous domain can be reconstructed from any of its cells.
\end{lemma}
\begin{proof}
Whether a cell is outer is computed from some fields.
If the cell is outer then \( \Drift \) shows its direction from the front,
else the parity of \( \Sweep \) shows it.
For booting cells, the number of simulation steps performed increases towards the front.
\end{proof}


\subsection{Stitching}\label{sec:stitching}

We will show that a configuration admissible over an interval of size \( >\Q\B/2 \)
can be locally corrected;
moreover, in case the configuration is clean, this correction
can be carried out by the machine \( M \) itself.

\begin{definition}[Substantial domains]\label{def:substantial}
Let \( \xi(A) \) be a tape configuration over an interval \( A \).
A homogenous domain of size at least \( 4\cns{stain}\beta\B \) will be called \df{substantial}.
The area between two neighboring maximal
substantial domains or between an end of \( A \) and the closest substantial domain in \( A \)
will be called \df{ambiguous}.
It is \df{terminal} if it contains an end of \( A \).
Let
 \begin{align}\label{eq:Delta}
     \Delta &= 24\cns{stain}\beta. 
 \end{align}
\end{definition}

Later, in Section~\ref{sec:annotation}, we will introduce the notion of \df{islands}: intervals
of size \( \le\cns{stain}\beta\B \) with the property that if the configuration is changed in the
islands it becomes healthy.
Under normal circumstances, there will be at most 3 islands in any interval of size \( \Q\B \).
 The size of a substantial domain assures that at least one of its cells is
outside an island, since even three neighboring islands have a
total size \( \le 3\cns{stain}\B \).

\begin{lemma}\label{lem:ambiguous}
In an admissible configuration, each half of a 
a substantial domain contains at least one cell outside the islands.
If an interval of size \( \le  \Q\B \) of a tape configuration \( \xi \) differs from a  healthy tape 
configuration \( \chi \) in at most three islands, then 
the size of each ambiguous area is at most \( \Delta\B \).
\end{lemma}
\begin{proof}
The first statement is immediate from the definition of substantial domains.
By Lemma~\ref{lem:3-boundaries}, there are at most 3 boundaries in \( \chi \).
There are at most 3 islands.
Between islands and boundaries there are at most 5 non-substantial domains: of sizes
\( < 4\cns{stain}\beta\B \).
The islands have a total size \( <3\cns{stain}\beta\B \) and the space between boundaries may add at
most \( 3\B \).
Adding all these up we get \( \B(20\cns{stain}\beta + 3\cns{stain}\beta + 3) < 24\cns{stain}\beta\B \).
\end{proof}

The following lemma forms the basis of the healing algorithm.

\begin{lemma}[Stitching]\label{lem:stitching}
In an admissible configuration, inside a clean interval,
let \( U,W \) be two substantial domains separated by an ambiguous area \( V \).
It is possible to change the tape on \( U,V,W \) using only information in \( U,W \) in such a 
way that the tape configuration over \( U\cup V\cup W \) becomes healthy.
Moreover, it is possible for a Turing machine to do so gradually, extending,
and changing the tape in \( U \) or \( W \) or enlarging \( U \) or \( W \)
gradually at the expense of \( V \).

The machine in question can make its turns via
``small turns'' as defined in Section~\ref{sec:sweep}.
\end{lemma}
\begin{Proof}
  At any step below, if we find that \( U\cup V\cup W \) is healthy then we stop.

\begin{step+}{step:stitching.colonies}
  If \( U \) consists of colony cells then let it be extended towards \( V \) until a colony boundary or \( W \)
  is hit.
  Then do the same with \( W \).
  If \( V \) gets eliminated then the boundary-pair
  between \( U \) and \( W \) is necessarily a legal one.
\end{step+}
Assume now that the above operations have still left \( V \).

\begin{step+}{step:stitching.1-colony}
  If for example \( U \) consists of colony cells but \( W \) does not, then extend \( W \) towards \( U \)
  until \( V \) is erased: the boundary obtained must be legal.
\end{step+}

\begin{step+}{step:stitching.2-colonies}
Assume that both \( U \) and \( V \) consist of colony cells.
\end{step+}
\begin{prooof}
  If both colonies are outer then we can turn all elements of \( V \) into stem cells.
  This situation will not be actually encountered since the front is never near the boundary between
  two outer colonies.

  If both colonies are inner then turn the cells between them into a bridge from \( U \) to \( V \).
  Continue into it the sweep from \( U \) (this is an arbitrary choice).

  If for example \( U \) is inner and \( W \) is outer then, if the sweep is not the transfer sweep
  towards \( W \) then we fill \( V \) with stem cells; else
  we fill \( V \) with bridge cells extending \( U \).
  In both cases we extend the sweep of \( U \) into \( V \).
\end{prooof} % step:stitching.2-colonies

\begin{step+}{step:non-colony}
  The case remains when neither \( U \) nor \( V \) consist of colony cells.
\end{step+}
\begin{prooof}
  If one of them consists of stem cells then extend it (does not matter which)
  towards the other until they meet.
  If both consist of bridge cells then extend either one of them towards the other until they meet.
  We will always end up with a legal boundary.
\end{prooof} % step:stitching.non-colony
\end{Proof}


\subsection{The healing procedure}\label{sec:healing-proc}

The healing and rebuilding procedures look as if we assumed no noise or disorder.
The rules described here, however (as will be proved later), will also clean an area locally under the 
appropriate conditions.

Healing performs only local repairs of the structure: for a given (locally) admissible configuration,
it will attempt to compute a satisfying (locally) healthy configuration.
If it fails---having encountered an inadmissible configuration---then
the rebuilding procedure is called, which is designed to repair a larger interval.

To protect from noise, any one call of the healing procedure will change only 
a small part of the tape, essentially one cell: so a noise burst during healing
will have limited impact.
Every healing operation starts with a survey on a certain interval around its starting point,
an illegal boundary called the \df{center}.
If it still finds healing to do then it performs one step of it, and then leaves a trace:
adds to an interval of cells around the center marked for rebuilding called a \df{germ}.
(The marking is done on a track different from \( \Core \) and therefore not influencing consistency.)
If the germ reaches a size \( 10\beta \) cells rebuilding starts.
This prevents rebuilding from starting in cases when healing can succeed.
Indeed, a zigging movement in rebuilding will recognize immediately if it has
no base of at least \( 10\beta \) rebuilding cells.
% Let us spell this out in advance, to be enable some reasoning the rebuilding procedure before
% specifying it in detail:

% \begin{fact}\label{fact:rebuild-zig}
%   Rebuilding mode uses zigging, just as normal mode.
%   If it finds fewer than \( 4\Delta \) rebuilding cells then it calls alarm.
% \end{fact}

Here are the details of healing.
Suppose that \( \rHeal \) is called at some position.
Then it sets \( \Mode\gets\Healing \).
In what follows, turns will always be small turns, as defined in Section~\ref{sec:feathering}. 
In any newly created cell, 
\( \Drift \) is set backwards to the creating cell---to make sure that the head does not get
lost on the edge of the infinite vacant space when hit by a burst of faults.

% \begin{varenum}{h}
% \item
%   Move left by \( 2\Delta \) cells.
%   Start a germ.

%   \item\label{i:heal.restart}
%     Move to the germ's right edge.
    
% \item\label{i:heal.survey}
%   If the germ is bigger than \( 4\Delta \) cells then start rebuilding.
%   Also, if the survey shows you at the front of a rebuilding procedure,
%   continue rebuilding.

%   In what follows, when an ``attempt'' fails, increase the germ by 1 cell towards the left,
%   and go to~\eqref{i:heal.restart}.

%   Let \( I \) be the interval of \( 4\Delta \) cells on the right of the germ.
%   If \( I \) contains a cell marked for rebuilding, remove the mark in the first one
%   (setting \( \Rebuild.\Sweep\gets 0 \)) and go to~\eqref{i:heal.restart}. 

%   Let \( I'\subset I \) be an interval starting after the first \( \Delta \) cells of \( I \)
%   and consisting of \( 2\Delta \) cells.
%   If \( I' \) is healthy then move to its center and go to~\eqref{i:heal.healthy}.
  
%   Find the first illegal boundary \( x \) in \( I' \).
%   Find the first substantial domain \( S' \) within \( \Delta \) steps on the left of \( x \).

%   Attempt to find the first substantial domain \( S'' \) within \( \Delta \) steps on the right of \( x \)
%   (both \( S' \) and \( S'' \) can reach outside \( I' \)).
%   By Lemma~\ref{lem:ambiguous} there must be such a domain.
%   Attempt one step of stitching operation, increase the germ by 1, 
%   and go to~\eqref{i:heal.restart}.

% \item\label{i:heal.healthy}
%   If the germ is nonempty, decrease it by 1 on the left, and go to~\eqref{i:heal.survey}.

%   If you are at an illegal boundary, go to~\eqref{i:heal.survey}.

%   If you are at the front, turn to normal mode.

%   Else move towards the front.
% \end{varenum}

  In what follows, when an ``attempt'' \df{fails}, 
increase the germ by 1 cell at one of its ends, go to the center and restart.  
Survey an interval \( I \) consisting of \( 4\Delta \) cells left and as many right from the center.
Let \( I'\subset I \) be an interval consisting of \( \Delta \) cells to the left and as
many to the right of the center.
\bigskip
{\newcommand{\instr}{\item[]\hspace{-0.6em}}
  \begin{itemize}
    \instr If the ambiguous areas in \( I \) cannot be covered by 3 intervals of size \( \le\Delta \) (separated by
    substantial homogenous intervals) then fail.

\instr If \( I' \) is healthy then check the germ.
  If it is nonempty, decrease it by one cell, go to the center and restart.
  Else go to the center and turn to normal mode.
  
\instr If the germ is bigger than \( 10\beta \) cells then start rebuilding.
  % Also, if the survey shows you at the front of a rebuilding procedure,
  % switch to continuing it.
  % If it is between two opposing fronts, continue the front of the newer rebuilding.

\instr  If \( I \) contains a (non-germ) cell marked for rebuilding, remove the mark in the first one
  (setting \( \Rebuild.\Sweep\gets 0 \)), go to the center and restart. 
  
\instr Find the first illegal boundary \( x \) in \( I' \).
  Attempt to find a substantial domain within \( \Delta \) steps on the left of \( x \);
  let \( S' \) be the first one.

\instr  Attempt to find a substantial domain \( S'' \) within \( \Delta \) steps on the right of \( x \).
  Let \( S'' \) be the first one.
  If \( S' \) and \( S'' \) are adjacent (so there is an illegal boundary between them) then fail.

\instr  Attempt one step of stitching operation, go to the center and restart.

\end{itemize}
}
\bigskip

Note that an ambiguous interval (between \( S' \) and \( S'' \)) does not trigger stitching unless
it contains an illegal boundary.

The healing procedure takes at most two sweeps of size \( 6\Delta \), so runs in \( O(\beta) \) 
steps.


\subsection{Rebuilding}\label{sec:rebuilding}

Rebuilding starts by extending a germ (created by healing) to the right, in a zigging way,
expecting rebuild-marked cells on the backward zig.
This notices if rebuilding started from a burst of faults smaller than a germ
in a healthy area, and calls alarm.
Just as with healing, we will not mention disorder (since the program does not see it)---but
the analysis will take disorder into account.

Rebuilding could also start from big turn starvation (see Section~\ref{sec:feathering}).
Since a whole track carries the counter \( \totalBigDigression \),
this start can also not be triggered by a burst of faults of size \( \beta\B \).

Here is an outline, for rebuilding that started from a cell \( \z \) on the right end of a germ.
The notion of front, of Definition~\ref{def:front} can be extended also to the rebuilding mode.
We will use the following notion.

\begin{definition}\label{def:valid-colony}
  Suppose that in a configuration \( \xi \), there is an interval \( I \) 
  ending in substantial homogenous domains,
  most 3 ambiguous intervals inside, in which it can be changed
  to become healthy, with a colony \( C \) in \( \Int(I,0.2\Q\B) \).
  Then we will say that \( C \) is a \df{valid} colony of \( \xi \) with a \df{neighborhood} \( I \).
\end{definition}

The goal is that
\begin{varenum}{r}
\item\label{i:rebuild-size} we end up with a new decodable area
  extending at least one colony to the left and one colony to the right of \( \z \).
\item\label{i:keep-healthy} the process does not destroy any valid colony.
\end{varenum}

The rebuilding operation uses its own addresses, in a special way, to avoid being
confused by the occasional deletion or insertion of cells.
It has two address tracks: 
\( \Rebuild.\Addr_{-1} \) counts from the left end of the rebuilding area towards the head,
and \( \Rebuild.\Addr_{1} \) from the right end.

% The healing procedure can start also during rebuilding.

Here are the stages.
Recall the stitching operation from Section~\ref{sec:stitching}.
\begin{description}
 \item[Mark] Starting from the germ, extend a rebuilding area  over \( 4\Q \) cells to the right
and \( 4\Q \) cells to the left from the center \( \z \).
Besides the address tracks, use also a track \( \Rebuild.\Sweep \).
Every step that changes the configuration must be accompanied by zigging, to check that
the rebuilding is indeed going on.

Rebuilding does not assume anything about the content of the area encountered, with
two exceptions: right-marking can override left-marking, and
there is the possibility of turn starvation as defined in Section~\ref{sec:feathering}.

If leftward marking encounters the front of a rightward marking 
process that proceeded to a distance of at least \( \PadLen \) as in Definition~\ref{def:PadLen},
then control is passed to the latter; see Remark~\ref{rem:rebuild-precedence}.

The other way that rebuilding can fail in a clean area is turn starvation.
Small turn starvation triggers alarm (thus healing).
Big turn starvation restarts rebuilding at a distance at least  \( 2\Q\B \) from the supposed turn.

 \item[Survey and Create]
More details of this stage will be given below.
It looks for existing valid colonies, and possibly creates some.
As a result, we will have one colony called \( C_{\Left} \)
on the left of \( z \) along with its neighborhood as in Definition~\ref{def:valid-colony},
one called \( C_{\Right} \) on the right of \( z \), and possibly some colonies between them.
Make all newly created colonies represent stem cells.
Direct all the other colonies with drifts and bridges towards \( C_{\Left} \).
(As during transfer, the creation of a bridge may result also in the creation of a new 
colony if the bridge becomes \( \Q \) cells long.)
The interval covering \( C_{\Left} \) and \( C_{\Right} \)
will be called the \df{output interval} of rebuilding.
The pair of neighbor colonies with \( C_{\Left} \) on its left will be made the current colony-pair.

\item[Mop] Remove the rebuild marks (address and sweep),
  shrinking the rebuilding area \( R \), starting on its left end,
  onto the right end of \( C_{\Left} \).
  % However, if during the zigging execution of mopping,
  % you find that after removal the area starting \( R \) and ending in \( C_{\Right} \)
  % does not become healthy, call alarm.
  % (This is the case if the rebuilt area is adjacent to another, unfinished rebuilding on the left.)



  
  % Importantly, alarm is triggered only at the end, not at the beginning of the rebuilding process;
  % this way except for the removal of the marks, the work of rebuilding is not delayed forever.)
\end{description}

Marked cells from some interrupted rebuilding may remain even after the mop-up operation.
These may trigger new healing-rebuilding later.


\subsubsection*{Details of the Survey and Create stage}

The complexity of this stage is due mainly to guaranteeing
property~\eqref{i:keep-healthy} above.

\begin{varenum}{s}
\item\label{i:stitch}
  Going from left to right,
  pass through the marked area, and stitch every pair of consecutive
  substantial domains separated by an ambiguous area of fewer than \( \Delta \) cells,
  just as during healing.
  But don't create a new germ as in healing: if the stitch result leaves some illegal boundary, just leave
  it there.
  The stitching operations may replace some of the germ cells: make sure that every replacement cell
  is also marked as germ.

\item\label{i:find-colonies}
  Pass through again, and look for whole colonies.
  Mark the cells belonging to whole colonies as such, and mark all other cells as such.
  The marks should go to a special track \( R_{1} \).

\item\label{i:repeat}
  Repeat steps~\eqref{i:stitch} and~\eqref{i:find-colonies}, writing the resulting marks onto a special
  track \( R_{2} \).
  The following steps will rely on the two tracks \( R_{1},R_{2} \) having identical content.
  If it is discovered that this is not the case, alarm is called.
  This is important since the colony creation operations are destructive, they should not be triggered by
  a single small burst of faults.
  
\item\label{i:C-left-right} Check if there is a marked whole colony to the left of the germ,
  whose whole neighborhood as in Definition~\ref{def:valid-colony} is healthy.
  If yes, find the closest one.
  If not, create one making sure it does not intersect any marked whole colony, and its
  neighborhood is healthy (if necessary overwrite part of the neighborhood with stem cells).
  Call this colony, found or created, \( C_{\Left} \).
  Proceed similarly in finding or creating a colony \( C_{\Right} \).
  
\item Fill in the area between \( C_{\Left} \) and \( C_{\Right} \)
  and the other marked whole colonies between them:
  fill these gaps with adjacent stem cells, creating a new colony every time
  an interval of \( \Q \) adjacent stem cells has been created.

\item Make all newly created colonies represent stem cells.
  Let \( C_{0} \) be the first colony towards the left of the center
  with at least half of it to the left of the center.
  Direct all drifts to the left end of \( C_{0} \).
  Make \( C_{0} \) and its right neighbor the new current colony-pair (create a bridge from
  \( C_{0} \) to its right neighbor if needed), and let them
  represent the start of a healing process on the level of \( M^{*} \).
\end{varenum}

\begin{remarks}\label{rem:rebuild-precedence}
  \begin{enumerate}
  \item\label{i:rebuilding-fail}
    There are only two ways in which the rebuilding process can be interrupted in the
    absence of noise: overriding from the left (as rightward rebuilding was given precedence),
    and turn starvation.
  \item
    Once rebuilding completes, since the state of the current colony-pair simulates the start of
    healing in \( M^{*} \), the head will continue to the right.
    There, rebuilding may be called again, but it will not rewrite the colony \( C_{\Left} \).
    It may rewrite its right neighbor colony, but not destroy it; so repeated calls to rebuilding
    will result in progress.
    
  \item Precedence will be used in the proof of Lemma~\ref{lem:pass-clean}.
    There, the goal is to see that in the absence of new noise, after a constant number of passes,
    a certain clean interval \( J \) will extend to the right until it reaches
the end of a colony pair or of a rebuilding area.
If marking is unstoppable in both directions then this may not happen soon, since after disorder
is entered and exited, no assumption can be made of the state of the current cell-pair.
Reaching the left end of  \( J \)
a new rebuilding process may send the head back to the right end, from which a new rebuilding
process can send it back to the left end, and so on.
If marking to the right has precedence then a new left-directed marking started on the right end would not stop it.

\item Giving precedence to the right rebuilding has the drawback that one can design a initial configuration
  in which even in the absence of noise, higher-level structure will never arise even locally.
  Namely, we can fill the line with short intervals \( \dots,J_{-1},J_{0},J_{1},\dots \)
  each of which is the start (say of size \( 3\Z \)) of a
  right-directed marking process.
  Then the head, after moving left on \( J_{0} \), will be captured by the process on \( J_{-1} \), then
  later captured by the similar process on \( J_{-2} \), and so on.
  But we will not need to consider such pathological configurations.

% \item Another asymmetry occurs in the mopping process, which starts from the right: it is immediately
%   interrupted unless the area it is freeing up, as well as its neighborhood on the right, is healthy.
%   So a large unhealthy area can be rebuilt only if there is a large healthy area on its right: it cannot be rebuilt
%   ``from within''.
%   This blemish of the program might be repairable, but our proof of Pass Cleaning relies on it.
  
  \end{enumerate}
\end{remarks}

% \begin{lemma}\label{lem:rebuild-health}
%   Suppose that a rebuilding procedure starts on one end of an admissible subinterval
%   \( J\subseteq I \) of a clean interval \( I \), and runs with at most one burst of faults
%   of size \( \le\beta \), to the finish (possibly restarted
%   some times due to big turn starvation (see Section~\ref{sec:feathering}) without leaving \( I \).
%   Denoting by \( K \) the output interval of rebuilding, then \( J\cup K \) will be admissible.
% \end{lemma}
% \begin{proof}
%   If a burst occurs then no matter what mode it puts the machine into, 
%   zigging will discover the inconsistency and call alarm.
%   Then according to part~\eqref{i:heal.germ} of the healing procedure the frontier zone of
%   rebuilding will be discovered, and rebuilding will be allowed to continue.

%   The other event that may interrupt (restarting) rebuilding is big turn starvation.
%   Assume for example that big turn starvation moves the head to the right repeatedly,
%   but finally (since the head does not leave \( I \)) a big left turn is allowed to happen.
%   Then over the area that has been passed during any of these rebuildings,
%   there will be no big turn starvation preventing the head from turning right,
%   since there the footprints of the big right turns (as define in Section~\ref{sec:feathering})
%   have now been spaced far from each other.
%   So eventually a big enough area will be free from closely spaced footprints and a rebuilding succeeds.
% \end{proof}

% \section{Scale-up}

% This section defines the decoding map \( \Phi^{*} \) and proves that it indeed takes a trajectory
% to a trajectory.
% As indicated in Section~\ref{sec:model}, when dealing with the behavior
% of machine \( M \) over some space-time rectangle, we will assume that the noise
% over this rectangle is \( (\beta\pair{\B}{\Tu}, \gamma\pair{\B^{*}}{\Tus}) \)-sparse.  
% This means in simpler terms that at most one noise \df{burst} affecting an
% area of size at most \( \beta(\B\times\Tu) \) can occur
% in any \( \gamma \) neighboring work periods.
% In the present section, histories will always be assumed to have this property.
% Let us extend the notion of annotation
% in order to account for damage not only to health but also to information.

% \subsection{Annotated history}

% Let us extend annotation to histories.

% \begin{definition}[Distress and relief]\label{def:distress}
% Consider an annotated trajectory over a certain space-time region.
% If the head is free (see Definition~\ref{def:annotation}), then
% the time (and the configuration) will be called \df{distress-free}.
% A space-time point that is not distress-free and is preceded by
% a distress-free time will be called a \df{distress event}.
% This can be of two kinds: the head steps onto an island, or a burst occurs
% (creating an island and leaving the head in it).

% % The direction of the last \( \Z \) non-turning moves of the front before the distress event
% % will be called the \df{pre-distress sweeping direction}.

% Consider a space-time region \( J\times K \) starting with a distress event contained in \( J \)
% and ending with a distress-free configuration.
% Let \( J \) be here the interval of tape where the head passed during \( K \), then 
% we will call \( J\times K \) a \df{relief event}, if the following holds.
% % the free head making \( \Z \) non-turning moves.
% % Their direction is called the \df{post-distress sweeping direction}.
% % If it coincides with the pre-distress sweeping direction then we will say that
% % \df{no turn} occurred.

% \begin{alphenumIn}
% \item Any new islands occurring in \( J \times K \) are due to some new burst.
% \item The island that started the distress event disappears by the end of \( K \).
% % \item Provided no turn occurred, the only possible island intersecting \( J \) 
% % at the end of \( K \) belongs to some island caused by a burst during \( K \).
% % (In other words, the \emph{old} islands will be eliminated in \( K \).
% % This is always the case if the distress occurs in the interior of a colony.)
% \end{alphenumIn}
% \end{definition}

% \begin{premark}
%   Quantify this for a large enough \( K \).
% \end{premark}

% In what follows we will show that for any trajectory \( (\eta, \Noise) \) 
% on a space-time rectangle on which the
% noise is \( (\beta\pair{\B}{\Tu}, \gamma\pair{\B^{*}}{\Tus}) \)-sparse,
% if the starting configuration was annotated then the annotation
% can be extended to the interior of the rectangle and
% each distress event will be followed by a relief event.
% In the rest of the section we always rely on the assumption of  this 
% sparsity property of the noise.

% After a distress event (unlike in~\cite{burstyTuring13}), islands 
% may have their cell structure damaged: may contain disorder.
% However, since \( \eta \) is a trajectory, as we will see the islands will be cleaned out.
% So, relief can be said to happen in two stages: cleaning, and correcting the structure.
% However, this division is only for the purposes of proof: the machine has no
% ``disorder-detector'', and the proof just relies on the cleanness-extending properties of a
% trajectory introduced in Definition~\ref{def:traj}.


\section{Annotation}    \label{sec:annotation}

This section defines the scale-up operation and analyzes trajectories under sparse noise.

\subsection{Annotation, scale-up}    \label{sec:annotation,scale-up}

Let us define the notion of ``almost healthy'' (admissible) for trajectories.
Recall the definition of the parameters \( Q_{k},U_{k},\Tu_{k} \) in Definition~\ref{def:hier-params},
and that when for example \( \Tu=\Tu_{k}\) then we denote \( \Tus = \Tu_{k+1} \),
an upper bound on the time of computation of a simulation work period.

Informally, an admissible configuration may differ from a healthy one in a small number
of intervals we will call ``islands''.
Even a healthy configuration may contain some intervals called ``stains'':
places in which the \( \Info \) track differs from a codeword.
These pose no obstacle to the simulation, and if they are small and few then
will be eliminated by it, via the error-correcting code.


\begin{definition}[Annotation]\label{def:annotation}
  Consider a region \( R \) of space-time where for each time \( t \) the set of space-time points
  belonging to \( R \) is an interval \( J(t) \).  
  An \df{annotated trajectory} over \( R \) is a tuple
  \begin{align*}
    (\eta, \chi, \cI(\cdot), \cS(\cdot)),
  \end{align*}
  where \( \eta,\chi \) are trajectories over \( R \), the trajectory \( \chi \) is healthy,  further
  to every interval \( I \) of size \( \Q\B \) belongs a
  number \( n_{I}\le 3 \) with the following properties:
  \begin{varenum}[series=annotated]{a}

  \item\label{i:islands,stains} At each time there is a set of intervals \( \cI(t) \) called \df{islands}
    and a set of intervals \( \cS(t) \) called \df{stains}, where each island is contained in a stain.

  The disorder of \( J(t) \) in \( \eta(\cdot,t) \)
  is covered by intervals of size \( \le (\beta+2\CSpill)\B \), one inside each island.
    
  \( \eta(\cdot,t) \) differs from \( \chi(\cdot,t) \) only in the islands.

  \item In each colony of \( \chi(t) \), at any time that does not belong to the last sweep,
    the \( \Info \) track of the interior can be changed in the stains in such a way that it becomes
    a codeword of the code \( \upsilon \) as in Definition~\ref{def:colony-interior}.
    There are at most 2 such stains intersecting the interior for each colony.
   
  \item Stains (and thus also islands) have size \( \le\cns{stain}\beta\B \)
    where \( \cns{stain} \) was introduced in~\eqref{eq:stain}.

  \item\label{i:n} At any time \( t \), every interval \( I \) of size \( <\Q\B \) contains
    at most \( n=n_{I} \) islands.
    The total size of these islands is at most \( \le (3n+1)\beta\B - 2d \),
    where \( d \) is the total size of disorder in them.

    If there was no noise during  \( \rint{t-\Tus}{t} \), then \( n\le 2 \) and
    every colony contains at most two stains.

  \item\label{i:turned}
    In every interval \( I \) of size \( \Q\B \), the maximum size of an interval of cells with 
    \( \Turned=1 \), is at most \( n_{I}\Delta \).
    Also \( I \) has at most \( 3n_{I}\log\Q \) footprints of a big turn closer than \( 2\F \)
    cells to each other (see Definition~\ref{def:footprint}). 

  \item\label{i:two-islands}
    Suppose \( n_{I}=2 \) in interval \( I \) of size \( \Q\B \) to the right of the head.
    Then one of these islands is in the turn region on the right of a colony \( C \) on its left.
    And either the field \( \Turned \) has value 1 in the cell state represented by \( C \), 
    or the \( \Drift \) track of \( C \) has value \( 1 \) (in case the represented cell state has already
    been or is in process of being rewritten).
    An analogous statement holds when right is replaced with left.
  \end{varenum}

  A trajectory \( \eta \) is \df{admissible} over the space-time region \( R \) if it allows an annotation
  \( (\eta,\chi,\dots) \)  there.
  We will say that the history \( \chi \) \df{satisfies} \( \eta \).
  Its \df{base colony-pair} at any time \( t \) is that of \( \chi \) (its position is uniquely determined).
  The head is \df{free} in an annotation
  when it is not in any island, and the observed cell-pair is in normal mode.

  A configuration \( \xi \) is admissible if the one-time-step trajectory
  consisting of just \( \xi \) is admissible.
\end{definition}

When considering a single time \( t \)
we can refer to \( \cI(t) \) as \( \cI \) and \( \xi(t)=\eta(\cdot,t) \) as \( \xi \),
and we can talk about the annotation of \( \xi \).
A configuration may allow several possible annotations;
however, since the code defined in Section~\ref{sec:simulation-phase}
is \( (\cns{stain}\beta,2) \)-error-correcting, 
the codewords recoverable from it do not depend on the choice of the annotation.

Formally, the proof of error-correction will happen by proving that
annotation can be extended forward in time; however, we will retain an informal language
whenever it is clear how to translate it to annotation.
Let us argue (informally, for now), that local correction
does not have to deal with more than three islands in any area of size \( \Q\B \). 

\begin{example}[Three islands]\label{xmp:3-islands}
  Suppose that the head has arrived at some colony-pair \( C_{0},C_{1} \) from the left,
goes through a work period and then passes to the right.
In this case, if no new noise occurs then we expect that
all islands found in \( C_{0},C_{1} \) will be eliminated by the healing procedure.
A new island \( I_{1} \) can be deposited in the last sweep.

Consider the next time (possibly much later), when the head arrives (from the right).
If it later continues to the left, then the situation is similar to the above.
Island \( I_{1} \) will be eliminated, but a new one may be deposited.
But what if the head arrived to the colony-pair \( C_{1},C_{2} \) and
turns back right at the end of the work period?
If \( I_{1} \) is not near the right end of \( C_{0} \), then
the head may never reach it to eliminate it; moreover, by the
feathering way of making turns,
it may add a new island \( I_{2} \) near on the right end of \( C_{0} \).

When the head returns a third time (possibly much later), 
from the right, feathering on the level of the simulated machine will
cause it to leave on the left.
Islands \( I_{1},I_{2} \) will be eliminated but a new island
\( I_{3} \) may be created by a new burst of faults before, after or during the elimination.
So the healing procedure must count with possibly three islands
possibly in close vicinity to each other.
But at least one of these, namely \( I_{2} \), is near the end of \( C_{0} \), not in
the extended interior \( \Int(C_{0},\PadLen-\F\B) \).
\end{example}

Let us now define formally the codes \( \varphi_{*k},\Phi_{k}^{*} \) needed
for the simulation of history \( (\eta^{k+1},\Noise^{(k+1)}) \) by history \( (\eta^{k},\Noise^{(k)}) \).
Omitting the index \( k \) we will write \( \varphi_{*},\Phi^{*} \).
To compute the configuration encoding \( \varphi_{*} \) we proceed first as
done in Section~\ref{sec:hier-codes}, using the code \( \psi_{*} \) there,
and then initialize the kind, sweep, drift and address fields appropriately.
The value \( \Noise^{*} \) is obtained by a residue operation
as in Definition~\ref{def:sparsity}; it remains to define \( \eta^{*} \).
In the parts of the history that can be locally annotated, and which we will call \df{clean},
if no colony has its starting point at \( x \) at time \( t \), set \( \eta^{*}(x,t)=\Vacant \).
Otherwise \( \eta^{*}(x,t) \) will be decoded from
the \( \Info \) track of this colony, at the beginning of its work period 
containing time \( t \).
More precisely:

\begin{definition}[Scale-up]\label{def:scale-up}
Let \( (\eta,\Noise) \) be a history of \( M \).
We define \( (\eta^{*},\Noise^{*}) \) \( =\Phi^{*}(\eta,\Noise) \) as follows.
Consider position \( x \) at time \( t \), and \( J=\rint{t-\Tus}{t} \).
If \( \lint{x}{x+\Q\B} \) is not contained in some interval \( I \) such that \( \eta \) is admissible
over \( I\times J \) then \( \eta^{*}(x,t)=\Bad^{*} \).
Assume now that it is contained, and let
\( \chi(\cdot,u) \) be some healthy history satisfying \( \eta \) over \( I\times J \).
If \( x \) is not the start of some colony \( C \) in \( \chi \)
then let \( \eta^{*}(x,t)=\Vacant \); assume now that it is.
Then let \( t'\in J \) be the starting time in \( \chi \) of the work period of \( C \)
containing \( t \), and let \( \eta^{*}(x,t) \) be the value decoded from \( \eta(C,t') \).
In more detail, as said at the end of Section~\ref{sec:coding}, we apply the decoding
\( \psi^{*} \) to the interior of \( C \) to obtain \( \eta(x,t) \).
\end{definition}

This definition decodes admissible intervals and trajectories for \( \eta \) into 
histories \( \eta^{*} \).
(We don't know yet whether these are trajectories of \( M^{*} \).)


% Recall the definition of a clean hole in Definition~\ref{def:clean-hole}.

% \begin{lemma}\label{lem:rebuild-clean}
%   Let  \( I \) be clean interval  of size \( 5\Q\B \).
%   Consider a noise-free time interval \( J \) during which the head spends time \( \ge 5\Tu \) in \( I \)
%   or passes through \( I \).
%   Then during \( J \) at some time the head will be found in a hole intersecting \( I \) that is
%   clean for \( M^{*} \).
% \end{lemma}
% \begin{proof}
% Assume, without loss of generality, that the head passes \( I \) from left to right.
% In the absence of noise, and inside a clean area,
% the healing procedure can only fail if it starts a rebuilding process.
% And a rebuilding process never fails.

% If the head passes \( I \) in normal mode, then
% the simulation makes \( I \) clean for \( M^{*} \).
% It may encounter a colony that is only healthy, not super-healthy;
% however, then the simulation will turn it into a healthy one.
% If healing is invoked but no rebuilding then we can follow the proof of Lemma~\ref{lem:combined-heals}:
% the result of each successful healing is consistent with the the continuation of a simulation.

% If a rebuilding is invoked whose whole range falls within \( I \) then it succeeds.
% Then simulation continues, with possible healings thrown in, until new rebulding starts.
% Lemma~\ref{lem:rebuild-health} shows that rebuilding will only extend the super-admissible area.  
% \end{proof}
% \Pnote{Coordinate these two lemmas, check and elaborate.}

\subsection{Isolated bursts}\label{sec:1-level-noise}

Here, we will prove that the healing procedure indeed deals with isolated bursts of faults.
For the elimination of disorder created by faults
we will rely on the Escape, Spill Bound and the Attack Cleaning
properties of a trajectory in Definition~\ref{def:traj}.
Let us give an informal argument first.

Isolated bursts of faults don't create disorder larger than \( 3\beta \).
The head escapes a disorder interval \( I \) via the Escape property; while it is inside, the
spreading of this interval is limited by the Spill Bound property.
Every subsequent time when the head enters and exits \( I \) this gets decreased
via the Attack Cleaning property, so it disappears after \( O(\beta) \) such interactions---see
Lemma~\ref{lem:healing} below.

% \begin{lemma}[Local escape]
% Let \( G \) be an interval of size \( n\B \) where \( n<\Z \).
% Then in the absence of noise, the head will either escape \( G \) within time \( O(n\Tu) \),
% or it will be inside a clean hole at some point during this time, as per Definition~\ref{def:clean-hole}.
% \end{lemma}
% \begin{proof}
%   Let \( c = (\CMarg+2\CSpill) \), as used in the Dwell Cleaning property of Definition~\ref{def:traj}.
% Let us cover \( G \) by consecutive intervals of size \( c\B \) called \df{blocks}, let \( m \) be the
% number of these blocks.
% Assume that the head does not escape \( G \) within time \( m\cdot\CEsc\Tu \).
% Then there is a block \( K \) in which it spends cumulative time \( \CEsc\Tu \),
% and the Dwell Cleaning property of trajectories implies that at some point during this time, it
% will be inside a clean hole in \( K \).
% \end{proof}
 
In a clean configuration, whenever healing started with an alarm, the procedure
will be brought to its conclusion as long as no new fault occurs.
However, as long as the head emerges repeatedly from disorder, we
cannot assume anything about the state of the cell-pair to which it arrives.
This complicates the reasoning, having to consider several restarts of the healing procedure.
By design, this procedure can change the \( \Core \) track only in one cell.
The following lemma limits even this kind of possible damage.

\begin{lemma}
In the absence of noise, no new island will arise.
\end{lemma}
\begin{proof}
  The islands are defined only by the \( \Core \) track.  
In normal mode, this track changes only at the front.
If this is not the real front, then we are already in or next to an island.

The healing procedure changes the \( \Core \) as part of a stitching operation,
or removing or adding a rebuild or germ mark.
The proof of Lemma~\ref{lem:stitching} shows that 
inside a healthy area, healing can only change the \( \Core \) track in two ways.
Either the front moves left or right, or the \( \Sweep \) values were changed
at turn boundaries in the turn region.
Neither of these operations affect health.

Adding or removing a rebuild or germ mark affects only the edges of islands.
\end{proof}

The following lemmas are central to the analysis under the condition that bursts of faults are isolated.


  \begin{lemma}[Healing]\label{lem:healing}
In the absence of noise in \( M^{*} \), the history can be annotated.
Also, the decoded history \( (\eta^{*},\Noise^{*}) \) satisfies the Transition Function property 
of trajectories (Definition~\ref{def:traj}).
\end{lemma}
\begin{Proof}
  In an annotated trajectory, call a space-time point a \df{distress event} if either a
  fault occurs there or the head steps onto an island.
The extension of annotation is straightforward as long as no distress event is encountered.
If after a distress event the head becomes free (according to Definition~\ref{def:annotation}),
then we will say that \df{relief} occurred.
Let us see what can occur between a distress and relief event.

\begin{step+}{step:heal.islands}
  By admissibility, there are at most \( n\le 3 \)
  islands within any interval of size \( <\Q\B \), and we will
  see that this property will be preserved.  
By the Spill Bound property,
the disorder in them can grow to at most \( n(\beta + 2\CSpill)\B \).
By the Escape property, every time the head is in the disorder
it must leave within time \( 9\CEsc(\beta+2\CSpill)^{2}\Tu \).
\end{step+}

\begin{step+}{step:heal.stages}
We will divide the time occurring after a distress event into \df{stages}: these continue until the head
is free at the front, with a complete zigging cycle performed.
Stages can be of various kinds:
\end{step+}
\begin{prooof}

\begin{varenum}{h}
\item\label{i:disorder} Entering and exiting disorder.
  We consider here also the case of a burst of noise, which increases \( n \)
  (then by assumption~\eqref{i:n} we had \( n<3 \), as the previous burst was long ago).

\item\label{i:heal-incomplete}
  Incomplete call to healing: either not started at its start or hit disorder before completing.

\item\label{i:rebuild} Start in rebuilding mode but finish either by hitting disorder or by calling alarm.

\item\label{i:heal} A complete call to healing.

\item\label{i:normal}
  Start in normal mode but meet disorder or alarm before completing a zigging cycle.

\end{varenum}

\end{prooof} % step:heal.stages

\begin{step+}{step:heal.island-size}
  An island 
  can increase only as a consequence of the head leaving disorder and possibly continuing
  in case of~\eqref{i:heal-incomplete}.
  It increases by at most 1 in a stage, and due to the Attack Cleaning property,
  in each case but the first one per island,
  this increase is associated by a decrease of the disorder by at least \( B/2 \).
  Therefore the bound 
\begin{align*}
 (3n+1)\beta\B - 2d \le 10\beta\B
\end{align*}
on the total size of islands, required in~\eqref{i:n}, is conserved.
  The germs are included in the islands, so by this bound on their size,
  rebuilding will not be started by the healing procedure.
\end{step+}

\begin{step+}{step:heal.disorder}
It follows from the above that
the head can leave the disorder at most \( (2n+1)(\beta + 2\CSpill) \) times.
This is also a bound on the number of times that case~\eqref{i:disorder} can  occur.
\end{step+}

\begin{step+}{step:heal.incomplete}
Cases~\eqref{i:heal-incomplete} and~\eqref{i:rebuild} imply a case~\eqref{i:disorder}, at their
beginning or end, so together they can occur at most \( 2(2n+1)(\beta + 2\CSpill) \) times.
Each of these stages makes at most two passes over an area of size \( <8\Delta\B \),
for a total time of \( < 32\Delta \) steps.
\end{step+}

\begin{step+}{step:heal.heal}
In case~\eqref{i:heal} we will either decrease one of the ambiguous areas containing an island, remove
a rebuilding or germ mark, or move to case~\eqref{i:normal}.
Since the total possible size of ambiguous areas is \( n\Delta\B \) and the total size of germs and rebuilding
signs is, as seen above, at most \( 10\beta\B \), there are at most \( n\Delta + 10\beta \) iterations of the
case~\eqref{i:heal} that actually change something.
The possibility of not changing, just returning to normal mode, can only occur
at the end of one of the other possibilities.
Therefore case~\eqref{i:heal} can occur at most \( 2n\Delta+20\beta \) times,
and just as incomplete heal, each stage lasts less than \( 32\Delta \) steps.
\end{step+}

\begin{step+}{step:heal.normal}
Case~\eqref{i:normal} can end in a case~\eqref{i:disorder} (\( < 7\beta \) times),
\eqref{i:heal-incomplete} (starting at normal, so \( <7\beta \) times) or~\eqref{i:heal} 
(when it actually starts from alarm, so can occur at most \( n\Delta+10\beta \) times).
The total number of times is therefore at most \( n\Delta+24\beta \).
The head never gets farther than two length of zipping plus \( (n+1)\Delta \), that is at most
\( 5\Z \) cells, so returning and performing a new zip of at most \( 8\Z \) steps bounds
each such stage by \( 13\Z \).
\end{step+}

\begin{step+}{step:heal.total-time}
  Summarizing the estimates: between a distress and relief,
  there are at most \( 3(2n+1)(\beta+\CSpill) < \Delta \) stages of type~\eqref{i:disorder}
  \eqref{i:heal-incomplete} or~\eqref{i:rebuild} (where we used~\eqref{eq:Delta}),
  at most \( 2 n\Delta+20\beta \) of type~\eqref{i:heal}
  and \(  n\Delta+17\beta \) of type~\eqref{i:normal} for a total of 
 at most \( (3n+2)\Delta \) stages.
  Those of kinds~\eqref{i:disorder}-\eqref{i:heal} take up time
  \( O(\beta^{3}\Tu) \), while those of kind~\eqref{i:normal} may take up time \( O(\beta\Z\Tu) \).
\end{step+}

\begin{step+}{step:heal.num-islands}
  The extended annotation still satisfies the restrictions on the number of islands, and also
  the restrictions~\eqref{i:turned} on the places with \( \Turned=1 \) and the footprints.
  
\end{step+}
\begin{pproof}
If at the time of the relief the islands encountered have not been eliminated
  then there are two possibilities:
  \begin{itemize}
  \item there is one island left, created after the start of the distress.
  \item the islands left are in a turn region, from which the head turned back
    in the normal course of simulation.
  \end{itemize}
  Indeed, an island can only be left if it is at the bottom of a zig as the front moves
  forward, since relief requires a whole free zig.
Suppose we have the case of the turn region, say on the right.
Because of the restriction~\eqref{i:two-islands} of annotation, at the end of the simulation cycle there
is transfer to the right, so the head moves past these islands, leaving at most one.

Contiguous intervals with \( \Turned=1 \) can form only either by a burst of faults, or
as the survey interval moves, stage after stage, in the same direction.
The latter will only happen as healing is called again and again, eliminating an ambiguous interval
gradually by stitching.
And since the ambiguous intervals are of size \( \le\Delta\B \), it happens at most \( \Delta \) times.

Footprints of big turns are only created at the edge of colony-pair during simulation.
On the right edge, one times \( 3\log\Q \) such footprints can be created when simulated
head moves left,
another one when the simulated head returns but moves left again,
and a third one when it returns again but will continue right.
These cases correspond to \( n_{I}=1,2,3 \).
\end{pproof}

\begin{step+}{step:heal.transition}
 The Transition Function property of the history \( (\eta^{*},\Noise^{*}) \) is satisfied.
\end{step+}
\begin{prooof}
Indeed, when the stains are bounded as they are here, the error-correcting code of the
simulation program will eliminate them, and computes the transition function correctly.
Condition~\eqref{i:turned} bounds by a constant the number of steps by which any zigging movements
needs to be extended in order to find a place to turn.

New stains only arise in new islands, so they remain bounded again.  
\end{prooof}
\end{Proof}

\begin{lemma}[Combined heals]\label{lem:combined-heals}
 Let \( d = 28\Delta\B \).
 Assume that the head moves in a noise-free and clean space-time rectangle
  \( J\times K \) with with \( 2 d < |J|<\Q\B \), \( |K|\ge |J|(32\Delta + \Z/2)\Tu/\B \),
  touching every cell of \( J \) at least once, and never in rebuilding mode.
  Assume also that at the beginning, \( J \) has no interval of \( >3\Delta \) consecutive
  cells with \( \Turned=1 \).
  Then during \( K \), the area \( \Int(J, d) \) becomes healthy,
  with no interval of \( >\Delta+1 \) consecutive cells having \( \Turned=1 \).
\end{lemma}
\begin{proof}
  If healing was not called then after the head touched every cell of \( J \) the
  health of the area is proved.
  If the head entered \( J \) in healing mode then before leaving healing mode,
  it touches over an area of size \( \le 16\Delta \).
  The upper bound \( 3\Delta \) on the number of consecutive cells with \( \Turned=1 \)
  makes sure that the turns happen within \( 3\Delta \) cells of both ends of this area, increasing
  its size to at most \( d = (16+12)\Delta\B \).
  
  Consider some time when healing mode is started while the head is in \( J \),
  and let \( I_{1} \) be the interval \( I \) defined in the healing
  procedure for this point.
  Since rebuilding is not started, this healing succeeds, with the interval \( I'_{1} \)
  becoming healthy, while staying in an area of size \( d \).
  After this, new healing starts only at some illegal boundary \( x \) outside \( I'_{1} \),
  and the interval \( A_{1} \) containing both \( x \) and \( I'_{1} \) is healthy at this time.
  If the head does not leave \( J \) during this procedure (and thus \( x\in\Int(J,d) \)),
  this healing also succeeds, creating a new healthy interval \( I'_{2} \) that
  intersects \( A_{1} \) in an interval of size \( \ge\Delta\B \).
  Hence \( A_{1}\cup I'_{2} \) becomes healthy.
  This process continues until the head leaves \( J \).
  So the only parts of \( J \) not becoming healthy are confined to the borders
  of size \( d \).

  As seen in the proof of part~\ref{step:heal.num-islands} of Lemma~\ref{lem:healing},
  the healing procedure can only create at most \( \Delta \) consecutive cells with
  \( \Turned=1 \).
  Zigging occurs only every 2 steps, so it does not create solid intervals with \( \Turned=1 \).

  Let us estimate the time needed for healing \( J \).
  As in part~\ref{step:heal.heal} of Lemma~\ref{lem:healing}, each call to healing to shrink
  an ambiguous interval lasts at most \( 32\Delta \) steps, for a total of \( \le 32\Delta^{2} \) steps,
  for a total of at most \( 32|J|/\Delta\B \).

  Let us now count the time needed in normal mode.
  In this case, the front will move only in one direction.
  Indeed, suppose that for example that the head entered \( J \)
  on the left, and at some time the  front turns in \( J \) from right to left.
  Then the head would travel to a distance \( >\Q\B>|J| \) and thus would exit on the left,
  not reaching the right end of \( J \).
  In normal mode, every two steps is followed by zigging, so the number of steps in normal mode
  is at most \( |J|\Z/2 \).
\end{proof}

An interval rewritten by noise can have \( \Turned=1 \) everywhere even if it is clean, so we define
a property of intervals avoiding this.

\begin{definition}\label{def:safe-for-turns}
  A clean interval will be called \df{safe for turns} if it has no more than \( 3\Delta + 1 \) consecutive cells
  with \( \Turned=1 \), and has no sequence of more than \( 3\F\log\Q \)
  footprints of a big turn closer than \( 2\F \) cells to each other.
\end{definition}

\begin{lemma}\label{lem:safe-for-turns}
  If a clean interval is passed over from left to right or right to left without noise then it becomes safe for turns.
\end{lemma}
\begin{proof}
  We will present the proof for a pass from left to right, and point out the only difference for the case
  when the pass is from right to left.
  % Add calculations!
  Let \( x_{1}<x_{2}<\dots<x_{n} \) be the points of the interval left with \( \Turned=1 \), and let
  \( t_{i} \) be the times when this happens at \( x_{i} \).
  \begin{enumerate}
  \item Consider the space-time points \( (x_{i},t_{i}) \)
    where the head makes a big turn in rebuilding mode.
    Then before time \( t_{i} \), the head must have performed at least one complete sweep of rebuilding.
    If this rebuilding succeeds then it leaves a healthy area containing at least one colony on the left and one
    on the right of its center.
    Another rebuilding can only start at the left or right of this interval.
    It cannot be on the left, since \( t_{i} \) was the last time when \( x_{i} \) was passed.
    So a next rebuilding big turn can only happen about \( \Q\B \) cells to the right of \( x_{i} \).

    If the pass is from left to right then 
    this rebuilding can only fail by big left turn starvation, see Section~\ref{sec:feathering}.
    This must happen at a distance at least \( 2\Q\B \) to the intended left turn.
    If any later rebuilding starts to the left of this, it will already succeed, and we can reason as above.

    In case the pass is from right to left then another possible way that the rebuilding can fail
    is the leftward rebuilding is overridden by a new rightward rebuilding, see the Marking part of the
    rebuild procedure in Section~\ref{sec:rebuilding}.
    Since this override can only happen when the front of the rightward process is still at a distance of
    \( \PadLen \) cells from the leftward front, several of these overrides are at least at a distance of \( 3\F\log\Q \)
    from each other, and therefore the big left turns on the other side will also be at least this far
    from each other, still guaranteeing safety for turns.
 
  \item Consider the space-time points \( (x_{i},t_{i}) \)
    where the head makes a big turn in normal mode, on the left of a (supposed) colony \( C \).
    If the simulation finishes normally, and a healthy colony \( C \) remains to the right of \( x_{i} \), then
    big turns, not belonging to this work period, will only be made at least \( \approx \Q\B \) to the right.

    There are two other possibilities.
    First, \( C \) is killed, and (in the same work period)
    another colony \( C' \) is created, overlapping it (possibly even two such colonies, \( C',C'' \)
    if the overlap is very small).
    Then \( C' \) cannot be deleted (without going to another colony on its left),
    so the big right turns on its left are necessarily separated on the
    right from others by at least \( \approx\Q\B \).

    The other possibility is that rebuilding will be called before the work period over \( C \) finishes.
    This can only happen if then this rebuilding experiences big left turn frustration on its right,
    since otherwise it would sweep over \( x_{i} \).
    Anyway, a new big left turn in normal mode near \( x_{i} \) can only result once, after some rebuilding
    creates some healthy colony \( C' \), and the reasoning continues as above.
    
    \item Consider the points \( (x_{i},t_{i}) \) where the head turns in healing mode.
  If \( i<n \) this healing cannot fail, since then the subsequent rebuilding would bring the head to the left
  of \( x_{i} \), contradicting the assumption that \( t_{i} \) was the last time when it was there.
  It follows that the healing will stitch an ambiguous area and the next healing can be started at a distance to the
  right as large as the size of a substantial area separating it from a next one.
  So, the size of an interval of cells \( x_{i},x_{i+1},\dots,x_{j} \) where the head turned in healing mode is at most
  \( \Delta \), the maximum allowed number of cells in an ambiguous area.
  And there is a gap of the size at least that of a substantial domain between these and the next turning
  points in healing mode.

  The analysis is similar for points \( (x_{i},t_{i}) \) where the head turns in the part of rebuilding when it is
  attempting to stitch an ambiguous area.

\item What remains is space-time points \( (x_{i},t_{i}) \)
  where the head makes a small turn in normal or rebuilding mode.
  In these modes the head makes a zig only in every second step, so normally these places also don't occur
  consecutively.
    \end{enumerate}
  
\end{proof}

\section{Cleaning}\label{sec:cleaning}

This section will scale up the Spill Bound, Escape, Attack Cleaning
and Pass Cleaning properties of trajectories, proving them for the history \( (\eta^{*},\Noise^{*}) \)
decoded from a trajectory \( (\eta,\Noise) \).

\subsection{Escape}\label{sec:escape}

We will scale up the Escape property in Lemma~\ref{lem:escape} below;
here is an outline of the argument.
Consider some fault-free path during a time interval \( J \) (later we will allow a single
burst of faults of size \( \beta \))
over some space interval \( G \) of size \( |G|=\lambda\Q\B \).
For the times \( t\in J \), let \( K(t) \) denote the set of those clean points in \( G \) that
the head passed at least once since they were clean.

The goal is to show that the path will not stay too long in \( G \).
This will be since if it stays long then it enlarges \( K(t) \), and then builds up colonies in it.
These simulate the machine \( M^{*} \), which commands its head to swing wide according
to the program (in zigging or healing), and thus leave \( G \).

Initially, the clean intervals of \( K(t) \) can be created using the 
Pass Cleaning property of trajectories.
Every time the head leaves such an interval, it grows via the Attack Cleaning property;
so we will mainly be concerned with longer stays.
The notion of ``long'' will be chosen here to make sure that most of it has to be spent in
simulating \( M^{*} \), since both healing and rebuilding finish relatively fast.
Let us proceed to details.

%  Here is a non-local strengthening of the health property.

% \begin{definition}[Super-health]\label{def:super-health}
%   Let \( \xi  \) be a healthy configuration on an interval \( I \) that is also safe for turns
%   (as in Definition~\ref{def:safe-for-turns}).
%   We say that \( \xi \) is \df{super-healthy} if it ends in colonies on both sides and
%   in each colony in it, whenever the head is not in the last sweep, the \( \Info \)
%   track contains a valid codeword as defined in Section~\ref{sec:coding}.
%   A tape configuration is \df{super-healthy} on \( I \)
%   if it can be extended (by indicating the head position) to a super-healthy configuration on it.
% \end{definition}

% In a super-healthy clean interval in history \( \eta \) the simulation of \( \eta^{*} \) will proceed.

% \begin{definition}\label{def:K(t)}

% A subinterval \( I \) of \( K(t) \) not containing the head will be called \df{regular}
% if it has the following properties:
% \begin{romanenum}
%   \item Its neighborhood of size \( \ge\Z\B \) is clean.
%   \item It can be subdivided into two parts (any one of these can be empty): the one
%     away from the head is healthy, and the one towards it is covered with rebuild marks.
%   \item It ends in colonies (some of which may have rebuild marks).
%   \end{romanenum}
%   The \df{rough size} of a regular interval is the number of colonies in it.

  % Observing the history during the time interval \( J \), we will follow the development
  % of \( K(t) \) and a set of disjoint regular intervals in it.
  % In what follows we establish some properties of the evolution of a regular interval which,
  % at time \( t \) we will denote by \( I(t) \).
  % Assume \( I(t) \) has size \( n\B \) with \( n\le 2\beta\Q \).
Time intervals of length \( \Tu \) we may consider as \df{steps}, since under clean and
noiseless conditions,
the machine \( M \) will perform at least one step of computation during each.
Let
  \begin{align}\label{eq:S-def}
   \S =\CShort\lambda\Z\Q\Tu,
  \end{align}
  with \( \CShort \) a constant to be determined later.
  We will say that the stay of the head in some maximal interval of \( K(t) \) is \df{short}
  if it is smaller than \( \S \), otherwise it is \df{long}.
  
% \begin{align*}
%  k(t)=|K^{*}(t)| .
% \end{align*}
% The set \( K(t) \) consists of maximal disjoint intervals.
% In the following lemmas, we consider one of these, \( I(t) \) during a fault-free path,
% where it may slightly decrease (without disappearing), increase or merge with others.
% \end{definition}

Recall  \( \U_{k} = \U =\Q^{3} \) in Definition~\ref{def:hier-params}.
This is an upper bound on the number of computation steps in one work period, even
allowing some calls for healing.

The following lemmas
follow the development of a maximal interval \( I(t) \) of \( K(t) \).
An interval \( I \) of size \( \Q\B \) in \( \Int(K(t), 2\B) \) is a \df{manifest colony} if
it is healthy with the possible exception of having some rebuild marks (only for survey, not
for decision), has undergone a complete simulation work period as part of a colony-pair in a
clean subinterval of \( K(t) \).
In a manifest colony, 
unless it is at a distance \( \le 2\Q\B \) from the head in the same interval of \( K(t) \),
the \( \Drift \) track points towards the head.

\begin{lemma}\label{lem:escape.non-decr}
  The number of manifest colonies does not decrease.
  Each manifest colony can be followed over time: it may stay in place or
  shift left or right (without jumping over other manifest colonies).
\end{lemma}
\begin{proof}
  Simulation, or healing does not destroy any part of a colony.
  It may shift a colony, if the simulation work period of a colony-pair encounters a
  replacement situation, see Section~\ref{sec:transfer}.
  Let us see that rebuilding does not destroy them either.

  In the definition of manifest colonies we did allow some (possible leftover)
  rebuild survey marks, but not decision marks.
  In order to destroy a colony, the rebuilding process needs to create two decision tracks.
  One has to consider the case when the rebuilding process is at one end of \( I(t) \),
  hence is fed some uncontrollable information.

  Now, after a long stay, the head can exit during a rebuilding process only if it is in its starting
  stage, marking its interval of operation.
  Zigging along with attack cleaning
  implies that in the following short stays between two long ones,
  before making a decision, the whole
  rebuilding interval will have to be incorporated into \( K(t) \), therefore the decision will
  be a correct one, not destroying a manifest colony.
\end{proof}
% Assuming that there was at least one long stay in \( I(t) \), we define two points inside it
% close to its end, as follows.

% \begin{definition}\label{def:escape.r}
%   Let \( u \) be the end-time of the last long stay inside \( I(t) \).
%   Let \( l(t) \) denote the left edge of the leftmost manifest colony of \( I(t) \) at time \( u \).
% The value \( r(t) \) for the right end is defined in a little more complex way.
% \begin{Alphenum}
% \item\label{i:escape.r.rebuild}
%   If at time \( u \), the head left \( I(t) \) on the right during an interrupted
%   rebuilding process then let \( r(t) \) denote the center of this process.
%   \item\label{i:escape.r.plain}
%     Otherwise, let \( r(t) \) be the right edge of the rightmost manifest colony in \( I(t) \)
%     at time \( u \).
% \end{Alphenum}
% \end{definition}


\begin{lemma}\label{lem:escape.inside-hole}
 \begin{alphenum}
 \item\label{i:escape.no-spill} No maximal subinterval of \( K(t) \) ever
   decreases by more than \( \CSpill\B \) on either side. 
%  \item\label{i:escape.attack-clean}
%    If the head leaves a maximal subinterval \( I(t_{1}) \) of \( K(t_{1}) \)
%    and then enters \( \Int(I(t_{2}),\CMarg\B) \) at some first time \( t_{2}>t_{1} \),
%    then \( I(t_{2}) \) increases compared to \( I(t_{1}) \) by at least \( \B/2 \) on the side of entry.
%    It follows that the total number of stays in any of the intervals of \( K(t) \)
%    is at most \( 2\lambda\Q \), and hence the total time spent in short stays
%    is at most 
% \begin{align*}
%   2\lambda\Q\cdot\CShort\Z \lambda\Q\Tu = 2\CShort\lambda^{2}\Z\Q^{2}\Tu.
% \end{align*}
%     % \item\label{i:esc.non-decr} The value \( l(t) \) does not increase. 
\item\label{i:escape.long-stay}
  The head does not stay longer than \( 2 n\U\Tu \) in any subinterval of  \( K(t) \) of size
  \( \le n\Q\B \).
  \end{alphenum}
\end{lemma}
\begin{proof}
  \begin{enumerate}
  \item 
  \eqref{i:escape.no-spill} follows from the No Spill property of trajectories.
\item\label{i:escape.inside-hole.long-stay} On~\eqref{i:escape.long-stay}:
  If any rebuilding has been started, it will finish in \( O(\Q\Z) \) steps unless
  interrupted.
  Let us show that it can only be restarted \( O(n) \) times while the head stays in
  the subinterval \( I(t) \), hence the total number of steps it can take is \( O(n\Q\Z) \).

  There are only two ways that rebuilding can be interrupted: big turn starvation,
  see Section~\ref{sec:feathering}, or being overridden by the marking process of another
  rebuilding process on the left.
  We claim that both of these possibilities can occur at most \( O(n) \) times.
  Big turn starvation occurs only after the head moved to a distance \( \ge 4\Q\B \) from
  the rebuilding center, so the center of a new rebuilding process is at least this far apart.
  Now consider the override by a rebuilding process on the left.
  The only reason the overriding rebuilding process was not finished before is
  turn starvation.
  Therefore its center is at a distance \( \le 4\Q\B \) to the left.
  So the number of restarted rebuildings is indeed \( O(n) \).

  While no rebuilding starts, the computation is in healing, normal or booting mode.
  If healing does not start rebuilding then it succeeds, turning to normal mode.
  New healing can start again, but consecutive healings enlarge the healthy area
  they are creating; eventually, normal mode computation starts;
  Subsequent healings can only delay this by a constant factor.
  The computation in normal (or booting) mode leads to the simulation of cells in \( M^{*} \).
  The program of \( M^{*} \), just like that of \( M \), proceeds by sweeps (zigging or healing).
  Even the shortest of these sweeps
  has size at least \( 2\beta\Q\B >\lambda\Q\B \), therefore a full sweep
  will exit \( I(t) \) in \( \le n\U\Tu \) steps.

  If rebuilding succeeds, it creates a colony-pair that simulates a cell-pair at the start of
  healing mode, hence starting a sweep of size \( >\beta\Q\B \) to the right.
  It may be interrupted by rebuilding again, but this rebuilding
  results in a new colony-pair of the same kind, in \( O(\Q\Z) \) steps, at the place
  where it started, at least \( \Q\B \) to the right of the last working colony-pair.
  So exit happens again in \( \le n\U\Tu \) steps.
    \end{enumerate}
  \end{proof}

  \begin{lemma}\label{lem:escape.results}
    Suppose that during a long stay in \( K(t) \) a rebuilding process is completed.
  It result is a pair of neighbor manifest colonies, on the left and right of the
  center from which rebuilding started.
  Let us call these the \df{left result} and \df{right result} of rebuilding.

  A manifest colony can only become a left result once, and a right result once.
\end{lemma}
\begin{proof}
  The smallest interval \( D \) containing the resulting colony-pair will be healthy and safe
  for turns at the time when rebuilding finishes.
  The following development will never introduce inconsistency into \( D \),
  other than rebuild marks resulting from some rebuilding process started outside it.

  The only way in which a rebuilding process can start even in a healthy area is
  big turn starvation, as defined in Section~\ref{sec:feathering}.
  But in the present case, the rebuild process looking for a big turn must have started
  looking for a turn outside \( D \), and since \( D \) is safe for turns, it would have
  found a turning point close to an end of \( D \), so the left colony of \( D \) could not become
  its left result, nor the right colony of \( D \) its right result.
\end{proof}

\begin{lemma}\label{lem:escape.long-stays}
  The number of long stays is at most \( 3\lambda \).
\end{lemma}
\begin{proof}
  \begin{enumerate}
  \item\label{i:escape.create}
  Consider some maximal interval \( I(t) \) of \( K(t) \), and a long stay in it.

  Suppose first that no rebuilding process 
  is triggered or continued during the stay; then
  only healing and computation steps are possible.
  
  Suppose that there was no manifest colony in \( I(t) \) before entry.
  The stay is long enough that at least one complete work period will be performed on
  a neighbor colony-pair.
  So by the time the head leaves, there will be at least one manifest colony; in fact the
  exit will happen during a transfer process from a manifest colony (possibly slowed down
  by healing).
  
  In general, whenever the exit happens after a long stay
  then it either happens this way or during the marking stage of
  a rebuilding process.

  Suppose there were manifest colonies at entry time, and the head enters on the left.
  Let \( C_{0} \) be the leftmost manifest colony of \( I(t) \).
  The head can pass to \( C_{0} \) only as a consequence of a
  transfer process from some colony \( C_{-1} \).
  So the long stay either adds \( C_{-1} \) as a new
  manifest colony, or joins \( I(t) \) with another subinterval of \( K(t) \) on its left, which
  contains a manifest colony \( C_{-1} \).
  
\item\label{i:escape.result}
  Suppose now that a rebuilding process starts or continues during the long stay.
  Then it either terminates, will be overridden by another rebuilding process, or
  triggers another one via turn starvation.
  This can happen repeatedly, but
  each of these processes has a center of at least \( \Q\B \) from the previous one, so
  one of them has to succeed since otherwise the stay would not be long.
  When it terminates, it creates a resulting colony-pair.

\item We found that each long stay either adds a new manifest colony, or
  joins two subintervals of \( K(t) \) of size \( \ge\Q\B \), or creates 
  a new left result and a new right result.
  Since there are at most \( \lambda \) manifest colonies in \( K(t) \),
  there can be at most \( \lambda \) creation events, and \( \lambda-1 \) events of
  joining two disjoint subintervals of \( K(t) \) of size \( \ge\Q\B \).
  Hence the total number of long stays of kind~\ref{i:escape.create} is at most \( 2\lambda-1 \),
  and the total number of long stays of kind~\ref{i:escape.result}
  is also at most \( \lambda \).
\end{enumerate}  
\end{proof}

%   Consider the situations when the head enters a maximal interval \( I(t) \) that has
%   at least one manifest colony, for a long stay.

%   \begin{lemma}\label{lem:escape.from-left}
%   Suppose that the head enters on the left and leaves on the left.
%   After the stay, a new manifest colony is found on the left from where it was.
% \end{lemma}
% \begin{proof}
%   If no rebuilding starts on the left of \( C_{0} \)
%   then the head can pass to \( C_{0} \) only as a consequence of a
%   transfer process from some colony \( C_{-1} \) on the left, so the new leftmost
%   manifest colony will be on the left of \( C_{0} \).

%   If, while or before the head enters the leftmost manifest colony \( C_{0} \),
%   a rebuilding process starts, then the head will exit \( I(t) \) on the right.
%   Indeed, given that the stay is long,
%   this process (or a later one if there is big turn starvation)
%   will finish, creating a pair of colonies simulating a pair of cells of \( M^{*} \)
%   at the start of healing (which directs the head to move \( \ge\beta \) big cells to the right).
%   After this there is no way for the head to exit on the left, as the created big cells
%   (or any later ones created by rebuilding) all direct the head to the right.
% \end{proof}

% Suppose that the head exits \( I(t) \) on the right after a long stay,
% during an interrupted rebuilding process.
% Above we defined the point \( r(t)\in I(t) \) as the center of this rebuilding process.

%  \begin{lemma}
%    Suppose that \( I(t) \) has at least one manifest colony and
%    the head enters \( I(t) \) for a long stay.
%    Then it enters again for a long stay (with possibly several short
%    stays in between), and exits again on the right.
%    Then either \( I(t) \) is merged with another maximal interval on its right,
%    or \( r(t) \) moves by at least \( \Q\B \) to the right.
%   \end{lemma}

%   \begin{proof}
%     \begin{enumerate}

%     \item\label{i:escape.no-rebuilding}
%     Suppose that the machine performs a work period
%     of complete simulation on the first manifest colony \( C_{0} \) it encounters
%     (leftmost or rightmost).
%     As we have seen in Lemma~\ref{lem:escape.from-left}, if the head enters from left,
%     then the leftmost manifest colony moves at least \( \Q\B \) to the left.

%   \item\label{i:escape.left-end} Suppose that the head enters from the left,
%     but before completing (or even starting) a work period like above,
%     a rebuilding process starts.
%     The only reason for this process not to be completed is big turn starvation,
%     but then another rebuilding process starts on the right at a distance \( \ge 4\Q\B \),
%     and so on.
%     As seen in the proof of Lemma~\ref{lem:escape.from-left},
%     this process ends up leaving on the right,
%     in one of two ways: either in the process of transfer during regular simulation,
%     or in a rebuilding process that interrupts such a transfer.
%     The center of the last finished rebuilding is at least \( \Q\B \) to the left of \( r(t) \),
%     and therefore any new rebuilding that would start later from a center to the right of
%     \( r(t) \), could not be interrupted by unfinished rebuilding with center
%     to the left of \( r(t) \), or by exiting on the left.

%   \item\label{i:escape.right-end}
%     Suppose that the head enters on the right, and rebuilding starts before a work period is
%     completed on the rightmost manifest colony.

%     If \( r(t) \) was defined via case~\eqref{i:escape.r.rebuild} of Definition~\ref{def:escape.r}
%     as the center of the last interrupted rebuilding, then now this rebuilding will be
%     finished, and \( r(t) \) will be moved right to the by at least \( \Q\B \), 
%     Indeed, this rebuilding can only be interrupted by a rebuilding process on its left, overriding it.
%     As mentioned in part~\ref{i:escape.left-end} above,
    
%     the overriding center has to be at least \( 4\Q\B \) to the left.
%     After possibly repeated overrides, one of these rebuilding processes terminates,
%     initiating a process described in part~\ref{i:escape.left-end} above, and resulting
%     in the definition of \( r(t) \).

%     If \( r(t) \) was already defined then, as mentioned at the end of part~\ref{i:escape.left-end}
%     above, the first successful rebuilding process
%     will have a center to the right of \( r(t) \), since there is no started rebuilding process
%     close to \( r(t) \) to override it.
%     So in this case \( r(t) \) will be moved to the right by at least \( \Q\B \).    
%    \end{enumerate}
%   \end{proof}

%   \begin{lemma}
%     The number of long stays in any subinterval of \( K(t) \) is at most
    
%   \end{lemma}
%   \begin{proof}
%     After every long stay, progress is made of one of the following kinds, with one of
%     the maximal intervals \( I(t) \) of \( K(t) \) size \( \ge\Q\B \):
    
%     \begin{enumerate}
%     \item\label{i:escape.create-manifest} A manifest colony is created if it did not exist;
%     \item\label{i:escape.merge} \( I(t) \) is merged with another
%       subinterval of \( K(t) \) having a manifest colony;
%     \item\label{i:escape.move-manifest} the manifest colony closest to the entry point is moved
%       by \( \Q\B \) in the direction of the entry point;
%     \item\label{i:escape.r-define}  \( r(t) \) is defined;
%     \item\label{i:escape.r-move} \( r(t) \) is moved by at least \( \Q\B \) to the right.
%     \end{enumerate}
%     Progress of kinds~\eqref{i:escape.create-manifest} and~\eqref{i:escape.merge}
%     can only happen \( \lambda \) times each,
%     since there are at most \( \lambda \) maximal subintervals of size \( \ge\Q\B \).

%     For each interval \( I(t) \) with a manifest colony, let \( r'(t) \) be the right end the rightmost
%     manifest colony if \( r(t) \) is undefined, and \( r(t) \) if it is.
%     Note that since \( r(t) \) is the right end of a 

    
%   \end{proof}


  
%   \begin{proof}
%   We will see that while the head does not leave \( I(t) \),
%   every certain number of steps results in some kind of progress.
%   \begin{enumerate}
%   \item\label{i:inside-hole.rebuild}
% Suppose that we are at some time when the rebuild procedure had started,
% from a base of rebuild-marked cells large enough not to result in alarm (renewed call for healing)
% after the first zigging.
% Then the rebuilding will be completed, increasing \( k(t) \).

% \item\label{i:inside-hole.normal}
%   Suppose that we are at some time when the mode is normal.
%   Then within \( 4\Z \) steps of the simulation
%   either alarm is called, or a step of progress will be
%   made in the ordinary work of simulation.
%   If the simulation performs a transfer operation and \( n<2\Q \)
%   then in moving to a new colony-pair, it must exit \( I \).
  
% \item\label{i:inside-hole.alarm}
%   Suppose that at some time alarm is called.
%   Then according to the proof of Lemma~\ref{lem:healing},
%   we either arrive at the above case~\ref{i:inside-hole.rebuild} (failed healing)
%   in \( O(\beta^{2})<\Z \) steps or healing finishes in
%   normal mode with at least one step made either to move closer to the front or to make a move
%   in the ordinary work of simulation.
  
%   Indeed, if healing succeeds it leaves a healthy area.
%   Lemmas~\ref{lem:health-extension} and~\ref{lem:combined-heals} imply that 
%   the overlapping successful healing areas can be combined, so healing will not be repeated over the same
%   area, and thus can slow down progress only by a 
%   factor \( O(\beta^{2}) \) (negligible compared to the \( \Z \) times slowdown by zigging), and even this
%   in at most one sweep of simulation over any area.

% \item\label{i:long-stay}  Suppose that \( n\ge 2\Q \) and the stay is long.
%   Without rebuilding, the continued healings add some colonies to the healthy area; any such colony will be
%   turned super-healthy by the first complete work-period of the simulation, taking at most \( \U \)
%   steps of computation.
%   If the head is already in a super-healthy area then it will perform the simulation of \( M^{*} \).
%   The simulated machine \( M^{*} \) has the same program as \( M \), so it will also
%   make switchbacks of at least \( \E>4\beta>2\lambda \) steps (for healing or zigging).
%   Therefore every \( 2\lambda\U\ge 4\U \) computation steps
%   simulating \( \ge 2\lambda \) steps of \( M^{*} \),
%   will pass to the end of the super-healthy interval in which it is working, and
%   whose size is at most \( \lambda\Q\B \), and extend it---unless interrupted by rebuilding.

% \item  If any rebuilding starts then it will either finish and extend \( K^{*}(t) \) by a colony,
%   or will be interrupted by a big turn starvation, as defined in Section~\ref{sec:feathering}.
%   Suppose that big turn-starvation happens at an attempted left turn:
%   then the marked rebuilding area is already of a size \( \ge 2\Q\B \).
%   Therefore a next big turn starvation cannot be due to an attempted right turn on the left, since
%   the marking process does not proceed so far to the left.
%   Repeated big turn starvations could only happen to the right, and the head would leave on the right before the
%   assumed \( \lambda\U \) computation steps.
%   Since this does not happen, rebuilding succeeds.
% \end{enumerate}
% \end{proof}

% Now consider cases where the head exits or enters \( I(t) \).

% \begin{definition}\label{def:advancing-end}
%   We will say that the right end of \( I(t) \) is \df{advancing} at time \( t \)
%   if the rightmost colony of \( K^{*}(t)\cap I(t) \) is in the start of the process of transfer to the right.
%   Advancing is defined similarly for the left end.
% \end{definition}

% \begin{lemma}\label{lem:long-stays}
%   Consider a sequence of long stays \( J_{1},J_{2},\dots,J_{r} \)
%   in \( I(t) \), possibly interrupted by any number of short ones.
%   \begin{alphenum}
%   \item\label{i:make-advancing}
%     In a long stay, \( k(t) \) will not decrease.
%     If it does not increase by at least \( \Q\B \)
%     then the end on which the head leaves becomes advancing.
%   \item\label{i:enter-advancing}
%     If the head enters on an advancing end for a long stay
%     then \( k(t) \) increases by at least \( \Q\B \) before it leaves---even
%     after any number of short stays in between.
%   \item\label{i:many-long}
%     If the number of steps spent on long stays in \( I(t) \) is at least \( s\lambda\U \) then
%     they will increase \( k(t) \) by at least \( (s/8)\Q\B \).
%   \end{alphenum}
% \end{lemma}
% \begin{proof}
%   To~\eqref{i:make-advancing}:
%   At the entrance from disorder, the head may slightly damage a colony.
%   But the subsequent checking would discover it and the stay is long enough for a rebuilding to succeed,
%   and even to create a new colony, increasing \( k(t) \) by at least  \( \Q\B \). 
%   In the absence of rebuilding, a simulation must have continued;
%   but then it can exit only via a started transfer operation, creating an advancing end.

%   To~\eqref{i:enter-advancing}:
%   Suppose that the head leaves on a advancing right end, and then re-enters after
%   possibly a number of short stays.
%   Let \( C \) be the right member of the colony-pair that
%   that started the right transfer operation.
%   The head may destroy \( C \) when entering, but even after repeated short stays, it cannot go past it
%   without either completing a rebuilding operation (and thus increasing \( k(t) \)) or
%   completing the transfer operation, and entering \( C \) from the right from a new colony
%   created by the transfer.
%   The long stay suffices for either the transfer or a rebuilding to succeed.

%   To~\eqref{i:many-long}:
%   Let us pair the long stays: \( (J_{1},J_{2}) \), \( (J_{3},J_{4}) \),\dots.
%   If \( r \) is odd and \( J_{r} \) has \( a\lambda\U \) steps for \( a\ge 2 \)
%   then by Lemma~\ref{lem:inside-hole}
%   it advances \( k(t) \) by \( \ge\flo{a/2}\Q\B\ge (a/4)\Q\B \).
%   Similarly if the longer of \( J_{2i-1},J_{2 i} \) has \( a\lambda\U \) steps, then the pair has
%   at most \( 2a\lambda\U \) steps, the pair advances \( k(t) \) by \( (2 a/8)\Q\B \).
%   Otherwise it follows from~\eqref{i:make-advancing}-\eqref{i:enter-advancing} that the pair increases \( k(t) \) by
%   \( \ge\Q\B \).  
% \end{proof}

The following lemma is the scale-up of the Escape condition.

\begin{lemma}[Escape]\label{lem:escape}
  Let  \( \CEsc \) be as defined in~\eqref{eq:cns.traj}.
  In the absence of \( \Noise^{*} \), the
  head will leave any interval \( G \) of size \( n\B \) with \( n=\lambda\Q \),
  \( 1\le\lambda\le 3\beta \), within \( \CEsc\lambda^{2}\U \) steps.
\end{lemma}
\begin{Proof}
  Consider a time interval of length \( \CEsc\lambda^{2}\U\Tu \).
  Suppose that a burst of faults of size \( \le\beta \) happens during it: then we will consider the
  larger part \( J \) of the time interval
  before or after the burst (or the whole interval if there is no fault).
  Let 
\begin{align*}
 \d=\CMarg,\; \g = \CEsc(7\d)^{2}.
\end{align*}
Let \( t_{0} \) be our starting time.
Subdivide the interval \( G \) into subintervals \( L_{i} \) of size \( \d\B \) called \df{blocks}.
The numbering of \( L_{i} \) should be such that head at time \( t_{0} \) is in block \( L_{0} \),
so \( i \) can have negative values.
Let the blocks with \( i\equiv 0\pmod 4 \) be called \df{boundary} blocks, and those
with \( i\equiv 2\pmod 4 \) called \df{middle} blocks. 
Consider the interval of adjacent blocks \( I=L_{i-3}\cup L_{i-3}\cup\dots\cup L_{i+3} \).
If the head is in \( L_{i} \) then by the Escape property of trajectories and~\eqref{eq:beta-lb},
it will escape \( I \) within time \( \g\Tu \).
If it is at time \( t_{j} \) in \( L_{i} \) then let \( t_{j+1} \) be defined
as the time at which it leaves \( I \).
This defines a sequence of times \( t_{j} \).
The time intervals \( \rint{t_{i}}{t_{i+1}} \), all of size \( \le\g\Tu \), will be called \df{skips}.
The skip is either to the left of \( I \) or to the right: if to the left, then its \df{middle block}
is \( L_{i-2} \), if it is to the right then \( L_{i+2} \).

\begin{step+}{step:escape.dirty}
  The number of skips in which the middle block is not clean is at most \(  \passno n/2\d \).
\end{step+}
\begin{pproof}
  The total number of middle blocks is \( \le n/4\d \).
  If a block is the middle block of a right skip \( \passno \) times,
  then the Pass Cleaning property implies that it becomes clean.
  Similarly for left skips.
  So it can be middle block for only \( 2\passno \) skips.
\end{pproof} % step:escape.dirty
\begin{step+}{step:escape.mixed}
  The number of skips during which the head touches disorder is at most
\( \passno n/2\d + 6 n/\d \).  
\end{step+}
\begin{pproof}
  We already estimated the number of skips whose middle block is not clean.
  The remaining skips pass over a clean middle block, but may touch disorder before
  or after it.
  If they do this then they will have to either enter a clean middle block from disorder,
  or leave it.
  By the Attack Cleaning property, each leaving skip increases the clean interval
  it leaves by \( \ge\B/2 \).
  There are only 6 other blocks in the range of the skip, with a total length \( 6d\B \),
  so after \( 12 \) leaving skips, they would be cleaned.
  The entering skips will have to be balanced by leaving skips,
  so the total number of skips touching disorder with a given middle block is \( \le 24 \).
  There are at most \( n/4\d \) middle blocks, bounding the total number of
  these skips by \( 6 n/\d \).
\end{pproof} % step:escape.mixed

Now consider the skips in which the head does not touch disorder (clean skips).

\begin{step+}{step:escape.short}
  The total number of short stays containing clean skips is at most \( 6 n/\d \).
\end{step+}
\begin{pproof}
  Each short stay ends with a skip that touches disorder.
\end{pproof} % step:escape.short

\begin{step+}{step:escape.sum}
Let us add up all the estimates.
\end{step+}
\begin{prooof}
  Part~\ref {step:escape.mixed} shows that the number of skips
  that are not clean is at most \( \passno n/2\d + 6n/\d \),
  for a total time, with \( n=\lambda\Q \).
  
  Part~\ref{step:escape.short} shows that the number of short stays containing clean
  skips is at most \( 6 n/\d \), for a total time of at most \( 6 \lambda\Q\S/\d \)
  where \( \S \) was defined in~\eqref{eq:S-def}.

  Lemma~\ref{lem:escape.long-stays} bounds the number of long stays by \( 3\lambda \),
  and Lemma~\ref{lem:escape.inside-hole} bounds the length
  of each long stay by \( 2 \lambda\U\Tu \), so the total time taken by long stays is
  at most \( 6\lambda^{2}\U\Tu \).
  Given that \( U=\Q^{3} \), this last term dominates the two previous one,
  so for large \( \Q \) the sum will be bounded by \( 7\lambda^{2}\U\Tu \).
  Since~\eqref{eq:cns.traj} defined \( \CEsc=7 \), this completes the proof.
\end{prooof} % step:escape.sum
% Lemma~\ref{lem:escape.long-stays} implies from part~\ref{step:escape.long}
% that the long stays increase \( |K^{*}(t)| \) by \( >(c\lambda/8 - 1/8\lambda)\Q\B \).
% If \( c=9 \) then this becomes \( >|G|=\lambda\Q\B \).
\end{Proof}


\subsection{Weak attack cleaning}

This section will scale up the Attack Cleaning
property of trajectories (Definition~\ref{def:traj})
to machine \( M^{*} \), but first only in 
a weaker version, restricting the number of bursts of faults in the relevant interval.

\begin{definition}[Trap]\label{def:trap}
  Recall the definition of trains in Section~\ref{sec:feathering}.
In an interval \( I \), clean except possibly up to \( 3\passno \) islands of size \( \beta \),
a point is considered a \df{leftward trap} if (after changing it in the islands),
it is at a right-directed frontier zone with a footprint of a big right turn (as in Definition~\ref{def:footprint}).
\end{definition}

The Attack Cleaning property says the following for the present case.
Let \( P \) be a path that is free of any fault of \( \eta^{*} \).
For current colony-pair \( \pair{x}{x'} \) (where \( x'< x+2\Q\B \)), suppose that the interval
\( I=\lint{x-\CMarg\Q\B}{x'+\Q\B} \) is clean for \( M^{*} \).
Suppose further that the transition function, applied to \( \eta^{*}(x,t) \), directs the head right.
Then by the time the head comes back to \( x-\CMarg\Q\B \),
the right end of the interval clean in \( M^{*} \)
containing \( x \) advances to the right by at least \( \Q\B /2\).

 \begin{lemma}[Weak attack cleaning]\label{lem:weak-attack-clean}
   In addition of the above condition of attack cleaning,
   assume that the faults of size of trajectory \( \eta \) in the interval
   \( I \) covered by at most \( \s<\Q/3\E \) bursts of size \( \beta \).
   Then the conclusion holds.
\end{lemma}
\begin{proof}
The computation phase of the simulation on the colony-pair \( \pair{x}{x'} \) is completed,
then the transfer phase begins, possibly entering the disorder to the right of \( x'+\Q\B \).
We argue that there are only two ways for the head to get back to \( x-\CMarg\Q\B \).
\begin{varenum}{at}
\item\label{i: weak-attack-clean.normal} The transfer into a new colony-pair with starting point
\( y\ge x'+\Q\B \) succeeds despite the disorder, and the clean interval extends over it, before
the head moves left to \( x-\CMarg\Q\B \) in the course of the regular simulation.
Some inconsistencies may be discovered along the way, but they are corrected by healing.

\item\label{i: weak-attack-clean.rebuild} The inconsistencies encountered along the way trigger some
rebuilding processes.
Eventually a complete, clean rebuilding area is created, the rebuilding succeeds, leaving a clean
colony also to the right of \( x'+\Q\B/2 \).
\end{varenum}

By the Spill Bound property, disorder can spill left of \( x'+\Q\B \) only by
\( \CSpill\B \) as long as the path \( P \) is fault-free.
If a burst of faults creates an island at a distance \( \ge\E\B \) from the disorder and other islands
then this island will be healed unless it is at a rightward trap.
The feathering property assures that such remaining islands are at a distance \( \ge\Z\B/3 \) from
each other, ready to be healed at any next pass.
There are at most \( \s \) bursts of size \( \le\beta \),
so the possibly not correctable islands are all
within distance \( \s\E\B \) of the disorder, to the right of
\begin{align*}
   R = x'+\Q\B -(\s\E+\CSpill)\B.
\end{align*}
Consider this as the new left end of the disorder; the bound \( \s \) on the number of bursts
implies that size of the new spill is still \( <\Q\B/3 \).

Suppose that rebuilding is not initiated (with creating a substantial germ):
then the head can move deeper left into the colony of \( x' \) only by the normal
course of simulation: the transfer stage of the simulation must be carried out, and this requires 
at least as many attacks to the right as the number of sweeps in the transfer stage.
Every attack (followed by return) extends the clean interval further,
until the whole target colony becomes clean, and the transfer completed.
This is the case~\eqref{i: weak-attack-clean.normal}.

Recall the rebuilding procedure in Section~\ref{sec:rebuilding}:
the rebuilding area extends \( 3\Q \) cells to the left and right from its initiating cell.
This may become as large as \( 6\Q\B \) to the left and right.
If initiated, its starting position \( z \) is to the right of \( R \) as defined above.
It then may extend to the left to at most \( z-6\Q\B \) (this is over-counting,
since the cells of the colony of \( x \) are all adjacent):
if the head moves to the left of this, then the rebuilding must have succeeded.
Its many sweeps will result in attacks that clean an area to the right of the starting point.
The procedure may be restarted several times, but those re-startings will also be initiated
to the right of \( z \).
The rebuilding also must find or create a colony manifestly to the right of the restarting site.
Since \( R>x'+\Q\B/2 \) this will move the boundary of the area clean in \( M^{*} \) 
by at least \( \Q\B/2 \): this is the case of~\eqref{i: weak-attack-clean.rebuild}.

In the process described above,
it is possible that the rebuilding finds a competing colony \( C \)
starting at some \( y \in x'+\Q\B + \lint{-\beta\B}{0}\) which
slightly (by the size of an island) overlaps from the right with the colony of \( x \).
The rebuilding may decide to keep \( C \) and to overwrite the rest of the colony of \( x' \) as a bridge
(or even target).
This does not affect the result.
\end{proof}

The following lemmas draw the consequences of several applications of weak attack cleaning.

\begin{lemma}\label{lem:k-bursts}
  Let \( P \) be a path with at most \( \Q/2\E \) bursts of faults of size \( \beta \)
  over an interval \( I = \lint{a}{b} \) that is admissible at the beginning of \( P \).
  Then by the end of \( P \), the subinterval \( \Int(I, 13\Q\B) \) will be still admissible.
  If no bursts occur on sections of the path that enter and exit \( I \) from the right then
  the subinterval \( \lint{a+13\Q\B}{b} \) will also stay admissible.
\end{lemma}
\begin{proof}
  Let us divide the bursts of faults into three groups.
  As bursts intersecting \( I \) occur, let us call each island created by a new burst
  an \df{end-island} if it is closer than \( 2\E\B \) to either one of the ends of \( I \) or to
  an earlier end-island.
  Let us call the other islands within \( 7\Q\B \) of the ends the \df{rebuilding} islands, and the rest the
  \df{interior} islands.

  By definition the end-islands are confined to within \( \Q\B \) of the ends of \( I \).
  If the head enters into any colony away from the end-islands in normal mode,
  then it will correct any two islands that are within \( 2\E\B \) from each other (an isolated
  one that was there and a new one just created).
  A burst can create an island that is not corrected within one pair of sweeps of the simulation,
  only at the end of a big turn.
  These big turns are outside the interior of any extended colony %?
  and separated from each other
  by at least \( \Z\B/3 \), therefore the islands at their ends
  will be corrected in any later pass by the head that touches them.

  Bursts can also affect rebuilding, but again the ones that do not become end-islands and
  are not corrected in one sweep are only the ones at the end of big turns.
  Even repeated rebuilding does not allow the remaining islands to be closer than \( \Z\B/3 \) to
  each other, therefore any new rebuilding process that touches one of these will correct it.
  It follows that if a rebuilding process is started at a distance of least \( 7\Q\B \) from the edges
  then, since it does not reach any end-island, it will be able to complete, not reaching the interior
  \( \Int(I,13\Q\B) \).
  Therefore the head will always reach this interior in normal mode.

  The argument clearly proves also the last statement of the lemma,
  about a path with no faults on entering from the right.
  In this case there is at most one end-island on the right end.
  Indeed, if the path returns from the right end-colony, leaving an island there,
  then due to feathering by the simulated trajectory, next time it must move right from it,
  and by passing the island, must correct it.
  \end{proof}

  \begin{lemma}\label{lem:weak-repeated-attack}
  Let \( I_{0} \) be an interval of size \( > 28\Q\B \), and \( J \) an adjacent
  interval of size \( k\Q\B \) on its right.
  Assume that \( I_{0} \) is super-healthy at the beginning of a path \( P \) whose
  faults are coverable by fewer
  than \( \Q/2\E \) bursts over the interval  \( I_{0}\cup J \), that passes \( I_{0} \)
  at least \( 2^{k+14} \) times from left to right.
  Assume also that no faults occur on segments of the path that enter and exit \( I_{0} \) from the right.
  Then at some time during the path, the interval \( J \) becomes admissible.
  The same statement holds if we switch left and right.
\end{lemma}
\begin{proof}
  We will apply Lemma~\ref{lem:k-bursts} to intervals into which the \( I_{0} \) and the
  right extensions of its admissible area.
  It is easy to see that \( \Int(I,13\Q\B) \) will always stay admissible; at any time \( t \)
  let \( I(t) \) be the largest admissible interval containing this.
  At the first pass, the rightmost colony of \( I(t) \) will be at a distance \( \le 13\Q\B \) from the right end.
  The lemma implies that the right end of \( I(t) \) will not move left.
  Every time when \( P \) passes to the right of \( I(t) \), there will be an attack, extending \( I(t) \) by \( \Q\B \).
  However, not every time that path \( P \) passes \( I_{0} \) to the right, will it necessarily pass
  also \( I(t) \); it may turn back before.
  Feathering makes sure, however, that in \( 2^{i} \) passes, it moves right at least \( i \) times,
  so the \( 2^{k+14} \) passes are sufficient to include extend \( I(t) \) over the whole interval \( J \).
  \end{proof}


\subsection{Pass cleaning}\label{sec:pass-cleaning}

\begin{sloppypar}
  We will assume that \( \passno \) is an even number.
The scaled-up version of the Pass Cleaning property
considers a path \( P \) with no faults of \( \eta^{*} \), as it makes
\begin{align}\label{eq:passno}
 \passno^{*}=\passno + 8
 \end{align}
 passes over an the interval \( I \) of size \( \CPass\Q\B \),
 and claims that they make \( \Int(I,\CMarg\Q\B) \) clean for \( \eta^{*} \).
 The weak version of this property uses the additional assumption that the faults of \( P \)
 are coverable by at most \( 3\passno \) bursts of size \( \beta \).
 This is what we will prove first, so let us use this assumption.
 Since there are few bursts, there will be long intervals that are fault-free.
 Specifically, \( I \) is made up of clean subintervals of size \( \ge 4\Z\B \) that we will call \df{basic holes}
 separated from each other and the ends by distances \( \le 12\passno\Z\B \).
 \end{sloppypar}
 
The pass cleaning property of \( \eta \) cleans the basic holes (except for margins of size \( \le\CMarg\B \)).
By the Spill Bound property, they may erode on the edges by a further amount \( \CSpill\B \).
We will call these somewhat smaller intervals still basic holes.
One more pass will make the basic holes, according to Lemma~\ref{lem:safe-for-turns}, safe for turns.
The following two lemmas will show how some order will be established on them in two more passes.
Recall that the maximum number of cells in a healing area, \( \E  = O(\beta) \)
from Definition~\ref{def:substantial}, is a constant, much smaller than the zigging distance (in cell widths)
defined in~\eqref{eq:FDef} as \( \Z=\passno^{1+\rho} \).

\begin{definition}\label{def:directed}
A clean interval \( J \) of size \( >3\Z\B \) not containing the head is called \df{right-directed}
if it is safe for turns, the head is to the right of \( J \),
and its cells, maybe with the exception areas of size \( 3\passno\E\B \) on the ends,
point towards a front at the right end of \( J \) (in normal operation or rebuilding),
with the corresponding frontier zone inside \( J \).
\end{definition}

\begin{lemma}\label{lem:make-directed}
  Consider an interval \( \lint{a}{b} \) of size \( \ge 4\Z\B \) that is safe for turns.
  If a path passes it noiselessly
  from left to right then it will leave a clean right-directed interval \( \lint{a}{b'} \) with 
  \( b'\ge b-\CSpill\B \).
  The same is true when interchanging left and right.
\end{lemma}
\begin{proof}
  Assume that the starting mode is normal.
  If it remains normal then \( J \) naturally becomes directed by the time the head exits.
  Since it exits at the front (more precisely at the right of the frontier zone),
  the frontier zone stays behind.
  Let us see that also in all other cases when the head exits it leaves behind the
  right frontier zone.
  
  If healing gets triggered then as long as healing succeeds it extends a healthy area.
  It moves towards right only if the front is on the right.
  If it does not succeed then rebuilding gets triggered,
  and since it does not touch the left end anymore, it either succeeds or exits on the right
  while trying to extend towards the right.
 The same considerations work if the starting mode is healing, except possibly on
 the part of size \( \le\E\B \) of the left end where the first healing took place, whose purview
 was not completely contained in \( J \).
\end{proof}

Recall the definition of the feathering parameter \( \F \) in~\eqref{eq:FDef}.

\begin{lemma}\label{lem:keep-directed}
  Consider a fault-free path.
  \begin{alphenum}
  \item\label{i:stay-directed}
    Suppose that an interval \( J \) is right-directed, and the head enters it from the right.
    If the head leaves on the right then \( J \) will stay right-directed. 
  \item\label{i:other-end}  If the head leaves on the left then within \( 2\Z \) cells of the right end
    of \( J \) there will be a footprint of a big left turn in \( J \) (as defined in Section~\ref{sec:feathering}).
% \item\label{i:no-inside-trap}
%   If the path passes a hole \( \lint{a}{b} \) from right to left 
%   then any rightward trap it leaves there must be within \( 2\E\B \) of the left end.
  \end{alphenum}
  The same conclusions hold if we switch left to right.
\end{lemma}
\begin{proof}
  To~\eqref{i:stay-directed}: Both in normal operation and rebuilding,
  the head moves the front with itself and returns to it from every zig, except when it is
  captured at an end of \( J \) (by faults or disorder).
  If an island is encountered or faults occur then this will be healed, except when the healing interval
  (whose maximum size is \( \E\B \)) intersects
  the boundary of \( J \) (where the disorder may capture the head).

  To~\eqref{i:other-end}: the front can turn back only at leftward traps;
  otherwise the simulation or rebuilding will move it forward, and the forward
  zigging prevents faults or disorder from turning it back prematurely.
  On turning back, it will leave behind a footprint of a big left turn,
  though the at most \( 3\passno \) bursts of size \( \le\beta \) covering the faults 
  happening in between can shorten this train (of size \( \Z/2 \))
  by \( 3\passno\ll\Z \) cells.

 %  To~\eqref{i:no-inside-trap}:
 %  Let us assume that the trap is in \( \lint{a+2\E\B}{b} \), and arrive at contradiction.
 %  Now, it does not turn back the head only if it triggers an alarm.
 %  Given the distance from \( a \) the healing concludes.
 % If it succeeds then again, the head turns the front back and erases the trap.
 % Otherwise it starts a rebuilding; but the latter starts to the right (and is not interrupted due to the
 % precedence of the right direction in rebuilding), erasing the trap.
\end{proof}

\begin{lemma}[Weak pass cleaning]\label{lem:weak-pass-clean}
  Suppose that a path \( P \) has no faults of \( \eta^{*} \),
  it makes \( \passno^{*} \) passes over the interval \( I \) starting from the left,
  with its faults covered by at most 
\begin{align*}
 \s=\passno^{*}(\passno^{*}+2^{\CPass+\CMarg + 14}).
\end{align*}
bursts of size \( \beta \) in \( I \).
Then by end of the \( \passno ^{*} \)th pass the interior
\( \Int(I, \CMarg\Q\B) \) becomes clean for \( \eta^{*} \).
\end{lemma}

\begin{Proof}
  Let us number the passes after the first \( \passno \) of them like pass 1,2,3,\dots.
  \begin{step+}{step:weak-pass-clean.pass-clean}
    The first \( \passno+1 \) passes make the basic holes clean and safe for turns, except
    for margins of size \( \le(\CMarg+\CSpill)\B \).
  \end{step+}
  \begin{pproof}
 As shown above, the basic holes, of size \( \ge 4\Z\B \) and
 separated from each other and the ends by distances \( \le 4\s\Z\B \),
 become and stay clean for \( \eta \) in the first \( \passno \) passes, except for margins
 of size \( \le(\CMarg+\CSpill)\B \).
 Now the next pass, called pass 1, will make the basic holes safe for turns.
\end{pproof} % step:weak-pass-clean.pass-clean

Assume that pass 1 was from right to left; otherwise, we start one pass later.
Since we will finish in 7 passes we will still finish by \( \passno^{*}=\passno+8 \).
Let us call at any time a subinterval of \( I \) a \df{hole} if it is clean and safe for turns
with the possible exception of  \( \s \) islands, and is maximal with this property.
Holes will grow from basic holes.

  \begin{step+}{step:weak-pass-clean.traps}
    Passes 2 and 3 will leave each hole left-directed, with the footprint of a left turn
    on the left end of each but possibly the last one.
\end{step+}
\begin{pproof}
  \begin{itemize}
  \item Lemma~\ref{lem:make-directed} shows that the
next pass turns each basic hole into a right-directed hole, with possibly a single island
caused by faults.
 \item Lemma~\ref{lem:keep-directed}\eqref{i:stay-directed} shows that
   the limited number of bursts of size \( \beta \) between this and the next pass
   that cover the faults, keeps the holes right-directed (just possibly adding some islands).
\item
  Lemma~\ref{lem:make-directed} shows again that the following leftward pass turns
  each hole into a left-directed one.
  Lemma~\ref{lem:keep-directed}\eqref{i:other-end} shows that this same leftward pass
  leaves a footprint of a left turn within \( \E\B \) of the right end of each hole.
  \end{itemize}
\end{pproof} % step:weak-pass-clean.traps

\begin{step+}{step:weak-pass-cleaning.opposing}
  After pass 4 (which is from the left),
  each interval between holes has a footprint of a big left turn on its left and one
  of a big right turn on its right.
\end{step+}
\begin{pproof}
  Feathering allows the footprint of a big left turn
  on the right end of a hole \( J \) to be erased only if it is
  moved to  a distance at least \( \ge\F\B \) to he right.
  As \( \F \gg \) the upper bound \( \s\Z \) on the separation between the holes,
  the process erases the disorder between \( J \) and the next one, \( J' \) unless \( J' \) contains
  a rightward trap at its end.
  In the latter case, a footprint of the big left turn at the right end of \( J \) remains.
  Lemma~\ref{lem:keep-directed}\eqref{i:other-end} shows that a footprint of a 
  big right turn is created on the left end of every remaining hole.
\end{pproof} % step:weak-pass-cleaning.opposing

\begin{step+}{step:weak-pass-clean.make-clean}
  Passes 5 and 6 make the interval clean and safe for turns, except possibly one island of size \( \beta \)
  caused by faults during pass 6.
\end{step+}
\begin{pproof}
  Having each boundary between holes surrounded by the footprints of big left and right turns,
  the next pass (which is from the right) will erase all these boundaries.
  So it makes the whole interval (other than the edges) clean.
  The following pass will make it safe for turns.
\end{pproof} % step:weak-pass-clean.make-clean
  
\begin{step+}{step:weak-pass-clean.finish}
  Pass 7 will clean \( \Int(I, 7\Q\B) \) for \( \eta^{*} \).
\end{step+}
\begin{pproof}
  The intrusions from right to left into \( I \) before the next pass
  may create up to \( \s \) islands of disorder, of size \( \beta \),
  but these islands are placed at least \( \Z\B/3 \) apart.
  Indeed, in order for an island not to be cleaned, it must be at the right end of a big left turn,
  and so will leave a left turning footprint.
  So a later intrusion can only leave an island if it does not see \( 2\E \) cells of this
  footprint and is therefore at a distance \( >\Z\B \) to its left, or passes it by a distance \( \F\B \).
  These intrusions create no rightward trap.

  When the full rightward pass comes, the head 
  cannot pass without either already having an area already clean for \( \eta^{*} \) or
  cleaning, healing and rebuilding.
  No rebuilding started farther than \( 6\B\Q \) from the boundary will exit \( I \): it may only result in
  alarm if it encounters disorder or the single burst of faults of size \( \le\beta \) occurs.
  As seen above, any disorder encountered at a time will be of size \( \le\beta\B \), at a distance
  at least \( \Z\B/3 \) from the next one.
  Hence once the healing restarts after this disorder is cleaned,
  it will discover the rebuilding front, allowing it to continue.
  So eventually the rebuilding succeeds.

  This process may be repeated as the head moves right, and indeed the head cannot pass through \( I \)
  without continuing this process, making it super-healthy.
  The only missed areas are those that may contain a rebuilding interval
  reaching the edge of \( I \).
\end{pproof} % step:weak-pass-clean.finish
\end{Proof}


% \begin{remark}
% Left and right are not symmetric in the above proof.
% Consider a right-directed basic hole with a rebuilding area being extended on the right.
% The head may be captured and returned, extending some other rebuilding area towards the left.
% Without giving preference to the right direction, this switching between left and right-directed rebuilding
% could happen an unbounded number of times.
% Using the asymmetry of the definition of rebuilding in Section~\ref{sec:rebuilding},
% the right-directed extension of the basic hole will not be overridden by a left-directed rebuilding.  
% \end{remark}

\begin{lemma}\label{lem:repeated-attack}
  Consider the statement of Lemma~\ref{lem:weak-repeated-attack} with the interval
  \( I_{0} \) having the same length \( k\Q\B \) with \( k=\CPass+\CMarg \) as the interval \( J \).
  The conclusion holds also
  without the bound on the number of bursts covering the faults over the interval  \( I_{0}\cup J \).
\end{lemma}
\begin{proof}
  Let \( J_{1}= I_{0} \), \( J_{0}=J \).
    We will show that if the conclusion does not hold then the paths passes over all the
  infinite sequence of consecutive adjacent intervals  \( J_{2},J_{3},\dots \) 
  on the left of \( J_{1} \), of size \( |J_{1}| \).
  Since the path is finite, this leads to a contradiction.
  Let \( i=1 \).
 \begin{enumerate}
 \item\label{i:repeated-attack.2}
   Suppose the conclusion of  Lemma~\ref{lem:weak-repeated-attack} does not hold.
   Then the faults needed at least \( \Q/2\E  \) bursts of size \( \beta \) to cover them
   over \( J_{i+1}\cup J_{i} \) during this time,
   consequently at least \( \passno^{*}+2^{k+14} \) bursts happened during
   some two consecutive pair of the  \( 2^{k+14} \) rightward passes over \( J_{i+1} \).
  % We will show that there is a rightward pass over \( J_{i+1} \) in \( K_{i} \), which leads to contradiction
  % with the choice of \( K_{i} \).

\item\label{i:repeated-attack.choice}
  By the Escape property, each fault is covered in a burst of size \( \beta \)
  contained in a segment covering an interval \( >3\CPass\Q\B \)
  with no more faults outside the burst.
  Since these segments don't pass over \( J_{i+1} \),  each contains a fault-free pass over \( J_{i+2} \).
  
  Suppose that \( \Int(J_{i+2},\CMarg\Q\B) \) becomes clean
  at some time during the first \( \passno^{*} \) of these passes.
  There are still \( 2^{k+14} \) fault-free passes over \( J_{i+2} \), so we are
  back at the situation of part~\ref{i:repeated-attack.2} with \( i\gets i+1 \).


    \item\label{i:repeated-attack.1}
      Suppose that \( J_{i+2} \) does not become clean during the first \( \passno^{*} \) passes.
      Then by Lemma~\ref{lem:weak-pass-clean}, since \( k=\CPass+\CMarg \), 
      the number set of faults need a number bursts of size \( \beta \) covering
      them in \( J_{i+2} \) exceeding  \( \s = \passno^{*}(\passno^{*}+2^{k+14}) \).
      Then at least \( \passno^{*}+2^{k+14} \) bursts happen over \( J_{i+2} \)
      between some consecutive pair of the left-right passes over \( J_{i+2} \).
  By the Escape property, each burst is contained in a segment
  covering an interval \( >3\CPass\Q\B \) with no more fault outside the bursts.
  Since these segments don't pass over \( J_{i+2} \),
  each contains a fault-free pass over \( J_{i+3} \).
  This brings us back to the situation of part~\ref{i:repeated-attack.choice} with \( i\gets i+1 \).
\end{enumerate}
\end{proof}


Let us remove the bound on the number of bursts
in the Pass Cleaning property of \( \eta^{*} \)

\begin{lemma}[Pass cleaning]\label{lem:pass-clean}
  Let \( P \) be a space-time path without faults of \( \eta^{*} \) that makes
  at least \( \passno^{*} \) passes over an interval \( I \) of size \( \CPass\Q\B \).
  Then there is a time during \( P \) when \( \Int(I,\CMarg\Q\B) \) becomes clean.
\end{lemma}
\begin{proof}
  Let \( J_{1}= I \).
  We will show that if the conclusion does not hold then the paths passes over all the
  infinite sequence of consecutive adjacent intervals  \( J_{2},J_{3},\dots \) 
  on the left of \( J_{1} \), of size \( |J_{1}| \).
  Since the path is finite, this leads to a contradiction.
Let \( i=1 \), \( k=\CPass+\CMarg \).

   \begin{enumerate}
  \item\label{i:pass-clean.1}
  By weak pass cleaning (Lemma~\ref{lem:weak-pass-clean}),
  if \( \Int(J_{i},\CMarg\Q\B) \) did not become clean for \( \eta^{*} \),
  the number of bursts of size \( \beta \)
  in \( J_{i} \) needed to cover the faults is more than \( \s = \passno^{*}(\passno^{*}+2^{k+14}) \).
  Therefore there is a time interval between two consecutive left-right passes over \( J_{i} \)
  with at least \( 2(\passno^{*}+2^{k+14}) \) bursts over \( J_{i} \).
  Due to the Escape property, each part of \( P \)
  containing one of these bursts has a noise-free segment
  of size \( >2\CPass\Q\B \) either on the left or on the right of \( J_{i} \).
  Without loss of generality we can assume that at least half of them are on the left, giving
   \( \passno^{*}+2^{k+14} \)  noise-free passes over \( J_{i+1} \) during this time.

  \item\label{i:first-choice}
  If  \( J_{i+1} \) does not become clean during the first \( \passno^{*} \) of these passes
  then restart the reasoning, going back to part~\ref{i:pass-clean.1}, setting \( i\gets i+1 \).
  Otherwise
by Lemma~\ref{lem:repeated-attack}, interval \( J_{i} \) becomes clean during the next \( 2^{k+14} \)
      noise-free passes over \( J_{i+1} \), contrary to the assumption.
\end{enumerate}
\end{proof}

\subsection{Attack cleaning and spill bound}

Let us remove the bound on the number of bursts in the scale-up of the Attack Cleaning property.

\begin{lemma}[Attack cleaning]\label{lem:attack-clean}
  Consider the situation of Lemma~\ref{lem:weak-attack-clean}.
  The conclusion holds also if the number of bursts of size \( \le\beta \) needed to cover the
  faults of \( \eta \) in
  \( I=\lint{x-\CMarg\Q\B}{x'+\Q\B} \) is not bounded by \( \Q/3\E \).
\end{lemma}
\begin{proof}
  By Lemma~\ref{lem:weak-attack-clean}, we need now only to consider the case
  when there are at least \( \Q/3\E \) bursts.
  Consider the path \( P'\subseteq P \) containing the first \( \passno^{*}+2^{\CMarg+16} \) of these.
  The Escape property implies that \( P' \) passes the
  interval \( J \) of length \( \CPass\Q\B \) on the right of \( I \) this many times.
  The Pass Cleaning property then implies that \( \Int(J,\CMarg\Q\B) \) becomes
  clean for \( \eta^{*} \) during \( P' \).
  Then Lemma~\ref{lem:repeated-attack} (applied in the left direction)
  implies that within the next \( 2^{\CMarg+16} \)
  passes, the disorder of \( \eta^{*} \) of length \( \le (1+\CMarg)\Q\B \) between the old clean interval
  ending at \( x'+\Q\B \) and the new one beginning at \( x'+(\CMarg+1)\Q\B \) will be erased.
    \end{proof}

Let us prove the scaled-up version of the spill bound property.

\begin{lemma}[Spill bound]\label{lem:spill-bound}
Suppose that an interval \( I \) of size \( > 2\CSpill\Q\B \) is clean for \( \eta^{*} \). and
let \( P \) be a path that has no faults of \( \eta^{*} \).
Then \( \Int(I,\CSpill\Q\B) \) stays clean for \( \eta^{*} \).
\end{lemma}
\begin{proof}
  Without loss of generality, consider exits and entries of the path on the left of \( I \).
  Let \( C_{0},C_{1}\) be the two leftmost colonies in \( I \), where
  by definition \( C_{0} \) is at the very end of \( I \).
  We can assume that \( C_{0} \) 
  is damaged since the Spill Bound property of \( \eta \) allows a spill of size \( \CSpill\B \) into it.
  Consider a part of the path entering \( I \) and then leaving again on the left.
  As long as disorder is at least at a distance \( \E\B \) away from \( C_{1} \),
  when the path enters these colonies it just continues the simulation.
  Any burst of faults will be corrected or leave an island subject to the limitations of health.

  The islands created by faults in \( C_{0} \) can be divided into two groups: one is a group 
  starting from the left end in such a way that the distance between consecutive elements
  is at most \( \E\B \).
  
  The other ones are at a distance \( \ge\Z\B/3 \) from each other, at left turning footprints.
  It follows that if the faults can be covered by at most \( \Q/3\E \) bursts of size \( \beta \)
  in \( P \) over \( C_{0} \) then no colony on the right of \( C_{0} \)
  will be damaged, since the first group never passes beyond \( C_{0} \).
  On the other hand, if  than \( \Q/3\E \) bursts are needed in \( C_{0} \)
  then we can finish just is in the proof of Lemma~\ref{lem:attack-clean}.
\end{proof}

% \section{After a large burst}

% Our goal is to show that the simulation \( M\to M^{*} \)
% of Definition~\ref{def:scale-up} is indeed a simulation.
% Section~\ref{sec:1-level-noise} shows this as long as the head operates in an
% area that is clean for the simulated machine\( M^{*} \) (can be annotated), 
% and has no noise for machine \( M^{*} \) (that is its bursts on the level of machine \( M \)
% are isolated).
% In other words, essentially the Transition Function property of Definition~\ref{def:traj} of
% trajectories for the simulated machine \( M^{*} \) has been taken care of.

% \begin{sloppypar}
% The new element is the possibility of large areas that cannot be annotated: they
% may not even be clean, even on the level of machine \( M \).
% \end{sloppypar}

\section{Proof of the theorem}\label{sec:computation}

Above, we constructed a sequence of generalized Turing machines \( M_{1},M_{2}\dots \)
with cell sizes \( \B_{1},\B_{2},\dots \) where \( M_{k} \) simulates \( M_{k+1} \).
The sequences and dwell periods were also specified in Definition~\ref{def:hier-params}.
Here, we will use this construction to prove Theorem~\ref{thm:main}.


\subsection{Fault estimation}\label{sec:fault-estimation}

The theorem says that there is a Turing machine \( M_{1} \) that can reliably (in the defined sense)
simulate any other Turing machine \( \G \).
Before the simulation starts, the input \( x \) of \( \G \) must be encoded by a code depending on
its length \( |x| \).
We will choose a code that represents the input \( x \) as the information content of a
pair of cells of \( M_{k_{0}} \) for an appropriate \( k_{0}=k_{0}(x) \), and set their kind to \( \Booting \).
Note that the code does not depend on the length of the computation to be performed.
At any stage of the computation there will be a highest level \( K \) such that a generalized Turing
machine \( M_{K} \) will be simulated, with its cells of the Booting kind.

As the computation continues and the probability of some fault occurring increases, the
encoding level will be raised again and again, by lifting mechanism of Section~\ref{sec:booting}.
Let \(  \cE_{k}  \) be the event that no burst of level \( k \) occurs in the space-time region
\( \lint{-2\B_{k}}{2\B_{k}}\times\lint{0}{\Tu_{k+1}} \).
This implies that the history on level \( k \) can be annotated in this region.
Let
\begin{align*}
   \cD_{k} = \bigcap_{i<k}\cE_{i}\cap\neg \cE_{k+1},
\end{align*}
then \( \Prob(\bigcap_{k}\cE_{k})\ge 1 -\sum_{k}\Prob(\cD_{k}) \).
Let us show
\begin{align}\label{eq:fault-estim-0}
 \sum_{k}\Prob(\cD_{k})  = O(\eps).
\end{align}
The number of top level steps on level \( k \) is at most \( 3\Q_{k}\F_{k} \),
where \( \F_{k} \) is the feathering digression size defined in~\eqref{eq:FDef}.
Indeed, in Section~\ref{sec:booting} machine \( M_{k} \) performs at most \( \Q_{k} \) simulation
steps, but the feathering with big turns may introduce digression steps of up to \( 2\F_{k} \) per turn.

From Definition~\ref{def:hier-params} feathering constant \( \F_{k} \) of~\eqref{eq:FDef}
is obtained as
 \begin{align*}
 \F_{k}=(8 k + c_{2})^{3+2\rho}<k^{4}
 \end{align*}
 if  \( \rho \) is a small enough constant and \( k \) is large.
Hence
\begin{align*}
  3 \F_{k}\Q_{k} \le 3 c_{1}^{2}k^{4}\cdot 2^{1.2^{k}}.
\end{align*}
Lemma~\ref{lem:sparsity} bounds the probability of burst of level \( k \) by
\( \eps \cdot 2^{-1.5^{k-1}} \), giving
\begin{align*}
   \Prob(\cD_{k}) = O(\eps k^{4} 2^{1.2^{k}-1.5^{k-1}}),
\end{align*}
which shows~\eqref{eq:fault-estim-0}.

Suppose that machine \( \G \) produces output at its step \( t \) (recall that there is no halting,
but the output in cell 0 will not change further).
Let \( t' \) be any time after the point in the  work of machine \( M_{1} \)
at which the simulation of \( \G \) reaches this stage.
For each \( k \) let \( \tau_{k} \) be the (random) last time before \( t' \)
when the head of the simulated machine \( M_{k} \) reaches position 0.
Let \( \cE'_{k} \) be the event that no burst of level \( k \)
occurs in the space-time region \( \lint{-\B_{k}}{\B_{k}}\times\rint{\tau_{k}}{\tau_{k}+\Tu_{k}} \).

Then \( \bigcap_{k}\cE_{k}\cap\bigcap_{k}\cE'_{k} \) implies that at time \( t' \) the \( \Output \) field
of cell 0 has the output of machine \( G \).
By an argument equivalent to the one given above, the probability of this event is \( 1-O(\eps) \).

Just as above, it is easy to see \( \Prob(\cap_{k}\cE'_{k})\ge 1-O(\eps) \).
(Even though the rectangles defining the events \( \cE'_{k} \) are random,
a probability estimate can be obtained for \( \neg\cE'_{k} \) similarly to \( \neg\cE_{k} \) above:
just average over all possible values of \( \tau_{k} \).)

 \subsection{Space- and time-redundancy}\label{sec:redundancy}

 Even with the simple tripling error-correcting code, there is a constant \( c>1 \) such that
 a colony of level \( k \) uses at most
 \( c \) times more space than the amount of information contained in the
 cell of level \( k+1 \) that it simulates.
 Therefore if \( k \) is the level that needs to be simulated before an output of \( G \) can be reached
 then the space used at that time is at most \( c^{k} \) times the space needed to just store the information.
 If \( G \) produces output at time \( t \) then this is about \( c^{k}t \).
 The size of cells of level \( k \) is of the order of \( 2^{1.2^{k}} \), and this is also the
 the order of the number \( t \) of steps of \( G \) that can be simulated.
 So \( k \) is about \( d\log\log t \) with \( d\approx 1/\log 1.2 \).
 This gives a space redundancy factor
 \begin{align*}
 c^{k}\approx c^{d\log\log t}=(\log t)^{\alpha}  
\end{align*}
 for some \( \alpha>0 \).
 The estimate for time redundancy is similar.

 \section{Discussion}

\paragraph{A weaker but much simpler solution}
If our Turing machine could just simulate a 1-dimensional
fault-tolerant cellular automaton, it would become
fault-tolerant, though compared to a fault-free Turing machine computation of length \( t \),
the slow-down could be quadratic.
(Such a solution would be only \emph{relatively} simpler, being a reduction to a complex, existing one.)
We did not find an easy reduction by just having the simulating
Turing machine sweep larger and larger
areas of the tape, due to the possibility of the head being trapped too long in some large disorder created by
the group of faults.
Trapping can be avoided, however, 
\emph{provided that the length \( t \) of the computation is known in advance}.
The cellular automaton \( C \) can have length \( t \) , and we could define
a ``kind of'' Turing machine \( T \) with a \emph{circular tape} of size \( t \) simulating \( C \).
The transition function of \( T \) would move the head to the right in every step
(with any backward movement just due to faults).

 \paragraph{Decreasing the space redundancy}
 We don't know how to reduce the time redundancy significantly, but
 the space redundancy can be apparently reduced to a multiplicative constant.
 Following Example~\ref{xmp:Reed-Solomon}, it is possible to
 choose an error-correcting code with redundancy that is only a factor \( \delta_{k} \)
 with \( 
   \prod_{k=1}^{\infty}(1-\delta_{k})>1/2
 \).
 This also requires a more elaborate organization of the computation phase described in
 Section~\ref{sec:simulation-phase} since
 the total width of all other tracks must be only some \( \delta_{k} \) times the width
 of the \( \Info \) track.
 For cellular automata, such a mechanism was described in~\cite{GacsSorg01}.

 \paragraph{Other models}
 There is probably a number of models worth exploring with more parallelism than Turing machines, but less
 than cellular automata: for example having some kind of restriction on the number of active units.
 On the other hand, a one-tape Turing machine seems to be the simplest computation model for which a reasonable
 reliability question can be posed, in the framework of transient, non-conspiring faults of constant-bounded
 probability.

 A simpler, universal computation model is the so-called \df{counter machine}.
 This has some constant number of nonnegative integer counters (at least two for universality), and an internal state.
 Each transition can change each counter by \( \pm 1 \), depends on both the internal state
 and on the set of those counters with zero value.
 A fault can change the state and can change the value of any counter by \( \pm 1 \).
 It does not seem possible to perform reliable computation on such a machine in any reasonable sense.
 The statement of such a result
 cannot be too simple-minded, since there is \emph{some} nontrivial task that such a machine can
 do: with \( 2n \) counters, it can remember almost \( 2n \) bits of information with large probability forever
 Indeed, let us start the machine with \( n \) counters having the value 0, and the other \( n \) having some
 large value (depending on the fault probability \( \eps \)).
 The machine will remember forever (with large probability) which set of counters was 0.
 It works as follows (in the absence of a fault):
 at any one time, if exactly \( n \) values have value 0, then increase each nonzero counter by 1.
 Otherwise decrease each nonzero counter by 1.
 
 This sort of computation seems close to the limit of what counter machines can do reliably, but
 how to express and prove this?
 
\bibliographystyle{plain}
\bibliography{reli,gacs-publ}

\end{document}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t%%% End: 
